<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> llm | Unknown NLP Papers </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknownnlp.github.io/blog/tag/llm/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Papers </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</h1> <p class="post-description">an archive of posts with this tag</p> </header> <article class="archive"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Aug 10, 2025</th> <td> <a class="post-link" href="/blog/2025/2025-08-10-block-diffusion-interpolating-between-autoregressive-and-diffusion-language/">BLOCK DIFFUSION: INTERPOLATING BETWEEN AUTOREGRESSIVE AND DIFFUSION LANGUAGE MODELS</a> </td> </tr> <tr> <th scope="row">Aug 05, 2025</th> <td> <a class="post-link" href="/blog/2025/impact-of-fine-tuning-methods-on-memorization-in/">Impact of Fine-Tuning Methods on Memorization in Large Language Models</a> </td> </tr> <tr> <th scope="row">Aug 05, 2025</th> <td> <a class="post-link" href="/blog/2025/impact-of-fine-tuning-methods-on-memorization-in-large-language-models/">Impact of Fine-Tuning Methods on Memorization in Large Language Models</a> </td> </tr> <tr> <th scope="row">Aug 05, 2025</th> <td> <a class="post-link" href="/blog/2025/block-diffusion-interpolating-between-autoregressive-and-diffusion-language/">BLOCK DIFFUSION: INTERPOLATING BETWEEN AUTOREGRESSIVE AND DIFFUSION LANGUAGE MODELS</a> </td> </tr> <tr> <th scope="row">Aug 05, 2025</th> <td> <a class="post-link" href="/blog/2025/block-diffusion-interpolating-between-autoregressive-and-diffusion-language-models/">BLOCK DIFFUSION: INTERPOLATING BETWEEN AUTOREGRESSIVE AND DIFFUSION LANGUAGE MODELS</a> </td> </tr> <tr> <th scope="row">Jul 15, 2025</th> <td> <a class="post-link" href="/blog/2025/search-r1-training-llms-to-reason-and-leverage/">Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning</a> </td> </tr> <tr> <th scope="row">Jul 15, 2025</th> <td> <a class="post-link" href="/blog/2025/search-r1-training-llms-to-reason-and-leverage-search-engines-with-reinforcement-learning/">Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning</a> </td> </tr> <tr> <th scope="row">Jul 15, 2025</th> <td> <a class="post-link" href="/blog/2025/scaling-reasoning-losing-control-evaluating-instruction-following-in/">Scaling Reasoning, Losing Control: Evaluating Instruction Following in Large Reasoning Models</a> </td> </tr> <tr> <th scope="row">Jul 15, 2025</th> <td> <a class="post-link" href="/blog/2025/reasoning-model-is-stubborn-diagnosing-instruction-overriding-in/">Reasoning Model is Stubborn: Diagnosing Instruction Overriding in Reasoning Models</a> </td> </tr> <tr> <th scope="row">Jul 01, 2025</th> <td> <a class="post-link" href="/blog/2025/reasoning-models-can-be-effective-without-thinking/">Reasoning Models Can Be Effective Without Thinking</a> </td> </tr> <tr> <th scope="row">Jul 01, 2025</th> <td> <a class="post-link" href="/blog/2025/between-underthinking-and-overthinking-an-empirical-study-of/">Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs</a> </td> </tr> <tr> <th scope="row">Jul 01, 2025</th> <td> <a class="post-link" href="/blog/2025/between-underthinking-and-overthinking-an-empirical-study-of-reasoning-length-and-correctness-in-llms/">Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs</a> </td> </tr> <tr> <th scope="row">Jun 24, 2025</th> <td> <a class="post-link" href="/blog/2025/see-what-you-are-told-visual-attention-sink/">See What You Are Told: Visual Attention Sink in Large Multimodal Models</a> </td> </tr> <tr> <th scope="row">Jun 17, 2025</th> <td> <a class="post-link" href="/blog/2025/diffusion-of-thought-chain-of-thought-reasoning-in/">Diffusion of Thought: Chain-of-Thought Reasoning in Diffusion Language Models</a> </td> </tr> <tr> <th scope="row">Jun 17, 2025</th> <td> <a class="post-link" href="/blog/2025/diffusion-of-thought-chain-of-thought-reasoning-in-diffusion-language-models/">Diffusion of Thought: Chain-of-Thought Reasoning in Diffusion Language Models</a> </td> </tr> <tr> <th scope="row">Jun 10, 2025</th> <td> <a class="post-link" href="/blog/2025/dra-grpo-exploring-diversity-aware-reward-adjustment-for/">DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models</a> </td> </tr> <tr> <th scope="row">Jun 10, 2025</th> <td> <a class="post-link" href="/blog/2025/dra-grpo-exploring-diversity-aware-reward-adjustment-for-r1-zero-like-training-of-large-language-models/">DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models</a> </td> </tr> <tr> <th scope="row">Jun 03, 2025</th> <td> <a class="post-link" href="/blog/2025/textgrad-automatic-differentiation-via-text/">Textgrad: Automatic “Differentiation” via Text</a> </td> </tr> <tr> <th scope="row">Jun 03, 2025</th> <td> <a class="post-link" href="/blog/2025/reinforcement-learning-finetunes-small-subnetworks-in-large-language/">Reinforcement Learning Finetunes Small Subnetworks in Large Language Models</a> </td> </tr> <tr> <th scope="row">Jun 03, 2025</th> <td> <a class="post-link" href="/blog/2025/reinforcement-learning-finetunes-small-subnetworks-in-large-language-models/">Reinforcement Learning Finetunes Small Subnetworks in Large Language Models</a> </td> </tr> <tr> <th scope="row">Apr 15, 2025</th> <td> <a class="post-link" href="/blog/2025/universal-and-transferable-adversarial-attacks-on-aligned-language/">Universal and Transferable Adversarial Attacks on Aligned Language Models</a> </td> </tr> <tr> <th scope="row">Apr 15, 2025</th> <td> <a class="post-link" href="/blog/2025/universal-and-transferable-adversarial-attacks-on-aligned-language-models/">Universal and Transferable Adversarial Attacks on Aligned Language Models</a> </td> </tr> <tr> <th scope="row">Apr 15, 2025</th> <td> <a class="post-link" href="/blog/2025/model-context-protocol-mcp-provided-by-antrophic/">Model Context Protocol (MCP) - provided by Antrophic</a> </td> </tr> <tr> <th scope="row">Apr 08, 2025</th> <td> <a class="post-link" href="/blog/2025/on-the-biology-of-a-large-language-model/">On the Biology of a Large Language Model</a> </td> </tr> <tr> <th scope="row">Mar 25, 2025</th> <td> <a class="post-link" href="/blog/2025/reft-reasoning-with-reinforced-fine-tuning/">ReFT: Reasoning with Reinforced Fine-Tuning</a> </td> </tr> <tr> <th scope="row">Mar 11, 2025</th> <td> <a class="post-link" href="/blog/2025/when-is-task-vector-provably-effective-for-model/">WHEN IS TASK VECTOR Provably EFFECTIVE FOR MODEL EDITING? A GENERALIZATION ANALYSIS OF NONLINEAR TRANSFORMERS</a> </td> </tr> <tr> <th scope="row">Mar 11, 2025</th> <td> <a class="post-link" href="/blog/2025/cognitive-behaviors-that-enable-self-improving-reasoners-or/">Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs</a> </td> </tr> <tr> <th scope="row">Mar 04, 2025</th> <td> <a class="post-link" href="/blog/2025/swe-rl-advancing-llm-reasoning-via-reinforcement-learning/">SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution</a> </td> </tr> <tr> <th scope="row">Mar 04, 2025</th> <td> <a class="post-link" href="/blog/2025/swe-rl-advancing-llm-reasoning-via-reinforcement-learning-on-open-software-evolution/">SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution</a> </td> </tr> <tr> <th scope="row">Mar 04, 2025</th> <td> <a class="post-link" href="/blog/2025/logic-rl-unleashing-llm-reasoning-with-rule-based/">Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning</a> </td> </tr> <tr> <th scope="row">Mar 04, 2025</th> <td> <a class="post-link" href="/blog/2025/logic-rl-unleashing-llm-reasoning-with-rule-based-reinforcement-learning/">Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning</a> </td> </tr> <tr> <th scope="row">Feb 18, 2025</th> <td> <a class="post-link" href="/blog/2025/deepseek-v3/">DeepSeek v3</a> </td> </tr> <tr> <th scope="row">Feb 04, 2025</th> <td> <a class="post-link" href="/blog/2025/ssm-hippo-lssl-s4-mamba-mamba2/">SSM → HIPPO → LSSL → S4 → Mamba → Mamba2</a> </td> </tr> <tr> <th scope="row">Jan 21, 2025</th> <td> <a class="post-link" href="/blog/2025/agent-laboratory-using-llm-agents-as-research-assistants/">Agent Laboratory: Using LLM Agents as Research Assistants</a> </td> </tr> <tr> <th scope="row">Jan 14, 2025</th> <td> <a class="post-link" href="/blog/2025/training-large-language-models-to-reason-in-a-continuous-latent-space/">Training Large Language Models to Reason in a Continuous Latent Space</a> </td> </tr> <tr> <th scope="row">Jan 02, 2025</th> <td> <a class="post-link" href="/blog/2025/logits-decoding/">Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection</a> </td> </tr> <tr> <th scope="row">Jan 02, 2025</th> <td> <a class="post-link" href="/blog/2025/inferring-from-logits-exploring-best-practices-for-decoding/">Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection</a> </td> </tr> <tr> <th scope="row">Jan 02, 2025</th> <td> <a class="post-link" href="/blog/2025/deepseek-r1/">DeepSeek R1</a> </td> </tr> <tr> <th scope="row">Jan 02, 2025</th> <td> <a class="post-link" href="/blog/2025/d1-scaling-reasoning-in-diffusion-large-language-models/">d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning</a> </td> </tr> <tr> <th scope="row">Jan 02, 2025</th> <td> <a class="post-link" href="/blog/2025/d1-scaling-reasoning-in-diffusion-large-language-models-via-reinforcement-learning/">d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning</a> </td> </tr> <tr> <th scope="row">Oct 17, 2024</th> <td> <a class="post-link" href="/blog/2024/rule-based-rewards-for-language-model-safety/">Rule Based Rewards for Language Model Safety</a> </td> </tr> <tr> <th scope="row">Oct 17, 2024</th> <td> <a class="post-link" href="/blog/2024/knowledge-entropy-decay-during-language-model-pretraining-hinders-new-knowledge-acquisition/">KNOWLEDGE ENTROPY DECAY DURING LANGUAGE MODEL PRETRAINING HINDERS NEW KNOWLEDGE ACQUISITION</a> </td> </tr> <tr> <th scope="row">Oct 10, 2024</th> <td> <a class="post-link" href="/blog/2024/faitheval-can-your-language-model-stay-faithful-to/">FAITHEVAL: CAN YOUR LANGUAGE MODEL STAY FAITHFUL TO CONTEXT, EVEN IF “THE MOON IS MADE OF MARSHMALLOWS”</a> </td> </tr> <tr> <th scope="row">Oct 10, 2024</th> <td> <a class="post-link" href="/blog/2024/faitheval-can-your-language-model-stay-faithful-to-context-even-if-the-moon-is-made-of-marshmallows/">FAITHEVAL: CAN YOUR LANGUAGE MODEL STAY FAITHFUL TO CONTEXT, EVEN IF “THE MOON IS MADE OF MARSHMALLOWS”</a> </td> </tr> <tr> <th scope="row">Oct 03, 2024</th> <td> <a class="post-link" href="/blog/2024/qcrd-quality-guided-contrastive-rationale-distillation-for-large/">QCRD: Quality-guided Contrastive Rationale Distillation for Large Lanauge Models</a> </td> </tr> <tr> <th scope="row">Sep 23, 2024</th> <td> <a class="post-link" href="/blog/2024/training-language-models-to-self-correct-via-reinforcement/">Training Language Models to Self-Correct via Reinforcement Learning</a> </td> </tr> <tr> <th scope="row">Sep 23, 2024</th> <td> <a class="post-link" href="/blog/2024/training-language-models-to-self-correct-via-reinforcement-learning/">Training Language Models to Self-Correct via Reinforcement Learning</a> </td> </tr> <tr> <th scope="row">Sep 23, 2024</th> <td> <a class="post-link" href="/blog/2024/super-evaluating-agents-on-setting-up-and-executing/">SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories</a> </td> </tr> <tr> <th scope="row">Sep 09, 2024</th> <td> <a class="post-link" href="/blog/2024/smaller-weaker-yet-better-training-llm-reasoners-via/">Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling</a> </td> </tr> <tr> <th scope="row">Sep 09, 2024</th> <td> <a class="post-link" href="/blog/2024/smaller-weaker-yet-better-training-llm-reasoners-via-compute-optimal-sampling/">Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling</a> </td> </tr> <tr> <th scope="row">Sep 09, 2024</th> <td> <a class="post-link" href="/blog/2024/jailbreak-in-pieces-compositional-adversarial-attacks-on-multi/">Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models</a> </td> </tr> <tr> <th scope="row">Sep 09, 2024</th> <td> <a class="post-link" href="/blog/2024/jailbreak-in-pieces-compositional-adversarial-attacks-on-multi-modal-language-models/">Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models</a> </td> </tr> <tr> <th scope="row">Sep 02, 2024</th> <td> <a class="post-link" href="/blog/2024/many-shot-jailbreaking/">Many-shot jailbreaking</a> </td> </tr> <tr> <th scope="row">Sep 02, 2024</th> <td> <a class="post-link" href="/blog/2024/llm2vec-large-language-models-are-secretly-powerful-text/">LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders</a> </td> </tr> <tr> <th scope="row">Sep 02, 2024</th> <td> <a class="post-link" href="/blog/2024/llm2vec-large-language-models-are-secretly-powerful-text-encoders/">LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders</a> </td> </tr> <tr> <th scope="row">Aug 20, 2024</th> <td> <a class="post-link" href="/blog/2024/knowledge-augmented-reasoning-distillation-for-small-language-models/">Knowledge-Augmented Reasoning distillation for Small Language Models in Knowledge-Intensive Tasks (KARD)</a> </td> </tr> <tr> <th scope="row">Aug 20, 2024</th> <td> <a class="post-link" href="/blog/2024/knowledge-augmented-reasoning-distillation-for-small-language-models-in-knowledge-intensive-tasks-kard/">Knowledge-Augmented Reasoning distillation for Small Language Models in Knowledge-Intensive Tasks (KARD)</a> </td> </tr> <tr> <th scope="row">Aug 13, 2024</th> <td> <a class="post-link" href="/blog/2024/physics-of-language-models-part-21-grade-school/">Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process</a> </td> </tr> <tr> <th scope="row">Aug 13, 2024</th> <td> <a class="post-link" href="/blog/2024/physics-of-language-models-part-21-grade-school-math-and-the-hidden-reasoning-process/">Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process</a> </td> </tr> <tr> <th scope="row">Aug 13, 2024</th> <td> <a class="post-link" href="/blog/2024/knowledge-conflict-survey/">Knowledge conflict survey</a> </td> </tr> <tr> <th scope="row">Jul 30, 2024</th> <td> <a class="post-link" href="/blog/2024/in-context-retrieval-augmented-language-models/">In-Context Retrieval-Augmented Language Models</a> </td> </tr> <tr> <th scope="row">Jul 23, 2024</th> <td> <a class="post-link" href="/blog/2024/training-large-language-models-for-reasoning-through-reverse/">Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning</a> </td> </tr> <tr> <th scope="row">Jul 23, 2024</th> <td> <a class="post-link" href="/blog/2024/training-large-language-models-for-reasoning-through-reverse-curriculum-reinforcement-learning/">Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning</a> </td> </tr> <tr> <th scope="row">Jul 23, 2024</th> <td> <a class="post-link" href="/blog/2024/step-dpo-step-wise-preference-optimization-for-long/">Step-DPO : Step-wise preference optimization for long-chain reasoning of LLMs</a> </td> </tr> <tr> <th scope="row">Jul 23, 2024</th> <td> <a class="post-link" href="/blog/2024/step-dpo-step-wise-preference-optimization-for-long-chain-reasoning-of-llms/">Step-DPO : Step-wise preference optimization for long-chain reasoning of LLMs</a> </td> </tr> <tr> <th scope="row">Jul 02, 2024</th> <td> <a class="post-link" href="/blog/2024/rl-jack-reinforcement-learning-powered-black-box-jailbreaking/">RL-JACK: Reinforcement Learning-powered Black-box Jailbreaking Attack against LLMs</a> </td> </tr> <tr> <th scope="row">Jul 02, 2024</th> <td> <a class="post-link" href="/blog/2024/rl-jack-reinforcement-learning-powered-black-box-jailbreaking-attack-against-llms/">RL-JACK: Reinforcement Learning-powered Black-box Jailbreaking Attack against LLMs</a> </td> </tr> <tr> <th scope="row">Jul 02, 2024</th> <td> <a class="post-link" href="/blog/2024/gecko-versatile-text-embeddings-distilled-from-large-language-models/">Gecko: Versatile Text Embeddings Distilled from Large Language Models</a> </td> </tr> <tr> <th scope="row">Jun 11, 2024</th> <td> <a class="post-link" href="/blog/2024/scaling-monosemanticity-extracting-interpretable-features-from-claude-3/">Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet</a> </td> </tr> <tr> <th scope="row">Jun 11, 2024</th> <td> <a class="post-link" href="/blog/2024/does-fine-tuning-llms-on-new-knowledge-encourage/">Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?</a> </td> </tr> <tr> <th scope="row">Jun 11, 2024</th> <td> <a class="post-link" href="/blog/2024/does-fine-tuning-llms-on-new-knowledge-encourage-hallucinations/">Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?</a> </td> </tr> <tr> <th scope="row">Jun 11, 2024</th> <td> <a class="post-link" href="/blog/2024/contextual-position-encoding-learning-to-count-whats-important/">Contextual Position Encoding: Learning to Count What’s Important</a> </td> </tr> <tr> <th scope="row">Jun 04, 2024</th> <td> <a class="post-link" href="/blog/2024/stacking-your-transformers-a-closer-look-at-model/">Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training</a> </td> </tr> <tr> <th scope="row">Jun 04, 2024</th> <td> <a class="post-link" href="/blog/2024/stacking-your-transformers-a-closer-look-at-model-growth-for-efficient-llm-pre-training/">Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training</a> </td> </tr> <tr> <th scope="row">May 27, 2024</th> <td> <a class="post-link" href="/blog/2024/understanding-the-performance-gap-between-online-and-offline/">Understanding the performance gap between online and offline alignment algorithms</a> </td> </tr> <tr> <th scope="row">May 21, 2024</th> <td> <a class="post-link" href="/blog/2024/llama-pro-progressive-llama-with-block-expansion/">LLAMA PRO: Progressive LLaMA with Block Expansion</a> </td> </tr> <tr> <th scope="row">May 07, 2024</th> <td> <a class="post-link" href="/blog/2024/how-to-train-llm-from-data/">How to Train LLM? - From Data Parallel To Fully Sharded Data Parallel</a> </td> </tr> <tr> <th scope="row">May 07, 2024</th> <td> <a class="post-link" href="/blog/2024/how-to-train-llm-from-data-parallel-to-fully-sharded-data-parallel/">How to Train LLM? - From Data Parallel To Fully Sharded Data Parallel</a> </td> </tr> <tr> <th scope="row">May 07, 2024</th> <td> <a class="post-link" href="/blog/2024/how-to-inference-big-llm-using/">How to Inference Big LLM? - Using Accelerate Library</a> </td> </tr> <tr> <th scope="row">May 07, 2024</th> <td> <a class="post-link" href="/blog/2024/how-to-inference-big-llm-using-accelerate-library/">How to Inference Big LLM? - Using Accelerate Library</a> </td> </tr> <tr> <th scope="row">Apr 30, 2024</th> <td> <a class="post-link" href="/blog/2024/many-shot-in-context-learning/">Many-Shot In-Context Learning</a> </td> </tr> <tr> <th scope="row">Apr 23, 2024</th> <td> <a class="post-link" href="/blog/2024/exploring-concept-depth-how-large-language-models-acquire/">Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?</a> </td> </tr> <tr> <th scope="row">Apr 23, 2024</th> <td> <a class="post-link" href="/blog/2024/exploring-concept-depth-how-large-language-models-acquire-knowledge-at-different-layers/">Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?</a> </td> </tr> <tr> <th scope="row">Apr 16, 2024</th> <td> <a class="post-link" href="/blog/2024/understanding-emergent-abilities-of-language-models-from-the/">Understanding Emergent Abilities of Language Models from the Loss Perspective</a> </td> </tr> <tr> <th scope="row">Apr 16, 2024</th> <td> <a class="post-link" href="/blog/2024/understanding-emergent-abilities-of-language-models-from-the-loss-perspective/">Understanding Emergent Abilities of Language Models from the Loss Perspective</a> </td> </tr> <tr> <th scope="row">Apr 13, 2024</th> <td> <a class="post-link" href="/blog/2024/scaling-laws-for-data-filtering-data-curation-cannot/">Scaling Laws for Data Filtering— Data Curation cannot be Compute Agnostic</a> </td> </tr> <tr> <th scope="row">Apr 02, 2024</th> <td> <a class="post-link" href="/blog/2024/preference-free-alignment-learning-with-regularized-relevance-reward/">Preference-free Alignment Learning with Regularized Relevance Reward</a> </td> </tr> <tr> <th scope="row">Mar 26, 2024</th> <td> <a class="post-link" href="/blog/2024/search-in-the-chain-interactively-enhancing-large-language/">Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks</a> </td> </tr> <tr> <th scope="row">Mar 26, 2024</th> <td> <a class="post-link" href="/blog/2024/search-in-the-chain-interactively-enhancing-large-language-models-with-search-for-knowledge-intensive-tasks/">Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks</a> </td> </tr> <tr> <th scope="row">Mar 19, 2024</th> <td> <a class="post-link" href="/blog/2024/unveiling-the-generalization-power-of-fine-tuned-large/">Unveiling the Generalization Power of Fine-Tuned Large Language Models</a> </td> </tr> <tr> <th scope="row">Mar 19, 2024</th> <td> <a class="post-link" href="/blog/2024/unveiling-the-generalization-power-of-fine-tuned-large-language-models/">Unveiling the Generalization Power of Fine-Tuned Large Language Models</a> </td> </tr> <tr> <th scope="row">Mar 19, 2024</th> <td> <a class="post-link" href="/blog/2024/mm1-methods-analysis-insights-from-multimodal-llm-pre-training/">MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training</a> </td> </tr> <tr> <th scope="row">Mar 12, 2024</th> <td> <a class="post-link" href="/blog/2024/a-simple-and-effective-pruning-approach-for-large/">A Simple and Effective Pruning Approach for Large Language Models</a> </td> </tr> <tr> <th scope="row">Mar 12, 2024</th> <td> <a class="post-link" href="/blog/2024/a-simple-and-effective-pruning-approach-for-large-language-models/">A Simple and Effective Pruning Approach for Large Language Models</a> </td> </tr> <tr> <th scope="row">Mar 11, 2024</th> <td> <a class="post-link" href="/blog/2024/bitnet-scaling-1-bit-transformers-for-large-language/">BitNet: Scaling 1-bit Transformers for Large Language Models</a> </td> </tr> <tr> <th scope="row">Mar 11, 2024</th> <td> <a class="post-link" href="/blog/2024/bitnet-scaling-1-bit-transformers-for-large-language-models/">BitNet: Scaling 1-bit Transformers for Large Language Models</a> </td> </tr> <tr> <th scope="row">Mar 05, 2024</th> <td> <a class="post-link" href="/blog/2024/beyond-memorization-violating-privacy-via-inferencing-with-llms/">Beyond Memorization: Violating Privacy Via Inferencing With LLMs</a> </td> </tr> <tr> <th scope="row">Feb 27, 2024</th> <td> <a class="post-link" href="/blog/2024/self-rag-learning-to-retrieve-generate-and-critique/">SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION</a> </td> </tr> <tr> <th scope="row">Feb 20, 2024</th> <td> <a class="post-link" href="/blog/2024/wikichat-stopping-the-hallucination-of-large-language-model/">WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia</a> </td> </tr> <tr> <th scope="row">Feb 20, 2024</th> <td> <a class="post-link" href="/blog/2024/wikichat-stopping-the-hallucination-of-large-language-model-chatbots-by-few-shot-grounding-on-wikipedia/">WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia</a> </td> </tr> <tr> <th scope="row">Feb 20, 2024</th> <td> <a class="post-link" href="/blog/2024/knowledge-card-filling-llms-knowledge-gaps-with-plug/">KNOWLEDGE CARD: FILLING LLMS’ KNOWLEDGE GAPS WITH PLUG-IN SPECIALIZED LANGUAGE MODELS</a> </td> </tr> <tr> <th scope="row">Feb 20, 2024</th> <td> <a class="post-link" href="/blog/2024/knowledge-card-filling-llms-knowledge-gaps-with-plug-in-specialized-language-models/">KNOWLEDGE CARD: FILLING LLMS’ KNOWLEDGE GAPS WITH PLUG-IN SPECIALIZED LANGUAGE MODELS</a> </td> </tr> <tr> <th scope="row">Feb 13, 2024</th> <td> <a class="post-link" href="/blog/2024/llm-augmented-llms-expanding-capabilities-through-composition/">LLM AUGMENTED LLMS: EXPANDING CAPABILITIES THROUGH COMPOSITION</a> </td> </tr> <tr> <th scope="row">Feb 13, 2024</th> <td> <a class="post-link" href="/blog/2024/can-sensitive-information-be-deleted-from-llms-objectives/">CAN SENSITIVE INFORMATION BE DELETED FROM LLMS? OBJECTIVES FOR DEFENDING AGAINST EXTRACTION ATTACKS</a> </td> </tr> <tr> <th scope="row">Feb 06, 2024</th> <td> <a class="post-link" href="/blog/2024/self-rewarding-language-models/">Self-Rewarding Language Models</a> </td> </tr> <tr> <th scope="row">Jan 30, 2024</th> <td> <a class="post-link" href="/blog/2024/lion-adversarial-distillation-of-proprietary-large-language-models/">Lion: Adversarial Distillation of Proprietary Large Language Models</a> </td> </tr> <tr> <th scope="row">Jan 23, 2024</th> <td> <a class="post-link" href="/blog/2024/in-context-pretraining-language-modeling-beyond-document-boundaries/">IN-CONTEXT PRETRAINING: LANGUAGE MODELING BEYOND DOCUMENT BOUNDARIES</a> </td> </tr> <tr> <th scope="row">Jan 16, 2024</th> <td> <a class="post-link" href="/blog/2024/mistral-7b-mixtral-mixtral-of-experts/">Mistral 7B &amp; Mixtral (Mixtral of Experts)</a> </td> </tr> <tr> <th scope="row">Jan 16, 2024</th> <td> <a class="post-link" href="/blog/2024/benchmarking-cognitive-biases-in-large-language-models-as/">BENCHMARKING COGNITIVE BIASES IN LARGE LANGUAGE MODELS AS EVALUATORS</a> </td> </tr> <tr> <th scope="row">Jan 09, 2024</th> <td> <a class="post-link" href="/blog/2024/making-large-language-models-a-better-foundation-for/">Making Large Language Models A Better Foundation For Dense Retrieval</a> </td> </tr> <tr> <th scope="row">Jan 03, 2024</th> <td> <a class="post-link" href="/blog/2024/vllm-easy-fast-and-cheap-llm-serving-with/">vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention</a> </td> </tr> <tr> <th scope="row">Jan 02, 2024</th> <td> <a class="post-link" href="/blog/2024/detecting-pretraining-data-from-large-language-models/">DETECTING PRETRAINING DATA FROM LARGE LANGUAGE MODELS</a> </td> </tr> <tr> <th scope="row">Dec 26, 2023</th> <td> <a class="post-link" href="/blog/2023/are-emergent-abilities-of-large-language-models-a/">Are Emergent Abilities of Large Language Models a Mirage?</a> </td> </tr> <tr> <th scope="row">Dec 19, 2023</th> <td> <a class="post-link" href="/blog/2023/break-the-sequential-dependency-of-llm-inference-using/">Break the Sequential Dependency of LLM Inference Using Lookahead Decoding</a> </td> </tr> <tr> <th scope="row">Dec 12, 2023</th> <td> <a class="post-link" href="/blog/2023/label-words-are-anchors-an-information-flow-perspective/">Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning</a> </td> </tr> <tr> <th scope="row">Oct 31, 2023</th> <td> <a class="post-link" href="/blog/2023/in-context-learning-learns-label-relationships-but-is/">In-Context Learning Learns Label Relationships but Is Not Conventional Learning</a> </td> </tr> <tr> <th scope="row">Oct 31, 2023</th> <td> <a class="post-link" href="/blog/2023/efficient-streaming-language-models-with-attention-sinks/">EFFICIENT STREAMING LANGUAGE MODELS WITH ATTENTION SINKS</a> </td> </tr> <tr> <th scope="row">Oct 31, 2023</th> <td> <a class="post-link" href="/blog/2023/a-survey-on-large-language-model-based-autonomous/">A Survey on Large Language Model based Autonomous Agents</a> </td> </tr> <tr> <th scope="row">Oct 10, 2023</th> <td> <a class="post-link" href="/blog/2023/longlora-efficient-fine-tuning-of-long-context-large/">LongLoRA: Efficient Fine-Tuning of Long-Context Large Language Models</a> </td> </tr> <tr> <th scope="row">Oct 03, 2023</th> <td> <a class="post-link" href="/blog/2023/dola-decoding-by-contrasting-layers-improves-factuality-in/">DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models</a> </td> </tr> <tr> <th scope="row">Sep 19, 2023</th> <td> <a class="post-link" href="/blog/2023/large-language-models-as-optimizers/">LARGE LANGUAGE MODELS AS OPTIMIZERS</a> </td> </tr> <tr> <th scope="row">Sep 12, 2023</th> <td> <a class="post-link" href="/blog/2023/silo-language-models-isolating-legal-risk-in-a/">SILO LANGUAGE MODELS: ISOLATING LEGAL RISK IN A NONPARAMETRIC DATASTORE</a> </td> </tr> <tr> <th scope="row">Aug 29, 2023</th> <td> <a class="post-link" href="/blog/2023/code-llama-open-foundation-models-for-code/">Code Llama: Open Foundation Models for Code</a> </td> </tr> <tr> <th scope="row">Jun 29, 2023</th> <td> <a class="post-link" href="/blog/2023/qlora-eficient-finetuning-of-quantized-llms/">QLoRA: Eficient Finetuning of Quantized LLMs</a> </td> </tr> <tr> <th scope="row">Jun 22, 2023</th> <td> <a class="post-link" href="/blog/2023/the-false-promise-of-imitating-proprietary-llms/">The False Promise of Imitating Proprietary LLMs</a> </td> </tr> <tr> <th scope="row">May 25, 2023</th> <td> <a class="post-link" href="/blog/2023/rethinking-the-role-of-demonstrations-what-makes-in/">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?</a> </td> </tr> <tr> <th scope="row">Apr 27, 2023</th> <td> <a class="post-link" href="/blog/2023/automatic-chain-of-thought-prompting-in-large-language-models/">Automatic chain of thought prompting in large language models</a> </td> </tr> <tr> <th scope="row">Jan 26, 2023</th> <td> <a class="post-link" href="/blog/2023/task-aware-retrieval-with-instructions/">Task-aware Retrieval with Instructions</a> </td> </tr> <tr> <th scope="row">Jan 12, 2023</th> <td> <a class="post-link" href="/blog/2023/a-survey-for-in-context-learning/">A Survey for In-context Learning</a> </td> </tr> </table> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>