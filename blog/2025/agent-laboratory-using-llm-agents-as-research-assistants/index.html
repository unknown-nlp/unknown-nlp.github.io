<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Agent Laboratory: Using LLM Agents as Research Assistants | Unknown NLP Papers </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content="논문 리뷰"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknownnlp.github.io/blog/2025/agent-laboratory-using-llm-agents-as-research-assistants/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Papers </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Agent Laboratory: Using LLM Agents as Research Assistants</h1> <p class="post-meta"> Created on January 21, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/gpt"> <i class="fa-solid fa-hashtag fa-sm"></i> gpt</a>   <a href="/blog/tag/language-model"> <i class="fa-solid fa-hashtag fa-sm"></i> language-model</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   <a href="/blog/tag/transformer"> <i class="fa-solid fa-hashtag fa-sm"></i> transformer</a>   ·   <a href="/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2025-01-21</li> <li> <strong>Reviewer</strong>: 상엽</li> </ul> <h1 id="introduction">Introduction</h1> <p>사람의 자원 한계로 인해 탐색할 수 없는 많은 리서치 분야가 있음.</p> <p>LLM을 활용한 자동화를 통해 리서치 탐색의 영역을 획기적으로 늘릴 수 있음.</p> <ul> <li> <p><strong>ResearchAgent (Baek et al. (2024))</strong></p> <ul> <li> <p>자동으로 리서치 아이디어, 방법론, 실험 디자인을 생성</p> </li> <li> <p>peer discussion 단계를 모방하기 위해 다수의 reviewing agent를 통해 feedback, refine 과정을 거침.</p> </li> <li> <p>human-aligned evaluation criteria를 이용해 output을 향상</p> </li> </ul> </li> <li> <p><strong>The AI Scientist (Lu et al. (2024a))</strong></p> <ul> <li> <p>fully automated paper generation</p> <ul> <li>리서치 아이디어 → 코드 작성 → 실험 실행 → 페이퍼 작성 → peer-review를 통한 평가</li> </ul> </li> </ul> </li> </ul> <p>→ Si et al. (2024)</p> <ul> <li> <p>위의 방법들이 새로운 아이디어를 제시한다고 할지라도 detail과 feasibility에서 여전한 한계점 존재</p> </li> <li> <p>사람을 완전히 대체하기 보다는 사람의 idea를 상호보완적으로 발전시키는 역할을 하는 것을 제안</p> </li> </ul> <p><strong>Agent Laboratory</strong></p> <ul> <li> <p>Human idea + LLM을 활용한 보조 (사람의 feedback level은 다양하게 가능!)</p> </li> <li> <p>Human research idea → research report &amp; code repository</p> </li> </ul> <p><strong>Contribution</strong></p> <ol> <li> <p>개인의 리서치 역량을 향상시킬 수 있는 <strong>오픈소스 LLM 모델 제공</strong> (다양한 compute 레벨 지원)</p> </li> <li> <p>사람 평가 결과 (실험 및 리포트 quality, 유용성): <strong>o1-preview &gt; o1-mini &gt; gpt-4o</strong></p> </li> <li> <p>Neurips 점수 기준, 사람의 평가와 automated-evaluation의 점수 격차가 매우 컸음. → 평가를 위해서 <strong>Human feedback이 필수적</strong>임.</p> </li> <li> <p>Overall score: <strong>Co-pilot mode &gt; autonomous mode</strong>, Co-pilot 모드의 경우 experimental quality와 usefulness trade-off도 존재</p> </li> <li> <p>The co-pilot 모드는 <strong>utility와 usability에서 긍정적인 답변</strong>을 받았고 사람들은 향후에도 사용하고 싶어함.</p> </li> <li> <p>비용과 추론 시간에 대한 분석 수행, 기존 모델 대비 <strong>저렴한 비용</strong>으로 작업 수행</p> </li> <li> <p><strong>MLE-Bench에서 SOTA</strong> 성능을 보이는 mle-solver 제안</p> </li> </ol> <h1 id="agent-laboratory">Agent Laboratory</h1> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_000.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>3 Phases: (1) Literature Review, (2) Experimentation, and (3) Report Writing.</p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_001.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>role</p> </li> <li> <p>Task instruction</p> </li> <li> <p>command description</p> </li> <li> <p>context: 찾은 자료</p> </li> <li> <p>History: agent 행적</p> </li> <li> <p>…</p> </li> </ul> <h3 id="literature-review">Literature Review</h3> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_002.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Literature Review Phase</strong>: 다음 단계 레퍼런스를 위해 관련 리서치 논문을 찾는 작업.</p> <p>PhD agent: arXiv API를 활용해 아래 3가지 main actions을 수행.</p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_003.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p><strong><em>summary</em></strong>: agent에 의해 생성된 쿼리와 관련성이 높은 20개의 paper를 추출.</p> </li> <li> <p><strong><em>full text</em></strong>: paper의 전체 content를 추출.</p> </li> <li> <p><strong><em>add paper</em></strong>: summary와 full text를 이용해 curated review를 만듦.</p> </li> <li> <p>위의 과정은 반복적으로 실행 (다수의 쿼리를 이용)하며 매 스텝에서 selection을 진행하여 최종적으로 N_max의 레퍼런스가 확보되면 종료</p> </li> </ul> <h3 id="experimentation">Experimentation</h3> <p>**Plan Formulation phase: **literature review와 goal을 기반으로 하여 자세하고 실행가능한 리서치 계획을 세우는 작업</p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_004.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>PhD &amp; Postdoc agent: 대화를 통한 협업 진행</p> <ul> <li> <p>리서치 목표를 어떻게 달성할지에 대해 구체화</p> </li> <li> <p>실험 구성 요소에 대한 설계 (머신러닝 모델)</p> </li> <li> <p>어떤 데이터셋을 사용할 것인지 등</p> </li> </ul> <p>→ Consensus에 도달하면 Postdoc agent가 <strong>plan</strong> command를 실행하며 생성된 plan을 다음 단계로 전달</p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_005.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_006.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Data Preparation phase</strong></p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_007.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>목적: 실험 진행을 위한 데이터셋을 준비하는 코드를 작성</p> <p>ML Engineer</p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_008.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>**Python **command를 활용해 코드를 실행</p> </li> <li> <p>HuggingFace dataset에 접근해 검색 실행 (<strong>search HF</strong> command)</p> </li> </ul> <p>SW Engineer</p> <ul> <li> <p>code 최종 승인 후, **submit **command</p> </li> <li> <p>최종 승인 전 python compiler를 통해 코드 실행, compile 관련 에러가 없어질 때까지 반복 실행</p> </li> </ul> <p><strong>Running Experiments phase</strong></p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_009.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>ML Engineer: 이전 실험 계획을 수행하는 것이 목표</p> <p><strong>mle-solver 활용</strong>: 코드 생성, 테스트, 수정에 특화된 모듈</p> <ul> <li> <p>리서치 plan과 레퍼런스에서의 insight에 따라 initial code 작성 from scratch</p> </li> <li> <p>절차 (top scoring program: 성능이 가장 높은 파일을 기준으로 수정, 대체 작업을 하는 것)</p> <ol> <li>Command Execution</li> </ol> <ul> <li> <p>현재 단계에서 상위 성능 프로그램 (단일 파일, *.py)을 샘플링</p> </li> <li> <p><strong>EDIT</strong>: 라인 범위 지정 → 해당 라인의 코드를 다른 것으로 수정</p> </li> <li> <p><strong>REPLACE</strong>: 완전히 새로운 파일을 생성</p> </li> </ul> <ol> <li>Code Execution</li> </ol> <ul> <li> <p>compiler를 통해 런타임 에러 체크</p> </li> <li> <p>성공할 시, 스코어 측정, top score program 리스트 업데이트</p> </li> <li> <p>실패할 시, 코드 수정 N_{rep}=3번 도전 그래도 실패할 경우 replacement</p> </li> </ul> <ol> <li>Program Scoring</li> </ol> <ul> <li> <p>2단계 성공 시, scoring function을 이용해 해당 코드가 이전 단계의 코드보다 점수가 향상되었는지를 확인</p> </li> <li> <p>LLM을 활용해 mle-solver가 만든 코드의 효과성에 대해 scoring (0~1)</p> </li> </ul> <ol> <li>Self Reflection</li> </ol> <ul> <li> <p>성공, 실패 여부와 상관없이 reflection 실행, 액션의 결과에 대해 반영하라고 prompted</p> <ul> <li> <p>실패할 경우, 다음 단계에 어떻게 에러를 고칠 것이지에 대해 반영</p> </li> <li> <p>성공할 경우, 이것이 어떻게 점수를 향상시켰는지에 대해 반영</p> </li> </ul> </li> </ul> <ol> <li>Performance Stabilization</li> </ol> <ul> <li> <p>시스템 성능의 안정성을 위해 다음 두 가지 전략을 취함.</p> <ul> <li> <p>top program sampling: 위의 설명과 같음.</p> </li> <li> <p>Batch-parallelization: 각 step에서 N개를 동시에 생성, 최상위 1개만 남기는 방식 (Prompt 변화는 없는듯, temparature를 높게 가져감.)</p> </li> </ul> </li> </ul> </li> </ul> <p><strong>Results Interpretation</strong></p> <p>Phd &amp; Postdoc agent간 토론을 통해 실험 결과로부터 유의미한 인사이트를 추출</p> <h3 id="report-writing">Report Writing</h3> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_010.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Report Writing</strong></p> <p><strong>PhD &amp; Professor agent는 paper-solver를 활용해 최종 보고서를 작성하는 역할을 함.</strong></p> <p>완전한 논문을 작성하는 것은 아니며 이전 결과물들을 readable한 형태로 정리하고 보고서로 만드는 것이 목적</p> <ol> <li>Initial Report Scaffold</li> </ol> <ul> <li> <p>8개의 표준 섹션으로 구성 (Abstract, Introduction, Background, Related Work, Methods, Experimental Setup, Results, and Discussion)</p> </li> <li> <p>Latex format 관련 코드 포함, 각 섹션 별로 placeholder로 구성</p> </li> </ul> <ol> <li>Arxiv Research</li> </ol> <ul> <li>이전 단계와 같은 API를 활용 이전에 찾은 reference 외에 추가로 필요할 경우 선택적으로 활용</li> </ul> <ol> <li>Report Editing</li> </ol> <ul> <li> <p>실제 report를 작성하는 단계</p> </li> <li> <p><strong>EDIT</strong>: latex code를 line 단위로 수정하는 것, 반복적 수정을 통해 계속 글을 수정하여 만족할만한 quality까지 도달할 수 있음.</p> </li> <li> <p>latex compile을 통해 bug-free 보장</p> </li> </ul> <ol> <li>Paper Review</li> </ol> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_011.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_012.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>각 iteration을 돌 때 마다 글을 평가하기 위해 LLM을 활용한 자동화 된 리뷰 시스템을 활용</p> </li> <li> <p>Neurips 가이드라인을 기준으로 prompt를 구성</p> </li> <li> <p>ICLR 2022 논문을 평가할 시 인간 수준의 정확도를 보였음.</p> </li> </ul> <p><strong>Paper Refinement</strong></p> <p>세 명의 reviewer agent를 활용해 peer review 단계를 모방, 각각의 평가에 대해 분석 후 Phd agent는 작성을 완료할지 이전 단계로 돌아가 글을 수정할지를 결정</p> <h3 id="autonomous-vs-co-pilot-mode">Autonomous vs Co-Pilot Mode</h3> <ul> <li> <p>Autonomous mode: 사람은 연구 아이디어만 제공</p> </li> <li> <p>Co-Pilot mode: 사람은 각 subtask별로 리뷰를 진행</p> </li> </ul> <h1 id="results">Results</h1> <h2 id="autonomous-mode">Autonomous Mode</h2> <h3 id="글의-quality-평가"><strong>글의 Quality 평가</strong></h3> <p>experiment quality, report quality, usefulness 측면에서 사람 평가 진행</p> <ul> <li> <p><strong>Experimental Quality</strong>: What is your perception of the quality of the experimental results presented in this report?</p> </li> <li> <p><strong>Report Quality</strong>: What is your perception of the quality of the research report writing quality presented in this report?</p> </li> <li> <p><strong>Usefulness</strong>: What is your perception of the usefulness of an AI assistant tool that can generate the presented report autonomously?</p> </li> </ul> <p>이렇게 5개의 research question 활용</p> <ol> <li> <p>Do language models exhibit cognitive biases, such as confirmation bias or anchoring bias?</p> </li> <li> <p>Are image transformers more or less sensitive to pixel noise than convolutional networks?</p> </li> <li> <p>Do language models improve accuracy on MedQA when asked to perform differential diagnosis?</p> </li> <li> <p>Are language models sensitive to word order in multiple choice benchmarks?</p> </li> <li> <p>Does gender role play affect the accuracy on of language models on answering math questions?</p> </li> </ol> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_013.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>인간 개입 없이 Agent Laboratory 실험 진행</p> </li> <li> <p>10명의 PhD 학생들에게 각각 3개의 논문을 배정 후, 평가하게 함.</p> </li> </ul> <p>→ 모델별로 평가 결과가 상이함. o1-preview &gt; o1-mini » gpt-4o</p> <h3 id="human-reviewer-점수-평가">Human reviewer 점수 평가</h3> <ul> <li> <p>뉴립스 기준에 따라 사람과 LLM을 활용해 평가를 진행</p> </li> <li> <p>전체 점수는 o1-preview &gt; o1-mini &gt; gpt-4o 순으로 똑같은 결과</p> </li> <li> <p>전체 점수가 3.8로 뉴립스 합격자 평균인 5.9에는 미치지 못하는 상태</p> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_014.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>사람과 Automated reviewer와의 점수 비교 결과, 사람의 점수와 큰 차이를 보임.</p> </li> <li> <p>인간 평가가 필수적일듯…</p> </li> </ul> <h2 id="co-pilot-mode">Co-pilot Mode</h2> <p>o1-mini로 모든 실험 진행</p> <ul> <li> <p>custom: 자신이 선정한 연구 주제와 함께 Agent Laboratory를 활용</p> </li> <li> <p>preselected: 이전 섹션에서 제시된 주제 중에 2가지를 골라서 Agent Laboratory를 활용</p> </li> </ul> <h3 id="quality-as-a-tool">Quality as a tool</h3> <p>report 생성 이후 아래 항목에 대해 설문 조사 진행</p> <ul> <li> <p>Utility: How useful is Agent Laboratory for assisting your research?</p> </li> <li> <p>Continuation: How likely are you to continue using Agent Laboratory for research?</p> </li> <li> <p>Satisfaction: How much did you enjoy using Agent Laboratory?</p> </li> <li> <p>Usability: How easy was it for you to build a project using Agent Laboratory?</p> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_015.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>Custom Topic이 Usability를 제외하고 더 높은 점수를 받음.</p> </li> <li> <p>Quality 측면에서는 Topic과 무관하게 autonomous o1-mini보다 낮음 점수를 기록 (이는 실험자의 의도를 Agent에게 실행시키는 방법에 어려움이 있어서라고 평가함. 자세한 논의는 뒤에서)</p> </li> <li> <p>추가 설문조사 결과: GUI 추가, 중간 결과 검사 기능 향상, 그림을 포함할 수 있는 옵션 추가, Literature review 단계 개선 등의 요청을 받음.</p> </li> </ul> <h3 id="evaluation-of-co-pilot-generated-papers">Evaluation of co-pilot generated papers</h3> <p><strong>Self-evaluation</strong></p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_016.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>내부 실험자 평가, autonomous mode보다 더 높은 점수를 보임.</p> </li> <li> <p>Overall score 3.8 → 4.13 (+0.33), o1-preview보다 좋은 성능</p> </li> <li> <p>Siginificance와 Contribution은 조금 감소 (-0.3, -0.1)</p> </li> </ul> <p><strong>External evaluation</strong></p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_017.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>외부 평가 결과 점수가 더 향상.</p> </li> <li> <p>Self-evaluation과 비교해도 대체로 상승했으나 Clarity 부분만 감소함.</p> </li> <li> <p>Custom topic과 Preselected topic간 점수 차이도 역전되는 현상 발생 (자체 평가자가 Preselected topic에 대해 조금 낮은 점수를 주는 경향)</p> </li> </ul> <h2 id="runtime-statistics">Runtime statistics</h2> <p><strong>Inference time</strong></p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_018.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>속도: gpt-4o » o1-mini » o1-preview</p> </li> <li> <p>주요 병목: Running Experiments, Report Writing</p> </li> </ul> <p><strong>Inference cost</strong></p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_019.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li>이전 연구에서 gpt-4o 비용이 $15였던 것에 비하면 저렴</li> </ul> <p><strong>Success Rate</strong></p> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_020.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>모든 모델이 전반적으로 높은 성공률을 가짐.</p> </li> <li> <p>Literature review가 가장 낮으며 Data Preparation은 역전이 되기도 함.</p> </li> </ul> <h3 id="evaluating-mle-solver-on-mle-bench">Evaluating mle-solver on MLE-Bench</h3> <figure> <picture> <img src="/assets/img/posts/2025-01-21-agent-laboratory-using-llm-agents-as-research-assistants/image_021.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>이전 평가에서는 ML 문제를 풀기 위한 solver에 대한 구체적 평가는 없었기 때문에 MLE-Bench의 10개 challenge를 이용해 4개의 solver들을 비교해봄.</p> </li> <li> <p>다른 모델의 경우 2시간 제한 안에 challenge를 클리어하지 못하는 경우도 있어 해당 부분은 결과에서 제외함.</p> </li> <li> <p>mle-solver가 가장 많은 메달을 땀. (금: 2, 은: 1, 동: 1), 6/10에서 median score를 넘음.</p> </li> </ul> <h1 id="limitations">Limitations</h1> <ul> <li> <p>벤치마크에서 사람과 거의 유사한 평가를 내리는 모델이라고 할지라도 Agent Laboratory 평가에서는 사람과 일치하지 않음.</p> </li> <li> <p>최종 논문이 아닌 사람과 협업을 위한 중간 report를 만드는 것이 목적임에도 Neurips 기준으로 휴리스틱 평가를 진행</p> </li> <li> <p>고정된 섹션 구조로 글을 작성함.</p> </li> <li> <p>오직 두 개의 그림만 그리게 설정되어 있음.</p> </li> <li> <p>repository 단위로 코드를 관리하지는 못함.</p> </li> <li> <p>gpt-4o와 같이 낮은 성능을 보이는 일부 모델에서 Hallucination이 발생했음.</p> </li> <li> <p>Common failure modes</p> <ul> <li> <p>Literature review 단계에서 summary command 사용 빈도가 너무 높음.</p> </li> <li> <p>Literature review 단계에서 context limit에 걸리는 경우가 발생</p> </li> <li> <p>mle-solver가 0% 성능을 보이는 경우도 빈번히 발생</p> </li> <li> <p>mle-solver가 0번 라인 위주로 수정하는 경우가 많아 replace가 더 효과적일 때가 많았음.</p> </li> <li> <p>mle-solver가 exit() 명령어를 사용하여 전체 시스템을 꺼버리는 경우가 존재</p> </li> <li> <p>mle-solver가 subprocess.run()을 사용하여 시스템 명령어를 사용하는 경우가 존재</p> </li> <li> <p>paper-solver가 arxiv api 활용 시 limit에 걸리는 경우가 많음.</p> </li> </ul> </li> </ul> <hr> <ul> <li> <p>할거면 다하지 중간 report를 만드는 게 목표라는 것이 조금 애매하다.</p> <ul> <li>limitation이라고는 하지만 비용이 다른 모델 대비 저렴한 것도 이것 때문 아닌가?</li> </ul> </li> <li> <p>기대한 것보다는 내용은 조금 없었던 거 같은데 그림이 귀여움.</p> </li> <li> <p>각 Phase 별로 모델을 섞는 것이 best가 아닐까?</p> </li> <li> <p>프롬프트를 포함한 모든 코드가 공개됨. (깔끔한듯, 생각보다 .py의 수도 적어서 쉽게 적용 가능할듯)</p> <ul> <li>돌려보니 결과가 좀 다른듯</li> </ul> </li> <li> <p>구글 Agent 백서: https://github.com/daiwk/collections/blob/master/assets/google-ai-agents-whitepaper.pdf</p> </li> </ul> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>