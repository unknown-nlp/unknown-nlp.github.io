<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="5EvH841dAH-gE3azIorT3dCfBA_7a3yppKdAm1JWne8"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The False Promise of Imitating Proprietary LLMs | Unknown NLP Lab </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content="논문 리뷰 - sLLM, LLM, Evaluation Metric 관련 연구"> <meta name="keywords" content="natural language processing, NLP, machine learning, artificial intelligence, research papers, academic collaboration, paper review, computational linguistics, deep learning, transformers, language models"> <meta property="og:site_name" content="Unknown NLP Lab"> <meta property="og:type" content="article"> <meta property="og:title" content="Unknown NLP Lab | The False Promise of Imitating Proprietary LLMs"> <meta property="og:url" content="https://unknownnlp.github.io/blog/2023/the-false-promise-of-imitating-proprietary-llms/"> <meta property="og:description" content="논문 리뷰 - sLLM, LLM, Evaluation Metric 관련 연구"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="The False Promise of Imitating Proprietary LLMs"> <meta name="twitter:description" content="논문 리뷰 - sLLM, LLM, Evaluation Metric 관련 연구"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Jeahee Kim"
        },
        "url": "https://unknownnlp.github.io/blog/2023/the-false-promise-of-imitating-proprietary-llms/",
        "@type": "BlogPosting",
        "description": "논문 리뷰 - sLLM, LLM, Evaluation Metric 관련 연구",
        "headline": "The False Promise of Imitating Proprietary LLMs",
        
        "sameAs": ["https://inspirehep.net/authors/1010907","https://scholar.google.com/citations?user=qc6CJjYAAAAJ","https://www.alberteinstein.com/"],
        
        "name": "Jeahee Kim",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknownnlp.github.io/blog/2023/the-false-promise-of-imitating-proprietary-llms/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The False Promise of Imitating Proprietary LLMs</h1> <p class="post-meta"> Created on June 22, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/evaluation-metric"> <i class="fa-solid fa-hashtag fa-sm"></i> evaluation metric</a>   <a href="/blog/tag/gpt"> <i class="fa-solid fa-hashtag fa-sm"></i> gpt</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   <a href="/blog/tag/rlhf"> <i class="fa-solid fa-hashtag fa-sm"></i> rlhf</a>   <a href="/blog/tag/sllm"> <i class="fa-solid fa-hashtag fa-sm"></i> sllm</a>   ·   <a href="/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2023-06-22</li> <li> <strong>Reviewer</strong>: 김재희</li> <li> <strong>Property</strong>: sLLM, LLM, Evaluation Metric</li> </ul> <hr> <hr> <h2 id="1-intro">1. Intro</h2> <blockquote> <p>단순히 데이터를 확보해서 sLLM을 SFT 방식으로 훈련하는 것은 <strong>정말로</strong> 모델이 해당 태스크에 대한 성능을 확보하지 못함.</p> </blockquote> <h3 id="sllm">sLLM</h3> <figure> <picture> <img src="/assets/img/posts/2023-06-22-the-false-promise-of-imitating-proprietary-llms/image_000.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>최근 LLaMA, Alpaca, Vicuna 등을 비롯해 정말 많은 sLLM들이 등장하고 있음</p> </li> <li> <p>해당 모델들이 가지는 임팩트는 다음과 같음</p> <ol> <li> <p>LLM 대비 작은(6b~40b) 크기</p> </li> <li> <p>학습에 필요한 데이터를 경제적으로 수집 가능</p> </li> <li> <p>학습 시 복잡한 RLHF 등을 수행하지 않고, SFT만으로 학습</p> </li> <li> <p>1 ~ 3에도 불구하고 LLM과 비슷하거나 다소 못미치는 성능</p> </li> </ol> </li> </ul> <h3 id="self-instuct">Self Instuct</h3> <figure> <picture> <img src="/assets/img/posts/2023-06-22-the-false-promise-of-imitating-proprietary-llms/image_001.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>특히 데이터 수집 시 Self Instruct 등의 방법론을 이용하는 것이 일반적</p> </li> <li> <p>Self Instruct는 공개된 LLM 서비스를 이용하여 데이터를 구축하는 방법론</p> </li> <li> <p>Self Instruct 기반 방법론을 분류하면 크게 두가지 흐름</p> <ol> <li> <p>저자들이 직접 작성한 초기 Prompt를 기반으로 LLM이 Prompt와 Output을 생성하는 방식</p> </li> <li> <p>사용자들이 본인이 작성한 Prompt와 LLM이 작성한 Output을 공개한 플랫폼에서 데이터를 수집하는 방식</p> </li> </ol> </li> <li> <p>두 방식 모두 결국 LLM의 지식을 Distillation 하는 방향</p> </li> </ul> <p>⇒ LLM의 Output을 모방하도록 학습하기 때문</p> <p>⇒ 본 논문에서는 sLLM을 Imitation Model이라고 부름</p> <h3 id="false-promise">False Promise</h3> <figure> <picture> <img src="/assets/img/posts/2023-06-22-the-false-promise-of-imitating-proprietary-llms/image_002.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>본 논문의 저자들은 이러한 SelfInstruct + SFT 방식으로 학습된 모델의 유효성에 대해 의문을 제기함</p> </li> <li> <p>이는 두가지 측면으로 구분</p> <ul> <li> <p>성능 : 위 그림에서도 볼 수 있듯이 sLLM은 LLM의 생성 스타일은 쉽게 모방하지만 실제 지식은 전혀 따라잡지 못하고 있음 (녹색 : 옳바른 생성, 노란색 : 애매한 생성, 빨간색 : 잘못된 생성)</p> </li> <li> <p>평가 방식 : 실제 Human Evaluation 시 사람들은 생성된 문장의 Factual Knowledge를 검증할 수 없음</p> </li> </ul> </li> </ul> <h3 id="contribution">Contribution</h3> <ul> <li> <p>본 논문은 이러한 최근 현상을 1) 지적하면서 2) sLLM 학습의 요소들을 분리하여 분석하고 3) 향후 sLLM 개선 연구의 방향에 대해 제안하고 있음</p> <ul> <li>숫자로 보이는 성능에 열광할 것이 아니라 분위기를 가라앉히고 다시 시작하자.</li> </ul> </li> </ul> <h2 id="2-evaluation">2. Evaluation</h2> <ul> <li> <p>해당 논문에서는 3가지 평가 방식 도입</p> </li> <li> <p>Metric : 기존 데이터셋에서 제공하는 Metric을 이용하여 평가</p> </li> <li> <p>GPT-4 : ChatGPT에게 Imitation Model과 ChatGPT가 생성한 문장을 입력하고, 선호도를 출력하도록 Prompt 구성</p> </li> <li> <p>Human : Amazon Turk를 이용하여 70명의 응답자에게 두 모델이 생성한 문장 중 더 나은 문장을 고르도록 요구</p> </li> </ul> <p>⇒ Metric 방식을 제외한 두 방식은 RLHF의 Reward Model과 비슷한 방식으로 진행</p> <p>⇒ Human과 GPT-4의 점수가 비슷한 경향을 보였다고 하는데, 자세한 내용은 소개 X</p> <blockquote> <p>해당 논문에서는 모든 데이터셋의 모든 평가 방식의 평균을 담고 있음</p> </blockquote> <h2 id="4-dataset">4. Dataset</h2> <ul> <li>본 논문에서는 두가지 목적에 따라 Dataset 구축을 구분하여 사용</li> </ul> <ol> <li> <p>Task-Speicific Imitation : 특정 태스트에 대해서 sLLM이 LLM의 성능을 따라잡도록 학습하기 위한 데이터셋 구축</p> </li> <li> <p>Self Instruct와 비슷하게 ChatGPT에게 In-Context 방식으로 Natural Questions 데이터에 대한 답변을 생성하여 구축</p> </li> <li> <p>Broad-coverage Imitation : 실제 LLM 서비스처럼 광범위한 태스크들을 수행할 수 있는 범용적 목적의 sLLM 학습을 위한 데이터셋 구축</p> </li> <li> <p>ShareGPT, HC3, Discord ChatGPT 채널 등 공개된 다양한 데이터셋 수집</p> </li> <li> <p>기존에 사용자들과 ChatGPT가 나눈 대화를 수집한 것</p> </li> <li> <p>해당 데이터를 모두 묶어 SharGPT-Mix라고 말함</p> </li> </ol> <ul> <li>SharGPT-Mix의 경우 기존에 연구목적으로 구축되었던 Prompt 데이터셋인 NaturalInstructions 보다 높은 품질을 가지고 있다고 주장</li> </ul> <p>⇒ 사용자 입력의 평균 BLEU 유사도가 8%에 불과</p> <hr> <h2 id="5-모델">5. 모델</h2> <ol> <li>Broad-Coverage Imatation</li> </ol> <figure> <picture> <img src="/assets/img/posts/2023-06-22-the-false-promise-of-imitating-proprietary-llms/image_003.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>특정 태스크에 대한 성능 측정</p> </li> <li> <p>학습 데이터의 크기와 모델 크기를 늘리는 실험 진행</p> <ul> <li> <p>학습 데이터의 크기를 늘렸을 때(위) : 놀랍게도 SFT 학습 데이터 크기를 늘린다고 성능이 개선되지 않았다.</p> </li> <li> <p>오히려 ShareGPT-Mix로 훈련되지 않은 기본 모델의 성능이 대부분의 경우 좋은 모습을 보이고 있다.</p> </li> </ul> </li> </ul> <p>⇒ ChatGPT 모델에 비해 턱없이 작은 크기의 모델로 인해 발생하는 문제로 추측</p> <p>⇒ ChatGPT 모델이 훨씬 더 많은 Knowledge를 내부 파라미터로 가지고 있기 때문에, 소수의 ShareGPT-Mix 데이터로 이러한 성능을 따라잡는 것은 불가능하다.</p> <ul> <li> <p>모델의 크기를 늘리는 실험 진행</p> <ul> <li>모델 크기가 커지면서 점차 성능이 나아지는 모습 관찰 가능</li> </ul> </li> </ul> <p>⇒ 학습 데이터 실험 결과와 맥락을 같이하는 결과</p> <p>⇒ base 모델이 가지고 있는 Knowledge가 많고, 성능이 우수해야 결국 General-Purpose 모델로 활용될 수 있음</p> <ol> <li>Broad Model - Broad Task</li> </ol> <figure> <picture> <img src="/assets/img/posts/2023-06-22-the-false-promise-of-imitating-proprietary-llms/image_004.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>General한 태스크에 대해 성능을 측정하기 위해 SharGPT-Mix 데이터셋의 일부를 평가 데이터로 사용</p> </li> <li> <p>학습 데이터 실험(좌)</p> <ul> <li> <p>학습 데이터셋의 크기가 늘어난다고 성능이 향상 되지는 않음</p> </li> <li> <p>다만, SFT를 이용한 Prompt 데이터에 대한 학습 여부는 성능에 큰 영향을 미침</p> </li> </ul> </li> <li> <p>모델 크기 실험(우)</p> <ul> <li>모델 크기가 커질수록 더 높은 성능을 달성하는</li> </ul> </li> </ul> <p>⇒ base 모델의 성능이 보장되어야 충분한 학습 효율을 달성할 수 있음</p> <ol> <li>Targeted Data에 대한 학습</li> </ol> <figure> <picture> <img src="/assets/img/posts/2023-06-22-the-false-promise-of-imitating-proprietary-llms/image_005.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>Taget 데이터와 범용(ShareGPT) 데이터로 학습한 실험 결과</p> <ul> <li> <p>ShareGPT 데이터로 학습한 모델보다 NQ 데이터로 학습된 모델이 훨씬 높은 성능을 보이고 있음</p> </li> <li> <p>1번 실험과 함께 생각해보면, 결국 범용적 목적의 모델로서 SFT는 좋은 선택지는 아니지만, 특정 태스크에 대한 모델로서 SFT를 이용한 sLLM은 좋은 선택지가 될 수 있음</p> </li> </ul> </li> <li> <p>sLLM은 스타일을 학습</p> <ul> <li> <p>ShareGPT-Mix로 훈련된 모델에 대한 Toxity 평가(우)</p> </li> <li> <p>base 모델에 비해 향상된 모습을 보이고 있음</p> <ul> <li> <p>Toxity는 결국 스타일과 관련된 이야기</p> </li> <li> <p>욕설, 문장 길이, 답변이 불가능한 Prompt 등</p> </li> </ul> </li> <li> <p>ChatGPT가 학습한 이러한 스타일을 모델은 잘 학습하는 모습</p> <ul> <li>특히 학습 데이터가 커질수록 이러한 스타일은 지속적으로 학습하는 모습을 보이고 있음</li> </ul> </li> </ul> </li> </ul> <h2 id="6-결론">6. 결론</h2> <ul> <li>요약하면 결국 : 범용 목적의 모델은 아직 sLLM으로 도달할 수 있는지 의문이다.</li> </ul> <p>⇒ 하지만 특정 태스크를 위한 모델은 충분히 sLLM으로 개발이 가능하다.</p> <ul> <li> <p>Human Evaluation에 대한 문제점을 지적한 점은 좋은 듯</p> <ul> <li>하지만 이에 대한 구체적인 논리 및 증명이 부족한 상황</li> </ul> </li> <li> <p>base 모델의 성능이 좋아야 Imitation 자체가 잘 진행된다고 귀결됨</p> <ul> <li>모델의 크기를 늘리지 않으면서 기본 성능을 올릴 수 있는 방법이 있는가…?</li> </ul> </li> <li> <p>LLM 개발하는 대기업 측면에서 오히려 걱정할 지점이 많아진다고 생각</p> <ul> <li>Safety를 위해 열심히 개발했더니, 단순히 SFT를 통해 따라잡을 수 있다.</li> </ul> </li> </ul> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>