<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Learning to Tokenize for Generative Retrieval | Unknown NLP Lab </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content="논문 리뷰 - Retrieval 관련 연구"> <meta name="keywords" content="natural language processing, NLP, machine learning, artificial intelligence, research papers, academic collaboration, paper review, computational linguistics, deep learning, transformers, language models"> <meta property="og:site_name" content="Unknown NLP Lab"> <meta property="og:type" content="article"> <meta property="og:title" content="Unknown NLP Lab | Learning to Tokenize for Generative Retrieval"> <meta property="og:url" content="https://unknownnlp.github.io/blog/2023/learning-to-tokenize-for-generative-retrieval/"> <meta property="og:description" content="논문 리뷰 - Retrieval 관련 연구"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Learning to Tokenize for Generative Retrieval"> <meta name="twitter:description" content="논문 리뷰 - Retrieval 관련 연구"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Jeahee Kim"
        },
        "url": "https://unknownnlp.github.io/blog/2023/learning-to-tokenize-for-generative-retrieval/",
        "@type": "BlogPosting",
        "description": "논문 리뷰 - Retrieval 관련 연구",
        "headline": "Learning to Tokenize for Generative Retrieval",
        
        "sameAs": ["https://inspirehep.net/authors/1010907","https://scholar.google.com/citations?user=qc6CJjYAAAAJ","https://www.alberteinstein.com/"],
        
        "name": "Jeahee Kim",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknownnlp.github.io/blog/2023/learning-to-tokenize-for-generative-retrieval/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Learning to Tokenize for Generative Retrieval</h1> <p class="post-meta"> Created on December 19, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/bert"> <i class="fa-solid fa-hashtag fa-sm"></i> bert</a>   <a href="/blog/tag/embedding"> <i class="fa-solid fa-hashtag fa-sm"></i> embedding</a>   <a href="/blog/tag/generative"> <i class="fa-solid fa-hashtag fa-sm"></i> generative</a>   <a href="/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   <a href="/blog/tag/retrieval"> <i class="fa-solid fa-hashtag fa-sm"></i> retrieval</a>   <a href="/blog/tag/transformer"> <i class="fa-solid fa-hashtag fa-sm"></i> transformer</a>   ·   <a href="/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2023-12-19</li> <li> <strong>Reviewer</strong>: 건우 김</li> <li> <strong>Property</strong>: Retrieval</li> </ul> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_000.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h1 id="abstract">Abstract</h1> <ul> <li> <p>본 연구에서는 generative retrieval 계열의 방법으로 document semantics을 docids로 encoding하는 과정을 학습하는 GENRET을 소개함.</p> </li> <li> <p>당연하게도 GENRET는 IR에서 SOTA를 보이고, 특히 unseen doc에 있어 높은 성능 향상을 보임.</p> </li> </ul> <h1 id="introduction">Introduction</h1> <p>최근 Information Retrieval에서 generative retrieval을 활용하는 연구들이 많이 진행되고 있다. 우리가 흔히 알고 있는 dense retrieval 방법들과 다르게, generative retrieval은 end-to-end 방법으로 주어진 query에 대해 ranked list of docids를 LM이 생성하게 함.</p> <p>docid를 할당하는 것은 document가 semantic space에 어떻게 분포되어 있는지 정의하는 과정이기 때문에 중요함. 이전에는 주로 title 혹은 URL과 같은 meta data를 사용하거나 off-the-shelf document embedding에서 clustering 결과를 활용하는 rule-based 방법을 사용해서 training에서 본 것들에 대한 document들은 잘 retrieving 했지만, 이것들은 ad-hoc하고 generalize 못하다는 단점이 있다.</p> <p>위 문제를 해결하기 위해 연구를 진행함</p> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_001.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p><strong>GENRET</strong>: a document tokenization learning framework that learns to tokenize a document into semantic docids in a discrete auto-encoding scheme</p> <ul> <li> <p>shared seq2seq-based document tokenization model</p> </li> <li> <p>generative retrieval model</p> </li> <li> <p>reconstruction model</p> </li> </ul> </li> <li> <p>auto-encoding을 이용하여 generative retrieval model을 optimize하는데 아래와 같은 issue 존재</p> <ul> <li> <p>docids with an autoregressive nature</p> <ul> <li>이 문제를 해결하기 위해 progressive training scheme 제안</li> </ul> </li> <li> <p>docids with diversity</p> <ul> <li>이 문제를 해결하기 위해 parameter initialization strategy와 docid의 re-assignment 제안</li> </ul> </li> </ul> </li> <li> <p><strong>Contributions</strong></p> <ul> <li> <p>처음으로 tokenization learning method를 document retrieval에 적용한 GENRET 제안</p> </li> <li> <p>학습의 안정화를 위해 progressive training scheme 적용</p> </li> <li> <p>SOTA 달성 및 unseen documents에서도 잘 함 (dense retrieval baseline은 가볍게 부숨)</p> </li> </ul> </li> </ul> <h1 id="preliminaries">Preliminaries</h1> <p><strong>document tokenization</strong>: generative retrieval은 original document를 직접 생성하는 것은 길기 때문에 inefficient. document tokenization은 document를 sequence of discrete tokens (docid)로 표현함.</p> <ul> <li> <p>D: collection of documents</p> </li> <li> <p>d: each document</p> </li> <li> <table> <tbody> <tr> <td>d</td> <td>: total number of tokens in document</td> </tr> </tbody> </table> </li> <li> <p>M: length of docid</p> </li> <li> <p>z: sequence of discrete tokens (docid)</p> </li> <li> <p>z_t: K-way categorical variable</p> </li> <li>위 그림에서는 M=3, K=64인 case</li> </ul> <p>docid인 z는 아래 두가지 조건을 만족해야함.</p> <ol> <li> <p>different documents have short but different docids</p> </li> <li> <p>docids capture the semantics of their associated documents as much as possible</p> </li> </ol> <p><strong>Tokenization model</strong>: Q:d\to z, document d를 docid z로 mapping</p> <p><strong>Generative retrieval model: **</strong>P:q \to z****, **query q와 관련된 문서 docid z를 autoregressive하게 생성하며 학습함</p> <h1 id="method">Method</h1> <p>document tokenization은 주로 fixed pre-processing step으로 사용됨</p> <ul> <li>e.g.) document의 title이나 BERT로 얻은 hierarchical clustering results</li> </ul> <p>→ 이런 ad-hoc한 방법은 document의 semantic을 잘 잡아내지 못한다는 단점이 존재함.</p> <ul> <li> <p>web page의 title이 없는 경우</p> </li> <li> <p>web page title의 의미가 page contetn랑 관련이 적은 경우</p> </li> <li> <p>clustering-based docids가 document를 discrete space에서 정의하는 경우</p> </li> </ul> <p><strong>GENRET</strong>: Semantic docid를 학습하는 discrete auto-encoding 기반의 tokenization leraning method</p> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_002.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>크게 세가지 components로 구성이 됨</p> <ol> <li> <table> <tbody> <tr> <td> <strong>seq2seq based retrieval model: **</strong>P(z</td> <td>q)**</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td> <strong>document tokenization model: **</strong>Q(z</td> <td>d)**</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td> <strong>reconstruction model: **</strong>R(d</td> <td>z)**</td> </tr> </tbody> </table> </li> </ol> <h3 id="overview-process"><strong>Overview process</strong></h3> <p>→ document tokenization model Q가 document d를 unique discrete variables z로 변환시키고, retrieval model P가 given query q에 대해 z를 생성하도록 학습이됨. 추가로 Reconstruction model R은 docid z에서 original document를 생성하도록 학습이됨 (original document의 semantic을 파악하기 위해)</p> <h2 id="architecture">Architecture</h2> <h3 id="document-tokenization-model">Document Tokenization Model</h3> <ul> <li> <p>enc-dec Transformer: input text d가 있을 때, T5-based tokenization model이 d와 a prefix of docid z_{&lt;t}를 인코딩하여 hidden latent vector d_t 생성.</p> <ul> <li>D: hidden size of model</li> </ul> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_003.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>tokenization model은 d_t를 기반으로 각 document에 대한 token을 생성</p> </li> <li> <p>각 timestep t 마다, codebook을 정의해줌</p> <ul> <li> <p>E_t^{K*D}: E는 external embedding matrix (codebook)을 의미하고 K는 discrete latent space의 size를 의미함</p> </li> <li> <p>e_{t,j} \isin R^D, j \isin [K]: K개의 embedding vectors</p> </li> </ul> </li> <li> <p>codebook embedding matrix E_t와 latent vector d_t를 dot-prodcut softmax 취하여 j \isin [K]에 대한 t 시점에서의 확률값 계산,</p> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_004.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="reconstruction-model">Reconstruction Model</h3> <ul> <li> <p>tokenization model Q가 생성한 docid는 semantic 정보를 담아야하기에, auto-encoding training scheme 사용</p> <ul> <li>R: z \to d는 Q: d \to z 로 하여금 original document로 reconstruct할 수 있는 z를 만들게 함</li> </ul> </li> <li> <p>Input: docid z</p> <ul> <li>embed z into representation matrix z={(z_1,…z_M) \isin R^{M*D}} (tokenization model에서 사용한 codebook)</li> </ul> </li> </ul> <p>→ 아래와 같이 표현</p> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_005.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li>output: document d</li> </ul> <h3 id="retrieval-based-reconstruction-model">Retrieval-based reconstruction model</h3> <ul> <li>docid z와 target document d 간의 relevance score는 다음과 같이 정의함</li> </ul> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_006.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>S(z<em>{&lt;t}): z</em>{&lt;t}와 동일한 docid prefix를 갖는 sub-collection of D</p> </li> <li> <p>d^* \isin S(z<em>{&lt;t}): sub-collection S(z</em>{&lt;t})에 있는 document</p> </li> <li> <p>d_t,d_t^{t}: representation vectors</p> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_007.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li>sg(*): stop gradient operator (gradient back propagation 방지)</li> </ul> <table> <tbody> <tr> <td>→ R(d</td> <td>z)는 S(z<em>{&lt;t})에서 각 timestep t 마다 특정 document를 retrieve함. 이 score를 활용한 loss function은, model로 하여금 previous docid z</em>{&lt;t}에서 잡지 못한 residual semnatics을 학습할 수 있게 해줌.</td> </tr> </tbody> </table> <h2 id="optimization">Optimization</h2> <p>Document tokenization model, generative retrieval model, reconstruction model을 한 번에 auto-encoding을 활용하여 학습시키기에는 다음과 같은 이유로 어렵다.</p> <ol> <li> <p><strong>Learning docids in an autoregressive fashion</strong></p> </li> <li> <p>t 시점의 z<em>t를 생성할 때는 previously predicted docids z</em>{&lt;t}를 이용해야하는데, 학습 초반에는 under-optimizaed 되어 있어 학습이 어려움</p> </li> <li> <p>z를 simultaneously optmize시키면 unique docid를 할당하는 것에 있어 어려울 수 있음</p> </li> </ol> <p>→ GENRET 학습을 안정화 시키기 위해 <em>progressive training scheme</em> 제안</p> <ol> <li> <p><strong>Generating docids with diversity</strong></p> </li> <li> <p>auto-encdoing으로 학습하면 unbalanced docid assignment가 될 수 있음 → model distinguishability에 영향을 줌 (잘못되면 docids의 길이가 너무 길어지는 문제가 생김)</p> </li> </ol> <p>→ docid diversity를 위해 2가지 <em>diverse clustering techniques</em> 제안</p> <h3 id="progressive-training-scheme">Progressive training scheme</h3> <ul> <li>M번의 learning steps을 갖는 전체 learning scheme에서 docid z_T은 T \isin [M] 시점에 학습이 됨. 이후 시점에서는 이전 시점의 docid z_T와 parameters들은 fixed됨.</li> </ul> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_008.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>아래 3가지 loss function을 통해 학습이 이루어짐</p> <ul> <li>**Reconstruction Loss: **Reconstruction model R을 활용</li> </ul> </li> </ul> <p>→ main goal: docid를 생성할때 semantic 정보를 최대한 많이 담기위해 auxiliary model로 사용</p> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_009.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- 위 수식에서 non-differentiable operation (argmax)가 존재하여 straight-through gradient estimation을 사용
</code></pre></div></div> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_010.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li>**Commitment Loss: **Tokenization model Q 사용</li> </ul> <p>→ main goal: predicted docid가 embedding에 대응되고, previous docid를 까먹지 않기 위해</p> <p>(말은 이렇게 해도 걍 docid 생성하도록 학습하는 Cross Entropy Loss)</p> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_011.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li>**Retrieval Loss: **Generative retrieval model P 사용 + Q를 함께 사용</li> </ul> <p>→ main goal: P가 query q가 들어올때 관련 documents d의 docids를 생성하는 것을 학습</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- (q,d) pair 주어지고 아래와 같이 loss 정의

- q_T, d_T,d_T^*: query, document, in-batch document의 latent vector
</code></pre></div></div> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_012.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- first term: ranking-oriented loss

- second term: CE loss, generating docid z based on q
</code></pre></div></div> <p>→ step-T에서 final loss는 아래와 정리됨</p> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_013.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="diverse-clustering-techniques">Diverse clustering techniques</h3> <p>docids의 diversity를 보장하기 위해 아래 두가지 clustering techniques을 각 progressive training step에 적용함.</p> <ol> <li><strong>Codebook Initialization</strong></li> </ol> <p>→ main goal: increase the balance of semantic space segmentation</p> <p>(MEMTO와 거의 판박이로 비슷함ㅋㅋ)</p> <ol> <li> <p>warm-up: docid representation z_T을 사용하지 않고 d_T를 바로 reconstruction model에 사용</p> </li> <li> <p>L(Rec) + L(Com)만 사용함</p> </li> <li> <p>documents에 대한 continuous vectors d_T 수집후 → K groups으로 clustering (Constrained K-Means)</p> </li> <li> <p>cluster의 각 centroid는 codebook E_T를 initialize하는데 사용</p> </li> <li> <p><strong>Docid re-assignment</strong></p> </li> </ol> <p>→ main goal: increase the balacne of docid assignments</p> <p>아래 dot-product results를 modify하여 different doc에 대응하는 docid가 distinct하는 것을 보장</p> <ul> <li>D: continuous vectors of batch of documents</li> </ul> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_014.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>re-normalization vectors (u and v) 사용</p> <ul> <li>Sinkhorn-Knopp algorithm을 통해 u and v vecotrs가 계산됨</li> </ul> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_015.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li>calculated H*는 Softmax에 들어가 확률 생성</li> </ul> <h1 id="experimental-setup">Experimental Setup</h1> <ul> <li> <p>enc-dec: T5-base</p> </li> <li> <p>retrieval model과 tokenization model에 사용되는 enc-dec, codebook 각각은 shared</p> </li> <li> <p>K number of clusters: 512</p> </li> <li> <p>M length of docid: 문서의 개수에 따라 달라짐</p> </li> </ul> <h1 id="experimental-results">Experimental Results</h1> <h3 id="nq320k-results">NQ320K results</h3> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_016.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>strong pretrained retrieval GTR + previous SOTA in generative retrieval보다 우수한 성능 보임</p> </li> <li> <p>Seen + Unseen dataset에서 우수한 성능 보임</p> </li> </ul> <p>→ 실험 결과는 GENRET이 dense + generative retrieval의 장점을 결합한 방법임을 강조함</p> <h3 id="ms-marco--beir-results">MS MARCO + BEIR results</h3> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_017.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p><strong>MS MARCO</strong></p> <ul> <li> <p>URL이나 title같은 meta data를 사용하는 generative retrieval model인 GENRE, Ultron은 MS MARCO에서 NQ320K 대비 성능이 크게 하락함.</p> <ul> <li>NQ320K는 wikipedia를 retrieve해서 meta data가 content와 밀접하지만, MS MARCO는 web search dataset이기 때문</li> </ul> </li> <li> <p>그치만 semantic docids를 생성하도록 학습한 GENRE는 roboust한 성능을 보여줌</p> </li> </ul> </li> <li> <p><strong>BEIR</strong></p> <ul> <li> <p>특히 BM25가 잘하는 dataset인데, 보다 높은 성능을 보여줌</p> </li> <li> <p>title을 docid로 사용하는 generative retrieval model인 GENRE는 BEIR-Covid, BEIR-SciDocs에서 성능이 낮은데, 이는 documents의 titles이 content의 semantic을 담지 못함.</p> </li> </ul> </li> </ul> <h3 id="qualitative-analysis">Qualitative analysis</h3> <p>NQ320K dataset에서 GENRET이 생성한 docid에 대한 시각화</p> <ul> <li> <p>left: similar docids는 비슷한 content로 구성</p> <ul> <li>338-173 branch는 email과 관련된 내용</li> </ul> </li> <li> <p>right: same group에 들어가는 docid는 semantically하게 비슷함</p> <ul> <li>338에서 173이 추가되면, 더욱 email과 관련된 내용 포함</li> </ul> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_018.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h1 id="conclusion">Conclusion</h1> <p>본 연구에서 처음으로 generative retrieval 계열의 document tokenization learning method인 GENRET 소개함. 요약하면, generated docids가 semantics을 담게 설계된 auto-encoding 방식을 통해 documents를 discrete representations으로 tokenize하는 것을 학습함.</p> <p>Dense retrieval method 보다 안정적으로 높은 성능을 보이며, 특히 unseen dataset에서도 좋은 성능을 보인 것으로 미루어 보아 generative retrieval이 앞으로 IR에서 핵심 연구 주제가 되지 않을까 싶음</p> <p>더 짧은 docids로 학습 및 infer해서 효율적이지만, training process가 복잡해서 computation cost가 높을 것 같은데, 이 점에 대한 dense retreival method와 비교 실험이 없어서 아쉬움.</p> <p>이 아니고 appendix에 꼭 숨겨놨었네요</p> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_019.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>학습 속도는 느리긴 하지만, infer 속도는 가장 빠르다는 결론!</p> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_020.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_021.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_022.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <img src="/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_023.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>+MEMTO!</p> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>