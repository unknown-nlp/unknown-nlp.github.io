<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Learning to Tokenize for Generative Retrieval | You R. Name </title> <meta name="author" content="You R. Name"> <meta name="description" content="논문 리뷰 - Retrieval 관련 연구"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/al-folio/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/al-folio/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/al-folio/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/al-folio/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://alshedivat.github.io/al-folio/blog/2023/learning-to-tokenize-for-generative-retrieval/"> <script src="/al-folio/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/al-folio/"> <span class="font-weight-bold">You</span> R. Name </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/al-folio/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/al-folio/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/al-folio/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Learning to Tokenize for Generative Retrieval</h1> <p class="post-meta"> Created on December 19, 2023 </p> <p class="post-tags"> <a href="/al-folio/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/al-folio/blog/tag/embedding"> <i class="fa-solid fa-hashtag fa-sm"></i> embedding</a>   <a href="/al-folio/blog/tag/generative"> <i class="fa-solid fa-hashtag fa-sm"></i> generative</a>   <a href="/al-folio/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   <a href="/al-folio/blog/tag/retrieval"> <i class="fa-solid fa-hashtag fa-sm"></i> retrieval</a>   <a href="/al-folio/blog/tag/transformer"> <i class="fa-solid fa-hashtag fa-sm"></i> transformer</a>   ·   <a href="/al-folio/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2023-12-19</li> <li> <strong>Reviewer</strong>: 건우 김</li> <li> <strong>Property</strong>: Retrieval</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_000-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_000-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_000-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_000.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h1 id="abstract">Abstract</h1> <ul> <li> <p>본 연구에서는 generative retrieval 계열의 방법으로 document semantics을 docids로 encoding하는 과정을 학습하는 GENRET을 소개함.</p> </li> <li> <p>당연하게도 GENRET는 IR에서 SOTA를 보이고, 특히 unseen doc에 있어 높은 성능 향상을 보임.</p> </li> </ul> <h1 id="introduction">Introduction</h1> <p>최근 Information Retrieval에서 generative retrieval을 활용하는 연구들이 많이 진행되고 있다. 우리가 흔히 알고 있는 dense retrieval 방법들과 다르게, generative retrieval은 end-to-end 방법으로 주어진 query에 대해 ranked list of docids를 LM이 생성하게 함.</p> <p>docid를 할당하는 것은 document가 semantic space에 어떻게 분포되어 있는지 정의하는 과정이기 때문에 중요함. 이전에는 주로 title 혹은 URL과 같은 meta data를 사용하거나 off-the-shelf document embedding에서 clustering 결과를 활용하는 rule-based 방법을 사용해서 training에서 본 것들에 대한 document들은 잘 retrieving 했지만, 이것들은 ad-hoc하고 generalize 못하다는 단점이 있다.</p> <p>위 문제를 해결하기 위해 연구를 진행함</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_001-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_001-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_001-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_001.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p><strong>GENRET</strong>: a document tokenization learning framework that learns to tokenize a document into semantic docids in a discrete auto-encoding scheme</p> </li> <li> <p>auto-encoding을 이용하여 generative retrieval model을 optimize하는데 아래와 같은 issue 존재</p> </li> <li> <p><strong>Contributions</strong></p> </li> </ul> <h1 id="preliminaries">Preliminaries</h1> <p><strong>document tokenization</strong>: generative retrieval은 original document를 직접 생성하는 것은 길기 때문에 inefficient. document tokenization은 document를 sequence of discrete tokens (docid)로 표현함.</p> <ul> <li> <p>D: collection of documents</p> </li> <li> <p>d: each document</p> </li> <li> <table> <tbody> <tr> <td>d</td> <td>: total number of tokens in document</td> </tr> </tbody> </table> </li> <li> <p>M: length of docid</p> </li> <li> <p>z: sequence of discrete tokens (docid)</p> </li> <li> <p>z_t: K-way categorical variable</p> </li> <li>위 그림에서는 M=3, K=64인 case</li> </ul> <p>docid인 z는 아래 두가지 조건을 만족해야함.</p> <ol> <li> <p>different documents have short but different docids</p> </li> <li> <p>docids capture the semantics of their associated documents as much as possible</p> </li> </ol> <p><strong>Tokenization model</strong>: Q:d\to z, document d를 docid z로 mapping</p> <p><strong>Generative retrieval model: **</strong>P:q \to z****, **query q와 관련된 문서 docid z를 autoregressive하게 생성하며 학습함</p> <h1 id="method">Method</h1> <p>document tokenization은 주로 fixed pre-processing step으로 사용됨</p> <p>→ 이런 ad-hoc한 방법은 document의 semantic을 잘 잡아내지 못한다는 단점이 존재함.</p> <p><strong>GENRET</strong>: Semantic docid를 학습하는 discrete auto-encoding 기반의 tokenization leraning method</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_002-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_002-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_002-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_002.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>크게 세가지 components로 구성이 됨</p> <ol> <li> <table> <tbody> <tr> <td> <strong>seq2seq based retrieval model: **</strong>P(z</td> <td>q)**</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td> <strong>document tokenization model: **</strong>Q(z</td> <td>d)**</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td> <strong>reconstruction model: **</strong>R(d</td> <td>z)**</td> </tr> </tbody> </table> </li> </ol> <h3 id="overview-process"><strong>Overview process</strong></h3> <p>→ document tokenization model Q가 document d를 unique discrete variables z로 변환시키고, retrieval model P가 given query q에 대해 z를 생성하도록 학습이됨. 추가로 Reconstruction model R은 docid z에서 original document를 생성하도록 학습이됨 (original document의 semantic을 파악하기 위해)</p> <h2 id="architecture">Architecture</h2> <h3 id="document-tokenization-model">Document Tokenization Model</h3> <ul> <li>enc-dec Transformer: input text d가 있을 때, T5-based tokenization model이 d와 a prefix of docid z_{&lt;t}를 인코딩하여 hidden latent vector d_t 생성.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_003-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_003-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_003-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_003.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>tokenization model은 d_t를 기반으로 각 document에 대한 token을 생성</p> </li> <li> <p>각 timestep t 마다, codebook을 정의해줌</p> </li> <li> <p>codebook embedding matrix E_t와 latent vector d_t를 dot-prodcut softmax 취하여 j \isin [K]에 대한 t 시점에서의 확률값 계산,</p> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_004-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_004-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_004-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_004.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="reconstruction-model">Reconstruction Model</h3> <ul> <li> <p>tokenization model Q가 생성한 docid는 semantic 정보를 담아야하기에, auto-encoding training scheme 사용</p> </li> <li> <p>Input: docid z</p> </li> <li> <p>output: document d</p> </li> </ul> <h3 id="retrieval-based-reconstruction-model">Retrieval-based reconstruction model</h3> <ul> <li>docid z와 target document d 간의 relevance score는 다음과 같이 정의함</li> </ul> <h2 id="optimization">Optimization</h2> <p>Document tokenization model, generative retrieval model, reconstruction model을 한 번에 auto-encoding을 활용하여 학습시키기에는 다음과 같은 이유로 어렵다.</p> <ol> <li> <p><strong>Learning docids in an autoregressive fashion</strong></p> </li> <li> <p><strong>Generating docids with diversity</strong></p> </li> </ol> <h3 id="progressive-training-scheme">Progressive training scheme</h3> <ul> <li>M번의 learning steps을 갖는 전체 learning scheme에서 docid z_T은 T \isin [M] 시점에 학습이 됨. 이후 시점에서는 이전 시점의 docid z_T와 parameters들은 fixed됨.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_005-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_005-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_005-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_005.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li>아래 3가지 loss function을 통해 학습이 이루어짐</li> </ul> <h3 id="diverse-clustering-techniques">Diverse clustering techniques</h3> <p>docids의 diversity를 보장하기 위해 아래 두가지 clustering techniques을 각 progressive training step에 적용함.</p> <ol> <li> <p><strong>Codebook Initialization</strong></p> </li> <li> <p><strong>Docid re-assignment</strong></p> </li> </ol> <h1 id="experimental-setup">Experimental Setup</h1> <ul> <li> <p>enc-dec: T5-base</p> </li> <li> <p>retrieval model과 tokenization model에 사용되는 enc-dec, codebook 각각은 shared</p> </li> <li> <p>K number of clusters: 512</p> </li> <li> <p>M length of docid: 문서의 개수에 따라 달라짐</p> </li> </ul> <h1 id="experimental-results">Experimental Results</h1> <h3 id="nq320k-results">NQ320K results</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_006-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_006-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_006-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_006.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>strong pretrained retrieval GTR + previous SOTA in generative retrieval보다 우수한 성능 보임</p> </li> <li> <p>Seen + Unseen dataset에서 우수한 성능 보임</p> </li> </ul> <h3 id="ms-marco--beir-results">MS MARCO + BEIR results</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_007-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_007-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_007-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_007.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p><strong>MS MARCO</strong></p> </li> <li> <p><strong>BEIR</strong></p> </li> </ul> <h3 id="qualitative-analysis">Qualitative analysis</h3> <p>NQ320K dataset에서 GENRET이 생성한 docid에 대한 시각화</p> <ul> <li> <p>left: similar docids는 비슷한 content로 구성</p> </li> <li> <p>right: same group에 들어가는 docid는 semantically하게 비슷함</p> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_008-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_008-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_008-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_008.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h1 id="conclusion">Conclusion</h1> <p>본 연구에서 처음으로 generative retrieval 계열의 document tokenization learning method인 GENRET 소개함. 요약하면, generated docids가 semantics을 담게 설계된 auto-encoding 방식을 통해 documents를 discrete representations으로 tokenize하는 것을 학습함.</p> <p>Dense retrieval method 보다 안정적으로 높은 성능을 보이며, 특히 unseen dataset에서도 좋은 성능을 보인 것으로 미루어 보아 generative retrieval이 앞으로 IR에서 핵심 연구 주제가 되지 않을까 싶음</p> <p>더 짧은 docids로 학습 및 infer해서 효율적이지만, training process가 복잡해서 computation cost가 높을 것 같은데, 이 점에 대한 dense retreival method와 비교 실험이 없어서 아쉬움.</p> <p>이 아니고 appendix에 꼭 숨겨놨었네요</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_009-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_009-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_009-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_009.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>학습 속도는 느리긴 하지만, infer 속도는 가장 빠르다는 결론!</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_010-480.webp 480w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_010-800.webp 800w,/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_010-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/posts/2023-12-19-learning-to-tokenize-for-generative-retrieval/image_010.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 You R. Name. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/al-folio/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/al-folio/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/al-folio/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/al-folio/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/al-folio/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/al-folio/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/al-folio/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/al-folio/assets/js/search-data.js"></script> <script src="/al-folio/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>