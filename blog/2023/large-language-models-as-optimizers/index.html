<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> LARGE LANGUAGE MODELS AS OPTIMIZERS | Unknown NLP Papers </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content="논문 리뷰 - LLM, Instruction Tuning 관련 연구"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknownnlp.github.io/blog/2023/large-language-models-as-optimizers/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Papers </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">LARGE LANGUAGE MODELS AS OPTIMIZERS</h1> <p class="post-meta"> Created on September 19, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/gpt"> <i class="fa-solid fa-hashtag fa-sm"></i> gpt</a>   <a href="/blog/tag/instruction-tuning"> <i class="fa-solid fa-hashtag fa-sm"></i> instruction tuning</a>   <a href="/blog/tag/language-model"> <i class="fa-solid fa-hashtag fa-sm"></i> language-model</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   ·   <a href="/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2023-09-19</li> <li> <strong>Reviewer</strong>: hyowon Cho</li> <li> <strong>Property</strong>: LLM, Instruction Tuning</li> </ul> <blockquote> <p>Google Deepmind</p> </blockquote> <p>이 연구에서는 “Optimization by PROmpting” (OPRO)이라는 방법을 제안한다. 이는 대규모 언어 모델 (LLMs)을 최적화 도구로 활용하는 방법인데, 각 최적화 단계에서 LLM은 값과 함께 이전에 생성된 해결책을 포함하는 프롬프트에서 새로운 해결책을 생성한 다음, 새로운 해결책을 평가하고 다음 최적화 단계를 위한 프롬프트에 추가한다.</p> <p>LLMs를 사용하여 최적화의 잠재력을 확인하기 위해, 먼저 선형 회귀와 외판원 문제라는 두 가지 클래식한 최적화 문제에 대한 실험을 진행한다. 또한, LLMs을 통해서 프롬프트를 최적화하는 방법과 그 과정을 보인다.</p> <p>기존 연구들은 하나의 프롬프트를 만든다음, 이를 수정하는 방식을 택했는데 해당 연구는 생성에 초점을 맞춘다는 점에서 다르다고 주장한다.</p> <h1 id="opro-llm-as-the-optimizer">OPRO: LLM AS THE OPTIMIZER</h1> <p>각 최적화 단계에서 LLM은 문제 설명과 이전에 평가된 솔루션을 기반으로 최적화 작업에 대한 후보 솔루션을 생성한다.</p> <p>그런 다음 새로운 솔루션은 평가되고 메타 프롬프트에 추가되어 이후의 최적화 프로세스에 사용된다.</p> <p>최적화 프로세스는 LLM이 더 나은 최적화 점수를 가진 새로운 솔루션을 제안할 수 없는 경우 또는 최대 최적화 단계 수에 도달한 경우에 종료된다.</p> <h2 id="desirables-of-optimization-by-llms">DESIRABLES OF OPTIMIZATION BY LLMS</h2> <ol> <li> <p>Making use of natural language descriptions.</p> </li> <li> <p>Trading off exploration and exploitation.</p> </li> </ol> <h2 id="meta-prompt-design">META-PROMPT DESIGN</h2> <p>메타 프롬프트는 다음 두 가지로 이루어진다.</p> <ol> <li> <p>Optimization problem description (meta-instructions)</p> </li> <li> <p>Optimization trajectory</p> </li> </ol> <h2 id="solution-generation">SOLUTION GENERATION</h2> <p>LLM은 메타 프롬프트를 입력으로 사용하여 새로운 솔루션을 생성한다.</p> <p>2가지 주요 최적화 도전 과제는 다음과 같다:</p> <ol> <li> <p>Optimization stability.</p> </li> <li> <p>Exploration-exploitation trade-off.</p> </li> </ol> <h1 id="motivating-example-mathematical-optimization">MOTIVATING EXAMPLE: MATHEMATICAL OPTIMIZATION</h1> <p>해당 섹션에서는 LLM이 수학적 최적화의 최적화 도구로서 사용될 수 있는지 확인한다.</p> <h2 id="linear-regression">Linear Regression</h2> <p>선형 회귀 문제에서 목표는 입력 변수에서 label을 확률적으로 가장 잘 설명하는 선형 계수를 찾는 것!</p> <p>각 단계에서 과거에 얻은 최고의 20개의 (w, b) 쌍과 그들의 정렬된 결과 값이 포함된 메타 프롬프트로 조정된 LLM에게 instruction을 제공. 그런 다음 메타 프롬프트에서는 목적 함수 값을 더 줄이는 새로운 (w, b) 쌍을 요청-&gt;평가-&gt;과거 기록에 추가.</p> <p>text-bison 및 GPT-4 모델은 수렴 속도에서 GPT-3.5-turbo 모델을 능가한다.</p> <p>최적화 궤적을 더 자세히 살펴보면, GPT-4가 과거로부터 합리적인 다음 단계를 제안하는 데 가장 뛰어나다는 것을 알 수 있다. 예를 들어, 과거에서 (w, b) = (8, 7), (w, b) = (8, 6) 및 (w, b) = (8, 5)의 목적 값이 감소하는 것을 보여줄 때, GPT-4는 (w, b) = (8, 4)를 평가할 확률이 가장 높다.</p> <h2 id="traveling-salesman-problem-tsp">TRAVELING SALESMAN PROBLEM (TSP)</h2> <p>TSP (Traveling Salesman Problem) 작업은 시작 노드에서 출발하여 모든 노드를 지나 다시 시작 노드로 돌아오는 가장 짧은 경로를 찾는 것.</p> <p>optimality gap은 평가된 방법에 의해 구성된 솔루션의 거리와 오라클 솔루션에서 달성한 거리의 차이를 오라클 솔루션의 거리로 나눈 것으로 정의.</p> <ul> <li> <p>Nearest Neighbor (NN) greedy</p> </li> <li> <p>Farthest Insertion (FI) FI는 각 단계에서 새로운 노드를 부분 솔루션에 삽입하는 비용을 최적화. 새로운 노드 k를 추가하는 최소 삽입 비용은 다음과 같이 정의: c(k) = min(i,j) d(i, k) + d(k, j) − d(i, j) 여기서 i와 j는 현재 경로에서 인접한 노드이고, d(·, ·)는 두 노드 사이의 거리를 나타낸다. 각 단계에서 FI는 최소 삽입 비용을 최대화하는 새로운 노드를 추가함.</p> </li> </ul> <p>gpt-4가 모든 경우, gpt-3.5-turbo와 text-bison을 능가함.</p> <ul> <li> <p>작은 규모의 문제에서 gpt-4는 다른 LLMs보다 약 4배 빠르게 최적점에 도달</p> </li> <li> <p>큰 규모의 문제에서, 특히 n = 50인 경우, gpt-4는 여전히 휴리스틱 알고리즘과 비슷한 품질의 솔루션을 제공.</p> </li> <li> <p>반면, text-bison과 gpt-3.5-turbo는 optimality gap이 최대 20배 더 나쁜 지역 최적점에서 멈춤.</p> </li> <li> <p>n = 10일 때, 모든 LLMs는 평가된 모든 문제에 대해 최적 솔루션을 찾음.</p> </li> </ul> <h2 id="application-prompt-optimization">APPLICATION: PROMPT OPTIMIZATION</h2> <p>목표는 작업 정확도를 극대화하는 프롬프트를 찾는 것!</p> <h2 id="problem-setup">PROBLEM SETUP</h2> <p>objective function evaluator는 최적화된 프롬프트가 적용될 LLM이며, 최적화를 위한 LLM과 동일하거나 다를 수 있다. 목적 함수 평가를 위한 LLM을 scorer LLM,이라고 표시하고 최적화를 위한 LLM을 optimizer LLM이라고 한다.</p> <p>optimizer LLM의 출력은 instruction으로, 모든 예시의 질문 부분에 연결되어 scorer LLM에 instruction을 제공한다. 구체적으로 다음 위치들을 고려한다.</p> <ul> <li> <p>Q_begin: 원래 질문 앞에 instruction이 추가.</p> </li> <li> <p>Q_end: 원래 질문 뒤에 instruction이 추가.</p> </li> <li> <p>A_begin: instruction이 scorer LLM 출력의 시작 부분에 추가.</p> </li> </ul> <h2 id="meta-prompt-design-1">META-PROMPT DESIGN</h2> <ul> <li> <p>Optimization problem examples.</p> </li> <li> <p>Optimization trajectory.</p> </li> <li> <p>Meta-instructions.</p> </li> </ul> <h1 id="prompt-optimization-experiments">PROMPT OPTIMIZATION EXPERIMENTS</h1> <ul> <li> <p>Models.</p> </li> <li> <p>Benchmarks</p> </li> </ul> <h2 id="gsm8k">GSM8K</h2> <p>For prompt optimization, we randomly sample 3.5% examples from the GSM8K training set.</p> <h2 id="bbh">BBH</h2> <h2 id="semantically-similar-instructions-may-achieve-drastically-different-accuracies">SEMANTICALLY SIMILAR INSTRUCTIONS MAY ACHIEVE DRASTICALLY DIFFERENT ACCURACIES</h2> <ul> <li> <p>Although the instructions are semantically similar, a paraphrase by the optimizer LLM offers a notable accuracy improvement</p> </li> <li> <p>“Let’s think step by step.” achieves accuracy 71.8, “Let’s solve the problem together.” has accuracy 60.5, while the accuracy of “Let’s work together to solve this problem step by step.” is only 49.4, although it is the semantic combination of the two upper instructions</p> </li> </ul> <h2 id="ablation-studies">ABLATION STUDIES</h2> <ul> <li> <p>The order of the previous instructions.</p> </li> <li> <p>The effect of instruction scores</p> </li> <li> <p>The effect of exemplars</p> </li> <li> <p>The number of generated instructions per step</p> </li> <li> <p>Starting point.</p> </li> </ul> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>