<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="5EvH841dAH-gE3azIorT3dCfBA_7a3yppKdAm1JWne8"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> DETECTING PRETRAINING DATA FROM LARGE LANGUAGE MODELS | Unknown NLP Lab </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content="논문 리뷰 - LLM 관련 연구"> <meta name="keywords" content="natural language processing, NLP, machine learning, artificial intelligence, research papers, academic collaboration, paper review, computational linguistics, deep learning, transformers, language models"> <meta property="og:site_name" content="Unknown NLP Lab"> <meta property="og:type" content="article"> <meta property="og:title" content="Unknown NLP Lab | DETECTING PRETRAINING DATA FROM LARGE LANGUAGE MODELS"> <meta property="og:url" content="https://unknownnlp.github.io/blog/2024/detecting-pretraining-data-from-large-language-models/"> <meta property="og:description" content="논문 리뷰 - LLM 관련 연구"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="DETECTING PRETRAINING DATA FROM LARGE LANGUAGE MODELS"> <meta name="twitter:description" content="논문 리뷰 - LLM 관련 연구"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Jeahee Kim"
        },
        "url": "https://unknownnlp.github.io/blog/2024/detecting-pretraining-data-from-large-language-models/",
        "@type": "BlogPosting",
        "description": "논문 리뷰 - LLM 관련 연구",
        "headline": "DETECTING PRETRAINING DATA FROM LARGE LANGUAGE MODELS",
        
        "sameAs": ["https://inspirehep.net/authors/1010907","https://scholar.google.com/citations?user=qc6CJjYAAAAJ","https://www.alberteinstein.com/"],
        
        "name": "Jeahee Kim",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknownnlp.github.io/blog/2024/detecting-pretraining-data-from-large-language-models/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">DETECTING PRETRAINING DATA FROM LARGE LANGUAGE MODELS</h1> <p class="post-meta"> Created on January 02, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/detection"> <i class="fa-solid fa-hashtag fa-sm"></i> detection</a>   <a href="/blog/tag/gpt"> <i class="fa-solid fa-hashtag fa-sm"></i> gpt</a>   <a href="/blog/tag/language-model"> <i class="fa-solid fa-hashtag fa-sm"></i> language-model</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   ·   <a href="/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2024-01-02</li> <li> <strong>Reviewer</strong>: 김재희</li> <li> <strong>Property</strong>: LLM</li> </ul> <hr> <hr> <h2 id="1-intro">1. Intro</h2> <h3 id="pretrain-data-detection">Pretrain Data Detection</h3> <ul> <li> <p>LLM 활용에 있어 Pretrain Data Detection 필요성</p> <ul> <li> <p>Privacy 관련 데이터 학습 여부를 확인하여야 함 ⇒ Privacy 데이터 생성 문제</p> </li> <li> <p>Copyright 관련 데이터 학습 여부를 확인하여야 함 ⇒ 저작권 및 사용료 문제</p> </li> <li> <p>Benchmark Dataset 데이터 학습 여부를 확인하여야 함 ⇒ 정확한 모델 성능 측정 문제</p> </li> </ul> </li> </ul> <h3 id="membership-inference-attack-mia">Membership Inference Attack (MIA)</h3> <ul> <li> <p>특정 데이터에 대해 대상 모델의 학습 여부를 Inference 과정을 통하여 탐색하는 분야</p> </li> <li> <p>LLM에 대한 기존 방법론 적용의 어려움</p> <ul> <li> <p>기존 방법론 : 특정 데이터와 유사한 분포를 가지는 데이터 존재 가정(Shadow Data)</p> <ul> <li> <p>Shadow Data로 대상 모델을 Finetune시킴 (Shadow Model)</p> </li> <li> <p>특정 데이터에 대한 Original Model의 Output Probability를 Shadow Model을 이용하여 Calibration → Original Model이 특정 데이터에 대해 Finetune 되었는지 판별</p> </li> <li> <p>두가지 가정 사용</p> </li> </ul> </li> </ul> </li> </ul> <ol> <li> <p>대상 모델의 Pretrain 데이터를 알고 있음</p> </li> <li> <p>Shadow Data를 충분한 양 수집할 수 있음</p> </li> </ol> <p>⇒ 두 가정 모두 LLM에서 성립 X</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Pretrain Corpus를 모르고, 알고 있다 하더라고 분석하기에 너무 방대하고, 우리가 실제로 접근할 수 있는 것은 생성 확률 뿐일 때를 가정하고 문제 상황 정의
</code></pre></div></div> <ul> <li> <p>탐지 어려움 :</p> <ul> <li> <p>MIA 태스크에서 일반적으로 학습 데이터의 크기가 커질수록, 학습 epoch 및 lr이 작을수록 탐지 난이도가 올라간다고 알려져 있음</p> <ul> <li>LLM Pretrain Corpus는 매우 크고, 학습 epoch과 lr은 매우 작음 → MIA 태스크 중 매우 난이도가 높음</li> </ul> </li> </ul> </li> </ul> <p>+) 특정 데이터의 Pretrain Corpus 내 등장 빈도 역시 고려되어야 함</p> <h2 id="2-wikimia--a-dynamic-evaluation-benchmark">2. WikiMIA : A Dynamic Evaluation Benchmark</h2> <ul> <li> <p>WimiMIA : LLM MIA 태스크를 위한 Benchmark 데이터셋 구축 및 공개</p> <ul> <li> <p>Data Construction: Non-Member Data 394 건 수집 + Member Data 394 건 샘플링</p> <ol> <li> <p>Non-Member Data : LLM들이 공통적으로 Pretrain에 사용되지 않았다고 확신할 수 있는 데이터</p> </li> <li> <p>2023년 1월 1일 이후 생성된 위키피디아 문서 수집</p> </li> <li> <p>사건사고 카테고리</p> </li> <li> <p>해당 페이지 생성일자가 2023년 1월 1일 이후</p> </li> <li> <p>Member Data : LLM들이 공통적으로 Pretrain에 사용했다고 확신할 수 있는 데이터</p> </li> <li> <p>2017년 이전에 생성된 위키피디아 문서 수집 → 대부분의 LLM들이 해당 시점의 위키피디아 데이터를 Pretrain에 사용했다고 보고</p> </li> <li> <p>의미가 없는 페이지 삭제 → Table of Contents 등으로만 구성된 페이지</p> </li> </ol> </li> <li> <p>Paraphrasing : 기존의 MIA 태스크는 정확하게 동일한 데이터만 탐지하는 것을 목표로 함</p> <ul> <li> <p>자연어 특성상 유사한 의미를 가지는 문서 탐지도 매우 중요</p> </li> <li> <p>ChatGPT에게 WikiMIA 데이터를 Paraphrasing해달라고 하여 별도 데이터 구축</p> </li> </ul> </li> <li> <p>Length : 기존의 MIA 태스크는 전체 데이터에 대해 하나의 metric 산출</p> <ul> <li> <p>자연어 특성 고려 및 실험 결과 문서 길이와 탐지 성능 간 높은 corr이 있었음.</p> </li> <li> <p>길이 별 데이터를 분리하여 성능 평가</p> </li> </ul> </li> </ul> </li> </ul> <h2 id="3-proposed-methods--min-k-prob">3. Proposed Methods : MIN-K% Prob</h2> <figure> <picture> <img src="/assets/img/posts/2024-01-02-detecting-pretraining-data-from-large-language-models/image_000.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="가정">가정</h3> <blockquote> <p>학습 때 사용되지 않은 데이터에 대해 inference 한다면 이상 단어(outlier words)를 포함하고 있으므로, 낮은 생성 확률을 가지고 있을 것이다.</p> </blockquote> <ul> <li>매우 단순하고 직관적인 아이디어를 기반으로 각 샘플 당 Non-Member(pretrain 때 사용되지 않은 데이터)일 Score 산출</li> </ul> <h3 id="수식">수식</h3> <figure> <picture> <img src="/assets/img/posts/2024-01-02-detecting-pretraining-data-from-large-language-models/image_001.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>각 토큰 생성 확률의 평균</p> <ul> <li> <p>대상 토큰 : 한 문장 내 토큰들 중 생성 확률 하위 K%의 토큰들</p> </li> <li> <p>생성될 확률이 낮았던 토큰들(이상 단어, outlier words)의 평균 생성 확률</p> </li> </ul> </li> <li> <p>해당 스코어에 대한 Thresholding을 통해 MIA 태스크 수행 가능</p> </li> </ul> <h2 id="4-experiments-1---main">4. Experiments 1 - Main</h2> <h3 id="implementation-details-and-setup">Implementation Details and Setup</h3> <ul> <li> <p>WikiMIA 데이터에 대한 성능 리포팅</p> </li> <li> <p>Validation Set에 대해 Top-K Search → 20이 Best Hyperparam, 데이터셋별 tune 없이 고정하여 사용</p> </li> <li> <p>AUC 점수를 reporting하여 별도의 threshold 고정 X</p> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2024-01-02-detecting-pretraining-data-from-large-language-models/image_002.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="result">Result</h3> <ul> <li> <p>타 방법론 대비 가장 높은 탐지 성능 기록</p> </li> <li> <p>제안 방법론 유효성 입증</p> <ul> <li> <p>타 방법론들의 경우 paraphrasing으로 인한 성능 감소 다수 발생</p> </li> <li> <p>제안 방법론은 성능 저하 거의 X</p> </li> </ul> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2024-01-02-detecting-pretraining-data-from-large-language-models/image_003.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="analysis">Analysis</h3> <ul> <li> <p>평가 데이터 길이 및 모델 크기에 따른 성능 변화</p> </li> <li> <p>모델 크기</p> <ul> <li>모델 크기가 클 수록 더 높은 탐지 성능 기록</li> </ul> </li> </ul> <p>⇒ 모델이 커질수록 학습 데이터에 대한 Memorization 성능 향상 → Membership 데이터에 대한 탐지 능력 확보</p> <ul> <li> <p>데이터 길이</p> <ul> <li>데이터가 길수록 더 높은 탐지 성능 기록</li> </ul> </li> </ul> <p>⇒ 데이터가 길수록 Memorization된 정보를 포함하고 있을 여지가 높아짐 → Memebership 데이터에 대한 탐지 능력 확보</p> <h2 id="5-experiments-2---detecting-copyrighted-books-in-pretraining-data">5. Experiments 2 - Detecting Copyrighted Books in Pretraining Data</h2> <h3 id="개요">개요</h3> <ul> <li> <p>LLM이 학습 데이터 내 copyright 문제가 있는 데이터 포함 여부 탐지 성능 측정</p> <ul> <li>이미 기존 연구를 통해 ChatGPT 내 저작권 이슈가 존재하는 책 50여권이 학습된 것으로 추정되는 상황</li> </ul> </li> <li> <p>별도의 평가 데이터셋 구축</p> <ul> <li> <p>Membership Data : 기존 연구를 통해 밝혀진 50 여권의 책, ChatGPT가 학습한 것으로 추정</p> </li> <li> <p>Non-Membership Data : 2023년 새로이 출간된 50권의 책, ChatGPT가 학습할 수 없는 데이터</p> </li> </ul> </li> <li> <p>GPT-3 내 저작권 이슈 데이터 확인</p> <ul> <li> <p>Book3 Corpus 내 저작권 이슈가 있는 서적 100권 선택</p> </li> <li> <p>Threshold를 설정하여 해당 데이터에 대한 GPT-3 학습 여부 판단</p> </li> </ul> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2024-01-02-detecting-pretraining-data-from-large-language-models/image_004.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>왼쪽 : 평가 데이터에 대한 판별 성능(AUC)</p> <ul> <li>비교 방법론 대비 제안 방법론이 가장 높은 성능 달성</li> </ul> </li> <li> <p>오른쪽 : GPT-3의 저작권 이슈가 있는 데이터 학습 정도</p> <ul> <li> <p>GPT-3의 경우 90% 이상의 서적에 대해 50% 이상의 문장에 대해 학습된 것으로 보임</p> </li> <li> <p>(사실은 문장이 아니라, segments)</p> </li> </ul> </li> </ul> <h2 id="6-experiments-3---detecting-downstream-dataset-contamination">6. Experiments 3 - Detecting Downstream Dataset Contamination</h2> <h3 id="개요-1">개요</h3> <ul> <li> <p>Downstream Task 데이터에 대한 학습 여부 탐지 성능 실험</p> </li> <li> <p>모델 : LLaMA 7B</p> </li> <li> <p>실험 방법 : 의도적으로 Downstream Task 데이터를 포함하는 Pretrain Corpus 구축 및 Continual Learning(Pretrain) 진행</p> <ul> <li> <p>데이터셋 구성</p> <ul> <li> <p>RedPajama Corpus에서 일부 데이터 추출하여 pretrain corpus 구축</p> </li> <li> <p>BoolQ, IMDB, TruthfulQA, CommonsenseQA 데이터셋에서 각 400개의 데이터 샘플링</p> <ul> <li> <p>200개의 데이터 : Pretrain Corpus에 포함 (Membership Data)</p> </li> <li> <p>200개의 데이터 : Pretrain Corpus에 포함 X (Non-Membership Data)</p> </li> </ul> </li> </ul> </li> <li> <p>RedPajama Corpus + 200*4 Data로 Contaminated Pretrain Corpus 구축</p> <ul> <li>해당 코퍼스에 대해 1 epoch 훈련 진행</li> </ul> </li> </ul> </li> </ul> <h3 id="result-1">Result</h3> <figure> <picture> <img src="/assets/img/posts/2024-01-02-detecting-pretraining-data-from-large-language-models/image_005.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>1 epoch만 학습되었음에도 86이상의 성능 리포팅</p> <ul> <li> <p>제안 방법론의 유효성 재차 검증</p> </li> <li> <p>LLM의 Memorization 능력이 매우 강하다는 점 확인</p> <ul> <li>Downstream Task의 데이터로 학습되었더라도 해당 태스크를 학습하기보다는 데이터를 외우는 경향이 있다고 볼 수도…?</li> </ul> </li> </ul> </li> </ul> <h3 id="additional-experiments">Additional Experiments</h3> <figure> <picture> <img src="/assets/img/posts/2024-01-02-detecting-pretraining-data-from-large-language-models/image_006.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>전체 pretrain corpus 크기에 따른 실험</p> <ul> <li> <p>본래 MIA 태스크에서는 학습 데이터의 크기가 클수록 특정 학습 데이터를 탐지하는 것이 어렵다고 생각되어왔음 → 일반화 성능이 올라가니까</p> </li> <li> <p>LLM에 있어서는 Pretrain Corpus가 특정 도메인만 포함하지 않고, 태스크를 의미하지 않기 때문에, 어떤 경향성을 띄는지 확인</p> </li> <li> <p>Pretraining Dataset Size : RedPajama의 크기를 늘려 Pretrain Corpus 크기를 늘리면서 실험 진행</p> <ul> <li> <p>Downstream Task 데이터의 갯수는 고정</p> </li> <li> <p>Pretrain Corpus의 크기가 커질수록 오히려 Detection 성능이 올라가는 경향성 포착</p> <ul> <li>LLM이 Tail Outlier를 잘 memorize하는 경향성에 기인</li> </ul> </li> </ul> </li> <li> <p>News Dataset Size</p> <ul> <li> <p>LLaMA의 Pretrain Corpus에 포함되어 있지 않은 2023년 08월 뉴스 데이터 수집</p> </li> <li> <p>해당 데이터의 1000, 5000, 10000 건을 학습 데이터 사용하고, 100건을 평가에만 사용하여, MIA 태스크 성능 측정</p> <ul> <li> <p>Pretraining Dataset Size 실험과 반대로 데이터 크기가 커질수록 Detetction 성능 저하 포착</p> </li> <li> <p>Downstream Task와 달리 범용 도메인의 일반 데이터에 대해서는 MIA 태스크 특징에 부합하는 현상</p> </li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Corpus 내 Membership data 빈도에 따른 실험</p> <ul> <li> <p>Pretrain Corpus 내 Downstream Task 데이터의 빈도수를 조절하며 학습/평가 진행</p> </li> <li> <p>빈도수가 높아질수록 잘 Detection 되는 경향을 보임</p> <ul> <li>Pretrain Corpus 내 빈도수가 올라갈수록 Memorization이 더 많이 일어나기 때문</li> </ul> </li> </ul> </li> <li> <p>Learning Rate에 따른 실험</p> <ul> <li> <p>learning rate을 낮출수록 Detection 성능이 급격히 낮아짐</p> <ul> <li>lr이 높아질수록 memorization이 더 심하게 발생하기 때문</li> </ul> </li> </ul> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2024-01-02-detecting-pretraining-data-from-large-language-models/image_007.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="7-conclusion">7. Conclusion</h2> <h3 id="summary">Summary</h3> <ul> <li> <p>LLM의 학습 데이터를 inference를 통해 판별하는 방법론 및 벤치마크 데이터셋 제안</p> <ul> <li> <p>방법론 : instance 내 log likelihood 하위 K%의 평균 확률을 계산하여 Score로 사용</p> </li> <li> <p>벤치마크 데이터셋 : 현재까지 공개된 LLM이 무조건 학습/절대 학습 불가한 데이터를 이용하여 Detection Benchmark 데이터셋 제안</p> </li> </ul> </li> <li> <p>LLM의 Memorization 성능이 매우 강력하고 이를 통해 Detection이 쉬워지는 경향성 포착</p> </li> <li> <p>단순히 PPL 등을 이용하기 보다는 Lowest K%를 이용하는 방법론의 유효성 입증</p> </li> <li> <p>Downstream Task Dataset과 Pretrain Corpus 데이터셋 간의 다른 경향성 포착</p> </li> </ul> <h3 id="pros--cons">Pros &amp; Cons</h3> <ul> <li> <p>요새 많이 주목받는 LLM Pretrain Corpus 분석 관련 연구</p> </li> <li> <p>연구 주제 및 Research Question 설정이 매우 구체적임</p> <ul> <li>논문이 매우 읽기 쉽고, 논리적이며 직관적인 인상을 줌</li> </ul> </li> <li> <p>LLM의 Pretrain Corpus를 확신할 수 없는 상황에서 효율적/효과적 실험 환경 설정</p> </li> <li> <p>LLM의 Memorization 현상에 대한 향후 연구가 더 필요해 보임</p> <ul> <li>비교 방법론 대비 높은 성능을 보이고 있지만, 실제로 써먹을 수 있는 방법인지에 대해서는 고민이…</li> </ul> </li> </ul> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>