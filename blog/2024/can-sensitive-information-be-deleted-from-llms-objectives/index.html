<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> CAN SENSITIVE INFORMATION BE DELETED FROM LLMS? OBJECTIVES FOR DEFENDING AGAINST EXTRACTION ATTACKS | Unknown NLP Papers </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content="논문 리뷰 - Editing, Evaluation Metric 관련 연구"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknownnlp.github.io/blog/2024/can-sensitive-information-be-deleted-from-llms-objectives/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Papers </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">CAN SENSITIVE INFORMATION BE DELETED FROM LLMS? OBJECTIVES FOR DEFENDING AGAINST EXTRACTION ATTACKS</h1> <p class="post-meta"> Created on February 13, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/editing"> <i class="fa-solid fa-hashtag fa-sm"></i> editing</a>   <a href="/blog/tag/evaluation-metric"> <i class="fa-solid fa-hashtag fa-sm"></i> evaluation metric</a>   <a href="/blog/tag/gpt"> <i class="fa-solid fa-hashtag fa-sm"></i> gpt</a>   <a href="/blog/tag/language-model"> <i class="fa-solid fa-hashtag fa-sm"></i> language-model</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   ·   <a href="/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2024-02-13</li> <li> <strong>Reviewer</strong>: hyowon Cho</li> <li> <strong>Property</strong>: Editing, Evaluation Metric</li> </ul> <h1 id="introduction">INTRODUCTION</h1> <p>언어 모델이 사실 정보를 가지고 있다는 것은 이미 자명하며, 그에 따라서 personal information을 기억하거나 혹은 out-dated 지식들을 여전히 사실이라고 여길 위험에 대한 경각심이 늘어나고 있다. 모델들은 또한 사람들에게 직접적으로 psychological harm을 가할 가능성이 있는 것으로 드러났는데, 이러한 유형의 사실 혹은 믿음을 sensitive information이라고 부른다.</p> <p>저자들은 이러한 분야에 가장 근본적인 질문 두 가지를 던진다.</p> <ol> <li> <p>How can we “delete” specific sensitive information from language models when we do not want models to know or express this information?</p> </li> <li> <p>How do we test whether that specific information was successfully deleted?</p> </li> </ol> <ul> <li> <blockquote> <p>특히나, 2번째의 질문이 knowledge editing이나 unlearning 분야의 고질적인 한계점으로 계속 지적되고 있는 만큼 어떠한 연구를 할지 흥미를 유발!</p> </blockquote> </li> </ul> <h3 id="scrubbing-sensitive-info-from-llm-outputs">Scrubbing Sensitive Info From LLM Outputs.</h3> <p>최근, sensitive information을 LLM output에서 지우기 위한 가장 지배적인 방법론은 강화학습을 사용하는 것이다. 가장 간단한 방법론으로는, training data에서 민감한 정보들을 필터링하는 것이라고 할 수 있겠다. 하지만, 여전히 이러한 필터링 이외에도 잘못된 정보를 뱉는 것으로 보아, 많은 한계가 있는 것이 사실이다.</p> <h3 id="model-editing-for-information-deletion">Model Editing for Information Deletion</h3> <p>이러한 이유로, 저자들은 이상적인 방법론은 model weight로부터 직접적으로 정보를 지울 수 있어야한다고 주장하며, 추가적으로 이러한 방식만이 whitebox extraction attack을 방지할 수 있다고 말한다.</p> <h3 id="whitebox-attacks">Whitebox Attacks.</h3> <p>저자들은 Whitebox Attacks으로 모델의 interpretability에 관한 연구들을 참조한다. *즉, 지난번에 다뤘던 logit lens를 이용한다! *intermediate hidden states를 이용하여 보다 정밀하게 모델이 특정 지식을 모든 weight에서 잊었는지 확인할 수 있다.</p> <p>또한 기존의 방법론은 보통 final layer의 단에서 수정을 하는데, logit lens를 활용하기 때문에 해당 model editing 방법론을 모든 layer 단에서 구현한다. 이를 통해 attack success rate를 38%에서 2.4%까지 내렸다.</p> <p>하지만 저자들은 여전히 이러한 공격 방식이 충분하지 않다고 이야기하며 정말 모델이 특정 지식을 잊었는지 판단하기 위한 다른 attack을 제안한다.</p> <h3 id="blackbox-attacks">Blackbox Attacks.</h3> <p>해당 공격은 automated input rephrasing attack이다.</p> <p>비록 model editing 방법론이 대부분의 prompt에 대한 paraphrases에 대해서 잘 반응하지만, 여전히 paramrphasing model로부터 만들어진 더 많은 것들에 대해서는 반응하지 못한다는 것을 확인했다.</p> <h1 id="related-work">RELATED WORK</h1> <ul> <li> <p>Evidence That LLMs Memorize Sensitive Information.</p> <ul> <li> <p>이미 다양한 연구들에서 정보들을 외운다는 것이 밝혀짐</p> </li> <li> <p>최근 연구로는 Carlini et al. (2023) show that GPT-J memorizes at least 1% of its entire training dataset.</p> </li> </ul> </li> <li> <p>Attacking LLMs for Sensitive Information</p> <ul> <li> <p>Membership inference attacks</p> </li> <li> <p>prompting and probing</p> </li> <li> <p>이 연구에서 하는 것은 attacker가 pretraining data를 가지고 있지 않고, threat model이 candidate set을 ‘하나의 텍스트’로 제한하지 않는다는 점에서 조금 다름</p> </li> </ul> </li> <li> <p>Machine Unlearning and Model Editing.</p> <ul> <li> <p>unlearning methods are generally focused on removing the influence of a training (x, y) pair on a supervised model -&gt; 정보를 삭제하는데에는 적합하지 않음.</p> </li> <li> <p>이러한 관점에서 Model editing은 focused on changing particular outputs for certain model inputs</p> </li> <li> <p>해당 연구에서도 이를 이어서 실험. 그러나 다른 점은: 기존 연구에서는 input에 따른 representation을 이용해서 information을 제거했다면, 이번 연구에서는 model weight에서 삭제한다는 점이다!</p> </li> </ul> </li> </ul> <h1 id="problem-statement">PROBLEM STATEMENT</h1> <p>이 연구에서의 목표는 “single undesired fact를 모델에서부터 제거하는 것”이다. 이를 위해서는 이것이 제대로 제거되었는지 아닌지 평가할 수 있는 metric이 필요하다.</p> <h2 id="threat-model">THREAT MODEL</h2> <h3 id="adversarys-objective">Adversary’s Objective:</h3> <table> <tbody> <tr> <td>민감한 정보에 대한 질문과 답을 담은 pair (Q, A)에서 답을 inference 중 낸 경우. 이때, A가 Candidate set C에 속하느냐로 unlearning 성능을 측정하며,</td> <td>C</td> <td>= B를 attack budget이라 칭한다.</td> </tr> </tbody> </table> <ol> <li>Password Attempts:</li> </ol> <ul> <li> <p>attacker가 민감 정보에 대한 답을 알지 못함</p> </li> <li> <p>attacker가 답이 사실인지 아닌지 판별은 가능 -&gt; 마치 비밀번호처럼!</p> </li> </ul> <ol> <li>Parallel Pursuit</li> </ol> <ul> <li>attacker가 사실 정보인지에 대한 확인이 필요없이 정보를 캐가는 경우 -&gt; ex. 이메일 캐서 스팸 한번에 뿌리기</li> </ul> <ol> <li>Verification by Data Owner</li> </ol> <ul> <li> <p>attacker가 실제 데이터의 owner인 경우</p> </li> <li> <p>즉, 정보를 알고있지만 퍼지기를 원하지 않는다.</p> </li> </ul> <h3 id="attack-success-metric">Attack Success Metric.</h3> <p>$AttackSuccess@B(M)$ = prediction이 C안에 속하는 경우.</p> <ul> <li> <p>Adversary’s Capabilities</p> <ul> <li> <p>whitebox: model weigth와 architecture에 대한 접근이 가능하다고 가정</p> </li> <li> <p>blackbox: input을 제공하면 output을 얻을 수 있음을 가정.</p> </li> </ul> </li> </ul> <h2 id="metrics-for-information-deletion">METRICS FOR INFORMATION DELETION</h2> <p>두 가지를 고려한다.</p> <ol> <li> <p>remove specific information</p> </li> <li> <p>avoiding damaging the model’s knowledge in general</p> </li> </ol> <p>arg\ min _{M^∗}AttackSuccess@B(M^∗) + λDamage(M^∗,M)</p> <p>M^∗은 edited model. M은 수정 전 모델.</p> <p>Model Damage를 판단하기 위한 metric으로는 두 가지를 측정한다.</p> <ol> <li>Random ∆-Acc</li> </ol> <ul> <li>random datapoint에 대한 성능 확인</li> </ul> <ol> <li>Neighborhood ∆-Acc</li> </ol> <ul> <li>삭제된 지식과 e same relations and the same (true) answers을 가진 정보들에 대한 사실 확인. 얘네는 삭제되면 안됨</li> </ul> <p>추가적으로 Rewrite Score 점수도 제공한다.</p> <table> <tbody> <tr> <td>\frac{p(y</td> <td>x;M^∗) − p(y</td> <td>x;M)}{1 − p(y</td> <td>x;M)}</td> </tr> </tbody> </table> <p>즉, target에 대해서 얼마나 바뀌었는지! 1이 된다면 new target 확률이 극대화, 0이 되면 반대. 이 점수를 극대화가 아닌 minimizing이 목적이 되게 되면 다음과 같이 수식이 변화한다.</p> <table> <tbody> <tr> <td>1 − p(y</td> <td>x;M∗)/p(y</td> <td>x;M)</td> </tr> </tbody> </table> <p>즉, target prob가 0에 가까워질수록 잘 잊었다!</p> <h1 id="attack-methods">ATTACK METHODS</h1> <figure> <picture> <img src="/assets/img/posts/2024-02-13-can-sensitive-information-be-deleted-from-llms-objectives/image_000.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="whitebox-logit-lens-attacks">WHITEBOX LOGIT LENS ATTACKS</h2> <ul> <li> <p>Head Projection Attack:</p> <ul> <li>candidate set C는 top-k highest probability tokens from each layer를 통해 구축됨. logit lens를 이용하여 구함</li> </ul> </li> <li> <p>Probability Delta Attack</p> <ul> <li> <p>삭제된 지식들이 사실은 초반부 레이어에서는 급격하게 확률이 높아졌다가 후반부로 갈수록 낮아지는 추세가 있음을 발견.</p> </li> <li> <p>이 경우, 오히려 근접한 레이어들에 대한 token Probability에 대한 차에서 top or bottom k의 단어에서 이들이 발견될 수 있음을 의미.</p> </li> <li> <p>C_{Probability-Delta} = \bigcup_{\ell \in L}top-k(D(\ell+1) − D(\ell)) \cup bottom-k(D(\ell+1) − D(\ell))</p> </li> </ul> </li> </ul> <h2 id="blackbox-attack-input-rephrasing">BLACKBOX ATTACK: INPUT REPHRASING</h2> <p>단순하게, rephrasing model을 만들어서 Model editing을 할 때 사용했던 데이터에 대한 변형을 만들고, 이 전부를 이용해서 공격을 하는 경우!</p> <ul> <li> <blockquote> <p>단순하지만 아직 아무도 안했다는 점이 포인트!</p> </blockquote> </li> </ul> <p>5개의 paraphrases 생성.</p> <p>dipper-paraphraser-xxl (Krishna et al., 2023) model 사용.</p> <h1 id="defense-methods">DEFENSE METHODS</h1> <p>기존에 존재하는 방법론들과 추가된 denfense 방법들을 소개한다.</p> <ol> <li>The Empty Response Defense(Ouyang et al.,2022)</li> </ol> <ul> <li>모델로 하여금 “I don’t know” 혹은 “dummy”를 뱉도록 하는 기법.</li> </ul> <ol> <li>Fact Erasure (Hase et al., 2023).</li> </ol> <ul> <li> <table> <tbody> <tr> <td>minimize p(y</td> <td>x;M) for the original fact (x, y).</td> </tr> </tbody> </table> </li> </ul> <ol> <li>Error Injection (De Cao et al., 2021).</li> </ol> <ul> <li> <table> <tbody> <tr> <td>arg maxM p(y∗</td> <td>x;M) where y∗ is the alternative</td> </tr> </tbody> </table> </li> <li>하지만, 이러한 방법은 현실에서는 사용하기 적합x - 잘못된 정보!</li> </ul> <ol> <li>Head Projection Defense (new!)</li> </ol> <ul> <li> <p>\ell번째 레이어의 logit lens distribution 즉각 보정</p> </li> <li> <table> <tbody> <tr> <td>\frac{1}{</td> <td>L</td> <td>}\sum max(0,D(\ell){answer} - D(\ell){k}+m)</td> </tr> </tbody> </table> </li> <li> <p>k = k-th top prob in D(\ell)</p> </li> <li>m = margin term. optimize하는 contraint가 없어서 그냥 tune.</li> </ul> <ol> <li>Max-Entropy Defense. (new!)</li> </ol> <ul> <li>maximize the entropy of the model’s logit lens distributions over the next token at each layer:</li> </ul> <ol> <li>Input Rephrasing Defense.(new!)</li> </ol> <ul> <li>새롭게 만들어진 모든 paraphrased ver에 대한 Fact Erasure 수행.</li> </ul> <h1 id="experiment">EXPERIMENT</h1> <h2 id="setup">SETUP</h2> <ul> <li> <p>Models</p> <ul> <li> <p>GPT-J</p> </li> <li> <p>llama2</p> </li> <li> <p>gpt2-xl</p> </li> </ul> </li> <li> <p>Datasets</p> <ul> <li> <p>CounterFact: factual completions + neighboring datapoints</p> </li> <li> <p>zsRE: short question-answer pairs derived from Wikipedia</p> </li> <li> <p>위의 두 가지 데이터셋에 대해서, 정답을 생성하는 것들만 sampling -&gt; 587,454</p> </li> </ul> </li> <li> <p>Model Editing Methods.</p> <ul> <li> <p>ROME</p> </li> <li> <p>MEMITxhdxhdwkdd</p> </li> </ul> </li> </ul> <h2 id="result">RESULT</h2> <h3 id="can-we-extract-a-deleted-answer-from-a-language-model">CAN WE EXTRACT A “DELETED” ANSWER FROM A LANGUAGE MODEL?</h3> <p>세팅: gpt-j, counterfact dataset, ROME editing with empty respose objectvie, Rewrite Score is high for all methods (90%+), with low Random ∆-Acc scores (&lt;1%)</p> <figure> <picture> <img src="/assets/img/posts/2024-02-13-can-sensitive-information-be-deleted-from-llms-objectives/image_001.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>결과를 통해서 확인할 수 있듯, B=20을 이용했을 때, attack success ratesms 38%를 넘어간다. 즉, 제대로 지워지지 않았음을 의미!</p> <p>whitebox뿐만 아니라, blackbox에서도 29%의 성공을 보였다.</p> <p>B=1일때도 사실, delat atttack에서 18%의 공격 성공률을 보였다.</p> <p>흥미롭게도 B=20을 넘어가면, 모든 방법론들은 saturate.</p> <h3 id="how-to-defend-against-information-extraction-attacks">HOW TO DEFEND AGAINST INFORMATION EXTRACTION ATTACKS</h3> <figure> <picture> <img src="/assets/img/posts/2024-02-13-can-sensitive-information-be-deleted-from-llms-objectives/image_002.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>결과를 해석해보면 다음과 같다:</p> <ol> <li> <p>whitebox and blackbox attacks are all frequently successful at extracting “deleted” facts. -&gt; 다른 말로는 여전히 정보들이 지워지지 않았다.</p> </li> <li> <p>MEMIT with the Empty Response defense is successfully attacked by our Head Projection attack 89% of the time on zsRE</p> </li> <li> <p>Head Projection and Max-Entropy defenses are the strongest defenses against whitebox attacks.</p> </li> <li> <p>Input Rephrasing defense does not reduce the blackbox attack success.</p> </li> <li> <p>MEMIT is generally higher than against ROME,</p> </li> </ol> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>