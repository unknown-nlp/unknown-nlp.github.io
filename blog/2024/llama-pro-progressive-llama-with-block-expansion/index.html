<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> LLAMA PRO: Progressive LLaMA with Block Expansion | You R. Name </title> <meta name="author" content="You R. Name"> <meta name="description" content=" 논문 리뷰 - LLAMA PRO: Progressive LLaMA with Block Expansion"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/al-folio/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/al-folio/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/al-folio/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/al-folio/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://alshedivat.github.io/al-folio/blog/2024/llama-pro-progressive-llama-with-block-expansion/"> <script src="/al-folio/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/al-folio/"> <span class="font-weight-bold">You</span> R. Name </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/al-folio/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/al-folio/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/al-folio/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">LLAMA PRO: Progressive LLaMA with Block Expansion</h1> <p class="post-meta"> Created on May 21, 2024 </p> <p class="post-tags"> <a href="/al-folio/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/al-folio/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   <a href="/al-folio/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> nlp</a>   ·   <a href="/al-folio/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2024-05-21</li> <li> <strong>Reviewer</strong>: hyowon Cho</li> <li> <strong>Property</strong>: LLM, Continual Learning</li> </ul> <h2 id="introduction">Introduction</h2> <p>더 큰 모델을 만들기 위해 애쓰고 있는 현실. 하지만, 자원이 한정되어있는 이상 우리가 모델의 크기를 무한정 키우는 것은 불가능하기에 MOE와 같은 다양한 방법들이 나오고 있다.</p> <p>이러한 방법은 효과적으로 LLM을 scale-up할 수 있지만, 여전히 학습과 추론의 단계에서 non-trivial한 변화를 만들어야 한다는 점에서 widespread applicability를 보장한다고 할 수 없다. 즉, 단순성이 필요하다는 것이다.</p> <p>해당 논문의 저자들은 이러한 한계점을 돌파하기 위해 depth up-scaling을 제안한다. 이 방식으로 만든 10.7b모델이 llama2 70b 모델, mistral 8x7b 모델에 준하는 성능을 보이고 있다고 하니, DUS를 좀 더 파고들어보자.</p> <h2 id="depth-up-scaling">Depth Up-Scaling</h2> <ul> <li>Base model. llama2 architecture에 Mistral 7b weight를 가져와서 사용.</li> </ul> <h3 id="depthwise-scaling">Depthwise scaling.</h3> <ul> <li> <p>notation</p> <ul> <li> <p>n: base_model의 layer 수</p> </li> <li> <p>s: target layer count</p> </li> </ul> </li> <li> <p>process</p> <p>당연히 단순한 Merging만으로 성능이 오르는 것이 아니라, continual pretraining을 수행함. 하지만 요점은, 아주 빠른 성능의 복구가 일어났다는 것.</p> </li> </ul> <p>논문 상에 얼마나 continual pretraining을 했는지는 나와있지 않음.</p> <p><br></p> <p>이렇게 초반부를 잘라서 merging하는 방식 외에도, 사실 단순히 레이어를 다시 얹어서 반복하는 방식으로 크기를 키울 수 있을 것이다. 하지만, 이러한 방식은 layer간의 discrepency가 강해지기에 성능 복구하는데 더 오랜 시간이 걸린다고 한다. 중간 단을 merging하는 방식으로 heterogeneity를 낮췄기 때문에 모델 입장에서 성능 복구가 가능하다는 주장!</p> <blockquote> <p>iDUS</p> </blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[https://github.com/gauss5930/iDUS](https://github.com/gauss5930/iDUS)

	## Results
</code></pre></div></div> <h3 id="experimental-details">Experimental Details</h3> <ul> <li> <p>2 stage</p> <ol> <li> <p>instruction tuning: QA format</p> </li> <li> <p>alignment tuning: sDPO</p> </li> </ol> </li> <li> <p>dataset</p> <ul> <li> <p>일부분만 sample하여 사용한 경우도 있음.</p> </li> <li> <p>alpaca-styled chat template</p> </li> <li> <p>6 evaluation tasks</p> <p><br></p> </li> </ul> </li> <li> <p>model merging</p> <ul> <li> <p>avergage</p> </li> <li> <p>slerp</p> </li> </ul> </li> </ul> <h3 id="experiments">Experiments</h3> <p><br></p> <p>뒷 부분은 alignment/instruction/merging의 ablation이므로 생략함</p> <p>LLM은 여전히 programming, mathematics, biomedical, finance과 같은 특정 도메인에서 부족한 점이 있다. 이에 따라 선행 연구들은 tailored data recipe를 이용해서 LLM의 능력을 향상시키려 했지만, 이는 많은 자원과 데이터를 필요로 하므로, 현실적으로 모든 연구자들이 사용할 수 있는 해결 방안은 아니다. 이에 따라, another line of research로 domain-adaptive pretraining(DAPT)를 이용해 이러한 문제를 개선하려 하지만, catastrophic forgetting 문제가 발생한다.</p> <p>해당 연구에서는 이를 해결하기 위해, <strong>block expansion</strong> 라는 post-pretraining method를 제안한다.</p> <p>이 방법은 Transformer 블록을 복사하여 LLM을 확장하고, domain-specific 코퍼스로만 추가 조정하여 모델의 일반 및 domain-specific 작업 모두에서 뛰어난 성능을 보이게 한다.</p> <h2 id="method">Method</h2> <h3 id="preliminaries-the-llama-block">Preliminaries: The LLaMA Block</h3> <p>LLaMA block을 구성하는 요소들은 다음과 같다:</p> <ul> <li> <p>multi-head self-attention (MHSA) mechanism</p> </li> <li> <p>position-wise feed-forward network (FFN)</p> </li> <li> <p>residual connections</p> </li> <li> <p>Swish-Gated Linear Unit (SwiGLU)</p> </li> </ul> <h3 id="block-expansion">Block Expansion</h3> <p>model with blocks (ϕ0, ϕ1, …, ϕL)이 있을 때, block expansion은 identity block ϕid를 각 original model block 다음에 붙이는 것이다. 이때, expanded model은 expansion 후에도 기존 output을 정확히 유지한다.</p> <blockquote> <p>identity block is defined as ϕid(x) = x, where the input and output are identical.</p> </blockquote> <p>이때, 모델이 L개의 block을 가진다고 할 때, 다음의 절차를 거친다.</p> <ol> <li> <p>partition the original L blocks into N groups.</p> <ul> <li>각 group은 L/N의 block을 가짐</li> </ul> </li> <li> <p>각 group 당, top P blocks에 대해 identity copies를 만든다.</p> </li> <li> <p>stack them on top of each group.</p> </li> </ol> <p>이때 특정 위치(아래, 위, 중간)에만 넣지 않은 이유는, transfomer의 구조상, deeper block이 더 복잡한 정보를 encode한다는 선행연구들이 많기 때문.</p> <blockquote> <p>initialization 관련해서도, 0으로 설정한 이유를 appendix에서 수학적으로 증명해놓음.</p> </blockquote> <p>이후, domain-specific knowledge를 학습할 때는 추가된 블락에 대해서만 학습 진행.</p> <h2 id="experiments-1">Experiments</h2> <h3 id="experimental-settings">Experimental Settings</h3> <ul> <li> <p>pretrain detail</p> <ul> <li> <p>dataset</p> <ul> <li> <p>code: Stack-dedup dataset</p> </li> <li> <p>math: Proof-pile-2</p> </li> </ul> </li> <li> <p>base model</p> <ul> <li>llama2-7b</li> </ul> </li> <li> <p>config</p> <ul> <li> <p>P top block: 1</p> </li> <li> <p>N 그룹 수: 8</p> </li> </ul> </li> <li> <p>gpu time</p> <ul> <li>(16 NVIDIA H800 GPUs for about 7 days)</li> </ul> </li> </ul> </li> <li> <p>SFT details.</p> <ul> <li> <p>instruction fine-tuning dataset</p> <ul> <li>ShareGPT1, WizardLM, CodeAlpaca, MetaMath, SlimOrca</li> </ul> </li> <li> <p>fully fine-tuning of all the blocks</p> </li> </ul> </li> </ul> <h3 id="results">Results</h3> <h3 id="pretrain-results">Pretrain Results</h3> <h3 id="sft-results">SFT Results</h3> <p>MINT-Bench tests LLMs’ ability to use tools by generating and executing Python code, focusing on tool-augmented task-solving and leveraging natural language feedback. MINT includes eight datasets covering reasoning, code generation, and decision-making.</p> <h3 id="ablation-study">Ablation Study</h3> <ul> <li>LoRA vs SeqFT vs BE</li> </ul> <p>TRACE is designed to assess continual learning in LLMs and comprises eight distinct datasets that span challenging tasks such as domain-specific tasks, multilingual capabilities, code generation, and mathematical reasoning.</p> <hr> <p><br></p> <p><br></p> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 You R. Name. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/al-folio/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/al-folio/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/al-folio/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/al-folio/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/al-folio/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/al-folio/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/al-folio/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/al-folio/assets/js/search-data.js"></script> <script src="/al-folio/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>