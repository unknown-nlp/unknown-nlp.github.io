<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> QCRD: Quality-guided Contrastive Rationale Distillation for Large Lanauge Models | Unknown NLP Papers </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content=" 논문 리뷰 - QCRD: Quality-guided Contrastive Rationale Distillation for Large Lanauge Models"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknownnlp.github.io/blog/2024/qcrd-quality-guided-contrastive-rationale-distillation-for-large-lanauge-models/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Papers </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">QCRD: Quality-guided Contrastive Rationale Distillation for Large Lanauge Models</h1> <p class="post-meta"> Created on October 03, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   ·   <a href="/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2024-10-03</li> <li> <strong>Reviewer</strong>: 전민진</li> <li> <strong>Property</strong>: Knowledge Distillation</li> </ul> <h2 id="abstract">Abstract</h2> <ul> <li> <p>LLM은 좋은 성능을 갖고 있으나 resource 제한, inference 효율성 등으로 다양한 application에서 사용되기엔 한계가 존재</p> </li> <li> <p>최근 LLM을 기반으로 한 knowledge distillatinon으로 smaller, task-specific한 모델을 학습하는 여러 방법론이 제안 됨</p> </li> <li> <p>하지만 기존 연구들은 knowledge의 disversity와 quality에 크게 집중하지 않음.</p> <ul> <li>특히, negative knowledge을 distillation에 사용하지 않음</li> </ul> </li> <li> <p>본 논문에서는 constrative knowledge learning을 통한 reasoning capability 향상을 목표로 하는 quality-guided contrstive rationale distillation(QCRD)을 제안</p> <ul> <li> <p>특히 small lm의 이전 iteration모델에서 rationale을 sampling, negative로 사용</p> </li> <li> <p>discriminator를 같이 학습하여 rationale의 pos, neg를 판별, quality score를 계산해 이를 학습에 반영</p> </li> </ul> </li> <li> <p>실험 결과, 기존의 distillation method보다 뛰어난 성능을 보임</p> </li> </ul> <h2 id="introduction">Introduction</h2> <ul> <li> <p>LLM의 모델 크기가 커지면서 reasoning ability가 발생 → 이를 이용해 작은 모델을 학습하자</p> <ul> <li>하지만 아직도 LLM과 distilled small model간의 성능 차이가 심한 task가 reasoning task</li> </ul> </li> <li> <p>이를 해소하기 위한 다양한 방법이 제안</p> <ul> <li> <p>LLM이 생성한 rationale을 생성하도록 small LM을 학습하는 방법(distill step-by-step )</p> <ul> <li> <p>$ L = L<em>{prediction}+\lambda L</em>{generation} $</p> </li> <li> <p>이 방법의 경우 postivie knowledge만 사용, knowledge가 한정적이고 noisy가 있을 수 있음</p> </li> </ul> </li> <li> <p>LLM이 생성한 rationale을 golden answer로 보고 작은 모델이 생성한 rationale과 정답의 차이를 줄이도록 하는 연구도 존재</p> <ul> <li>대부분 LLM의 zero-shot/few-shot 결과를 그대로 사용, reaosning step에서 오류가 발생할 확률이 높음</li> </ul> </li> </ul> <p>⇒ 하지만 이러한 방법들 모두 negative rationale을 생성해서 학습에 사용하진 않음</p> </li> <li> <p>본 논문에서는, Quality-guided Contrastive Rationale Disilltation(QCRD)을 제안</p> <ul> <li> <p>positive example : LLM이 생성한 rationale 중 self-consisteny O</p> </li> <li> <p>negative example : LLM이 생성한 rationale중 self-consistency X + previous iteration student model이 생성한 rationale (with high temp)</p> </li> <li> <p>discriminator가 rationale의 quality를 계산, 이를 학습에 반영</p> </li> <li> <p>QCRD의 우수성을 입증하기 위해서, T5-base(220M), small(60M)을 student로 사용해 실험 진행, 여러 벤치마크 데이터셋에서 우수한 성능을 보임</p> </li> </ul> </li> </ul> <h2 id="related-work">Related Work</h2> <ul> <li> <p>Multi-task learning with LLM generated ratioanles</p> <ul> <li> <p>기존에 rationale을 바탕으로 하는 여러 KD 방법론이 제안</p> </li> <li> <p>rationale을 학습에 활용하는 것이 효과가 있다는 것이 밝혀져 있음</p> </li> <li> <p>이전에는 multi-task learning framework방식으로, prefix를 기반으로 모델이 label을 예측하면서 동시에 rationale도 생성할 수 있도록 학습, 내재적으로 rationale에 있는 knowledge를 학습하도록 함</p> </li> <li> <p>하지만 smalle model의 rationale과 LLM의 rationale이 align 되도록 하나의 loss form에만 집중</p> </li> </ul> </li> <li> <p>Contrastive learning for LLMs</p> <ul> <li>LLM에 contrastive leraning을 하는 방법론이 기존에 많이 제안되었으나, CoT distillation쪽에선 한번도 차용되지 않음</li> </ul> </li> </ul> <h2 id="methodology">Methodology</h2> <ul> <li> <p>QCRD는 3가지 파트로 구성이 되어 있음</p> <ul> <li> <p>multi-task learning framework : L = prediction_loss + CL_loss</p> </li> <li> <p>generate contrastive knowledge from LLM and student model</p> </li> <li> <p>quality-guided contrastive learning strategy</p> <ul> <li>positive와 negative를 구별하는 online-updated discriminator의 guidance를 사용</li> </ul> </li> </ul> </li> </ul> <p><strong>Multi-task learning framework for the student model</strong></p> <ul> <li> <p>이전 연구와 유사하게 prefix를 활용해서 small model이 다양한 형태의 output을 생성할 수 있도록 학습</p> <ul> <li> <p>for prediction label task, <predict></predict></p>
      </li>
      <li>
        <p>for rationale generatrion task, <explain></explain></p>
      </li>
    </ul>
  </li>
</ul>

<p><strong>Generation of contrastive knowledge</strong></p>

<ul>
  <li>
    <p>Positive sample</p>

    <ul>
      <li>
        <p>CoT prompting with sampling using LLM</p>

        <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>- 각 data마다 K개의 rationale을 생성, self-consisteny를 만족하는 rationale을 positive로 사용
</code></pre></div> </div> </li> </ul> </li> <li> <p>Negative sample</p> <ul> <li> <p>위에서 self-consistency를 만족하지 못한 rationale을 negative rationale로 봄</p> <ul> <li> <p>self-consistency방법론 특성상 negative가 positive에 비해 적음</p> </li> <li> <p>LLM이 생성한 negative는 student가 봤을 땐, positive처럼 보일 수 있음 → 학습 효과가 떨어짐</p> </li> </ul> </li> <li> <p>이전 iteration의 student model에 high temperature를 사용해서 rationale을 sampling</p> <p>→ low quality rationale이라 판단, negative로 사용</p> </li> <li> <p>$ \mathbf{x} = [x_1, x_2,..,x_n], S<em>{pos}={r_1^{pos},…,r_m^{pos}}, S</em>{neg} = {r_1^{neg},..,r_k^{neg}} $</p> </li> </ul> </li> </ul> <p><strong>Constrastive knowledge distillation</strong></p> <ul> <li> <p>Train a discriminator to judge rationales</p> <ul> <li> <p>같은 question에 대한 rationale의 quality는 상이, 하지만 학습하면 할수록 student가 생성하는 rationale은 positive rationale과 가까워질 것</p> <ul> <li>무작정 student model이 생성했다고 계속 negative로 보는 것은 합리적이지 않을 수 있음</li> </ul> </li> <li> <p>그래서 효과적으로 positive와 negative rationale를 판별, quality score를 계산해줄 discriminator가 필요</p> </li> <li> <p>Discriminator에 input으로 question과 rationle을 넣고, score를 계산하도록 함</p> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>	- discriminator로는 encoder architecture를 사용

- T5-base의 encoder를 사용, max pooling layer랑 2개의 linear layer를 추가

- 학습 전에 LLM이 생성한 rationale로 pretrain진행(with 500 max step), pos와 neg의 비율을 맞춰주기 위해 word_mask and replacement로 data augmenatation.

- online-updated during training
</code></pre></div> </div> </li> <li> <p>LLM으로 생성한 positive, negative로 D를 pretrain, 학습 동안에는 D를 regular epoch interval로 업데이트</p> <ul> <li>Quality-guided contrastive distillation</li> </ul> </li> <li> <p>위의 단계로 여러 positive, negative sample을 수집</p> <p>→ many-to-one contrastive distillation loss를 사용</p> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>	- $ l(f(\mathbf{x}_i),s_{pos}^i)=min_{r_{j}^{pos,i}\in S^i_{pos}}\{l(f(\mathbf{x}_i),r_j^{pos,i})\} $

- 모델이 생성한 rationale과 가장 유사한 postivie rationale과의 Cross entropy loss
</code></pre></div> </div> <ul> <li> <p>$ l(f(\mathbf{x}<em>i),s</em>{pos}^i)=min<em>{r</em>{j}^{neg,i}\in S^i_{neg}}{l(f(\mathbf{x}_i),r_j^{neg,i})} $</p> <ul> <li>negative는 가장 차이 많이 나는 것 선택</li> </ul> </li> <li> <p>$ l(f(\mathbf{x}),r_j^{neg})=min(l(f(\mathbf{x},r^{neg}_j))-\delta,0) $</p> <ul> <li>너무 단순한 neg는 거르기 위해 margin사용</li> </ul> </li> </ul> </li> <li> <p>또한, student model이 생성했다고 해서 무조건 negative로 볼 경우, 학습이 진행되면서 local optima에 빠질 수 있기 때문에 discriminator를 사용하는 quality-guided distillation을 사용</p> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>	- Discriminator로 quality score s를 계산, pos의 경우 quality가 높으면 더 학습에 반영되도록, neg의 경우 quality가 높으면 학습에 덜 반영되도록 함
</code></pre></div> </div> </li> </ul> </li> <li> <p>Training loss</p> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>- 이 total loss를 보면 최종적으론 student model의 encoder를 똑 떼서 discriminator로 학습한다는 느낌같은데.. 확실히 맞는지 모르겠음
</code></pre></div> </div> </li> </ul> <h2 id="experiments">Experiments</h2> <p><strong>Datasets</strong></p> <ul> <li> <p>SVAMP : arithmetic word problem solving</p> </li> <li> <p>CQA : commonsense QA</p> </li> <li> <p>e-SNLI, ANLI : NLI</p> </li> <li> <p>rationale을 GPT-3.5-turbo로 생성</p> </li> </ul> <p><strong>Implementation details</strong></p> <ul> <li> <p>T5-base(220M),T-small(60M)사용</p> </li> <li> <p>$ \alpha_1,\alpha_2,\alpha_3 $은 실험적으로 0.5으로 세팅 $ \alpha_3 $은 매 iteration마다 0.9를 곱함</p> </li> <li> <p>$ \beta=0.2,\delta=3 $</p> </li> <li> <p>LLM temp 0.7로 5번 샘플링, small model은 5-iteration-before model에서 temp 1.5로 1개 샘플링</p> </li> </ul> <p><strong>Baselines</strong></p> <ul> <li> <p>Fintuning</p> </li> <li> <p>Single-supervision : teacher model이 예측한 label을 맞추도록 학습</p> </li> <li> <p>DSS : multi task learning with label prediction and rationale generation</p> </li> <li> <p>MI : DSS기반에 prediction label과 rationale사이의 mutual information이 최대화하도록 task 추가</p> </li> </ul> <p><strong>Experimental result</strong></p> <ul> <li> <p>Experiments across four benchmarks</p> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>	- 다른 유사한 CoT distillation 방법론과 비교해도 높은 성능을 보임
</code></pre></div> </div> </li> <li> <p>Distillation with LLM labels</p> <ul> <li> <p>ground truth를 사용하지 않고, LLM이 생성한 label로 학습했을 때의 실험</p> <ul> <li> <p>temperature sampling, self-consistency의 효과로 noisy label을 사용해도 비교적 높은 성능을 보임</p> <ul> <li>이전에 SC로 rationale을 pos랑 neg로 분류했다더니.. 아니었나..?</li> </ul> </li> </ul> </li> <li> <p>Distillation with smaller datasets</p> </li> <li> <p>Ablation study on QCRD</p> </li> <li> <p>ED : sample the outputs of the LLM and leverage the self-consistency to denoise rationales</p> </li> <li> <p>NK : generator low-quality rationaels as negative rationales</p> </li> <li> <p>QJ : use of discriminator</p> </li> </ul> <h2 id="discussion">Discussion</h2> </li> <li> <p>Different contrastive distillation schemes</p> <ul> <li> <p>min-max방식이 가장 좋더라!</p> </li> <li> <p>influence of negative sample</p> </li> <li> <p>5번 전 iteration의 모델로 negative를 만들때가 가장 효과적</p> </li> <li> <p>Fixed의 경우 DSS로 학습된 모델이 생성한 rationle을 negative로 썼을 때</p> </li> <li> <p>Assessment for generated rationales</p> </li> <li> <p>GPT-3.5로 DSS와 QCRD로 만든 rationale중 무엇이 더 좋은지 평가</p> </li> <li> <p>DSS win / tie / QCRD win</p> </li> <li> <p>QCRD가 더 좋은 rationale을 생성한다!</p> </li> <li> <p>Distribution of rationale quality scores</p> </li> <li> <p>확실히 좋은 rationale과 나쁜 rationale은 잘 scoring하는 것을 볼 수 있음</p> </li> </ul> <h2 id="conclusion">Conclusion</h2> </li> <li> <p>Contrastive learning을 CoT distillation에 접목한 최초의 논문!</p> </li> </ul> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>