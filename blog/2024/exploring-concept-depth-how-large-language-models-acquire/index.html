<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers? | Unknown NLP Papers </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content="논문 리뷰"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknownnlp.github.io/blog/2024/exploring-concept-depth-how-large-language-models-acquire/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Papers </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?</h1> <p class="post-meta"> Created on April 23, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/classification"> <i class="fa-solid fa-hashtag fa-sm"></i> classification</a>   <a href="/blog/tag/language-model"> <i class="fa-solid fa-hashtag fa-sm"></i> language-model</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   <a href="/blog/tag/reasoning"> <i class="fa-solid fa-hashtag fa-sm"></i> reasoning</a>   ·   <a href="/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2024-04-23</li> <li> <strong>Reviewer</strong>: hyowon Cho</li> </ul> <h1 id="introduction">Introduction</h1> <p>최근 더 큰 모델이 더 좋은 성능을 보인다는 믿음에 힘입어 많은 연구자들이 모델의 크기를 키우는데 더 깊은 네트워크를 만드는데 집중하고 있다. 하지만 여전히 LLM의 네트워크 깊이와 conceptual understanding의 연관 관계를 empirical하게 보이는 연구는 많지 않다.</p> <p>둘의 연관관계를 보이는 연구는 크게 두 가지 관점으로 진행된다.</p> <ol> <li>analyzing model weights and architectures</li> </ol> <ul> <li>pruning을 통해 어떤 layer 혹은 param을 제거해도 성능에 변화가 없는지 확인</li> </ul> <ol> <li>probing representations</li> </ol> <p>이 연구에서는 각기 다른 모델이 각기 다른 데이터셋에서 어떻게 지식을 이해하는지 측정하기 위해 “Concept Depth”라는 개념을 제안한다. 방법은 아주 간단하다.</p> <ol> <li> <p>capture the feature responses of different layers of the LLMs for different datasets</p> </li> <li> <p>use independent linear probes to indicate the best performance that the current layer can achieve</p> </li> </ol> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_000.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>간단한 방법론이지만, 그럼에도 불구하고 1) 다양한 크기의 LLM들이 어디서 학습을 진행했는가에 대한 비교 및 일반적인 양상 포착 2) robustness 적인 측면에서 기여가 있다고 할 수 있겠다!</p> <blockquote> <p>즉 오늘 발표는 아주 가볍게 들어주시면 되겠습니다 😊</p> </blockquote> <h1 id="related-work">Related Work</h1> <h3 id="concepts-representation-in-dnns">Concepts representation in DNNs</h3> <p>연구자들은 DNN의 지식습득의 과정을 인간이 이해할 수 있는 방식으로 묘사한다. 주목할만한 부분은 ‘representation bottleneck,’이라고 불리는 것으로, 사람과 DNN간의 인지적 부조화를 의미한다. 즉, 사람이 다양한 예시들 사이에서 유사점을 찾아 개념을 형성한다고 할 때, DNN은 인간과 달리, 너무 단순하거나 지나치게 복잡한 개념을 파악하는 경향이 있다는 것이다. 즉, ‘적당한’ 복잡성의 개념을 습득하는데 어려움을 겪는다.</p> <p>이 연구에서는 이렇게 인간이 이해할 수 있는 방식으로 설명을 이어나가기 위해, 다양한 복잡성의 개념을 다루며 LLM을 설명한다.</p> <h3 id="knowledge-and-concepts-in-llms">Knowledge and concepts in LLMs</h3> <p>LLM에 관한 가장 뜨거운 논쟁은 LLM이 정말 개념 자체를 이해하고 있는지 혹은 단순히 앵무새일 뿐인지이다. 이 연구에서는 LLM이 개념 자체를 이해하고 있다는 전제하에서 진행되며 그 근거는 다음과 같다:</p> <ul> <li> <p>Gurnee and Tegmark [14] showed that LLMs internally store concepts like latitude, longitude, and time.</p> </li> <li> <p>another work showed that the truth of a statement can be detected from the internal state of LLMs [4].</p> </li> <li> <p>Geva et al. [12] also came to similar conclusions by artificially blocking or “knocking out” specific parts of the LLMs to observe their effects on the inference process.</p> </li> </ul> <p>즉, 개념을 이해한다는 전제 하에, 그렇다면 개념의 복잡도에 따라 어떻게 LLM에서 다르게 이해하는지를 평가해본다고 보면 되겠다!</p> <h1 id="analyzing-method">Analyzing Method</h1> <h3 id="visualizing-layer-wise-representations">Visualizing Layer-wise Representations</h3> <p>각 레이어의 representation들을 뽑아, 시각화를 위해 PCA를 진행한다. 예를 들어, 다음의 그림을 보자</p> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_001.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>위의 그림은 Counterfact 데이터셋에서 fact인 데이터와 counterfact인 데이터에 대해서 80% 깊이의 Gemma-7b 모델에 넣어 representation을 구해 시각화한 결과이다 즉, 이 깊이에서 두 개념 자체를 잘 분리해내고 있음을 확인할 수 있다.</p> <h3 id="linear-classifier-probing">Linear Classifier Probing</h3> <p>각 레이어가 final prediction에 기여하는 바를 더 자세히 분석하기 위해서, Linear classifier를 학습시켜 사용한다.</p> <p>주어진 작업 w에 대해,</p> <ul> <li> <p>LLMs의 hidden feature set은 x ∈ R^n×dmodel로 표현된다.</p> </li> <li> <p>n은 샘플의 수를,</p> </li> <li> <p>x(i) ∈ R^1×dmodel은 특정 레이어에서의 representation을 나타낸다.</p> </li> <li> <p>binary 레이블 y(i)는 0 또는 1로 설정된다.</p> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_002.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>즉, binary logistic regression classifier with L2 regularization이다! 그리고, 각 layer 별로 다 학습을 진행하는 것을 볼 수 있다.</p> <h1 id="experimental-setting">Experimental Setting</h1> <h3 id="models">Models</h3> <ul> <li> <p>Gemma (2B, 7B)</p> </li> <li> <p>LLaMA (7B, 13B)</p> </li> <li> <p>QWen (0.5B,1.8B, 4B, 7B, and 14B)</p> </li> </ul> <p>linear classifier를 만들 때는, each layer의 마지막 feature representation을 사용.</p> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_003.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="dataset">Dataset</h3> <ul> <li> <p>nine datasets</p> <ul> <li> <p>fact/factual analysis (Cities[22], CommonClaim[7], Counterfact[24])</p> </li> <li> <p>emotion (STSA[17], IMDb[20], Sarcasm[25], HateEval [21])</p> </li> <li> <p>inference/logical reasoning (StrategyQA[11], Coinflip[34])</p> </li> </ul> </li> </ul> <div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Cities [22]: consists of statements about the location of cities and
their veracity labels (e.g., The city of Zagreb is in Japan, which is
wrong).

CommonClaim [7]: A dataset of boolean statements, each labeled
by two humans as common-knowledge-true, common-knowledgefalse, or neither.

Counterfact [24]: Counterfact includes thousands of counterfactuals along with text that allows quantitative testing of specificity and
generalization when learning a counterfactual.

HateEval [21]: HateEval has English tweets which were annotated
hierarchically.

STSA [17]: STSA includes movie reviews, half of which were considered positive and the other half negative. Each label is extracted
from a longer movie review and reflects the writer’s overall intention
for this review.

IMDb [20]: IMDb is a benchmark dataset for binary sentiment classification.
Sarcasm [25]: Sarcasm is a high-quality news headlines dataset that
is annotated as sarcastic or not sarcastic.

StrategyQA [11]: StrategyQA contains questions across all knowledge domains to elicit creative and diverse yes/no questions that require implicit reasoning steps.

Coinflip [34]: Coinflip includes questions about coin flipping. This
task requires the model to determine if a coin remains heads up after
it is either flipped or left unflipped by individuals.

</code></pre></div></div> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_004.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>LLM의 성능에 따라 easy ~ complex로 구분</p> <ul> <li> <p>initial or middle depth of the LLMs에서 좋은 성능을 보이는 데이터는 easy</p> </li> <li> <p>large fluctuations and stable classification accuracy occurring at the deep depth of the LLMs을 보이는 데이터는 complex</p> </li> </ul> </li> </ul> <h3 id="the-robustness-of-internal-representations">The Robustness of Internal Representations</h3> <h3 id="adding-noise">Adding Noise</h3> <p>input question의 앞에 random string을 붙이는 방식으로 noise 추가. 50%의 데이터에 추가되어있음.</p> <h3 id="quantization-settings">Quantization Settings</h3> <p>quantization을 했을 때는 어떻게 달라질까? -&gt; Quantization is set as 8-bit, 16-bit, and full 32-bit.</p> <h3 id="metrics-for-accuracy-variation">Metrics for Accuracy Variation</h3> <ul> <li> <p>Variation Rate</p> <ul> <li> <p>i-th layer의 acc = a_i</p> </li> <li> <p>vartiation rate β<em>i = a_i/a</em>{i-1}</p> </li> </ul> </li> </ul> <p>2가지 acc metric을 소개한다: (1) jump point (2) coveraging point</p> <ol> <li> <p><strong>Jump Point</strong> We denote J(M, D) = min{\frac{i}{d}} s.t. β_i &gt;= 1.1, i ∈ {1, 2, …, d − 1}, as the jump point, where $M$ and $D = (q, y)$ represents the LLM classifier and the dataset. 즉, 성능 상 주목할만한 향상이 있을 때, 그 지점을 jump point라고 부른다.</p> </li> <li> <p><strong>Converging Point</strong> We denote C(M, D) = max{\frac{i}{d}} s.t. |β_i − 1| &lt; 0.03, i ∈ {1, 2, …, d − 1} s.t. , as the converging point, where M and D = (q, y) represents the LLM classifier and the dataset.</p> </li> </ol> <p>정확도가 유지 혹은 줄어들기 시작하면, saturation이 일어났다고 본다.</p> <h1 id="experimental-analysis">Experimental Analysis</h1> <p>다음의 세 가지 research question을 가지고 실험을 진행한다 .</p> <ul> <li> <p>RQ1: Do different LLMs’ concept depths behave consistently in the same dataset? (Section 5.1)</p> </li> <li> <p>RQ2: Do different size LLMs but the same series (e.g., Gemma series) have consistent Concept Depth? (Section 5.2)</p> </li> <li> <p>RQ3: Do LLMs’ Concept Depth of the same size behave consistently? (Section 5.3)</p> </li> </ul> <h2 id="comparison-among-the-datasets">Comparison Among the Datasets</h2> <blockquote> <p>RQ1: Do different LLMs’ concept depths behave consistently in the same dataset? (Section 5.1)</p> </blockquote> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_005.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ol> <li> <p>LLMs은 다루는 개념에 따라, layer에서 다른 양상을 보였다. 하지만, 같은 개념은 다양한 LLM들에서 일관된 양상을 보였다.</p> </li> <li> <p>다양한 레벨의 conceptual understanding이 필요한 태스크의 경우, LLMs은 여러 레이어에 걸쳐가며 처리를 하는 양상을 보였다 ==&gt; indicating a layered approach to processing complex concepts</p> </li> </ol> <h3 id="fact-concept">Fact Concept</h3> <ul> <li> <p>Cities: 낮은 레이어에서 sharp increase, stabilize in the highter layer == 개념 자체를 아주 강하게 이해</p> </li> <li> <p>CommonClaim: stabilize in the lower layer</p> </li> <li> <p>Counterfact: utilizing deeper layers, low acc –&gt; complex!</p> </li> </ul> <h3 id="emotional-concept">Emotional Concept</h3> <p>모든 task가 initial layer에서 rise. intermediate layer에서 converge</p> <ul> <li>-&gt; LLM이 low layer에서 emotional concept 잡고있음</li> </ul> <h3 id="reasoning-skills">Reasoning Skills</h3> <p>display a bell-shaped accuracy trajectory in all models, 즉 peak는 중간에서!</p> <h3 id="remarks">Remarks</h3> <p>classification tasks의 성능은 세 가지 타입으로 묶을 수 잇다.</p> <ol> <li> <p>For Cities, STSA, IMDb, and Sarcasm, the LLMs suddenly understand the tasks at intermediate layers.</p> </li> <li> <p>For CommonClaim and HateEval, the LLMs have already understood the tasks in shallower layers.</p> </li> <li> <p>For Counterfact, StrategyQA, and Coinflip, The tasksare more difficult to understand, compared with others.</p> </li> </ol> <p>따라서, 1,2를 easy, 3을 complex task라고 분류한다.</p> <h2 id="comparison-among-the-number-of-parameters">Comparison Among the Number of Parameters</h2> <ul> <li>RQ2: Do different size LLMs but the same series (e.g., Gemma series) have consistent Concept Depth? (Section 5.2)</li> </ul> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_006.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>figure는 두가지의 반복되는 패턴을 보인다.</p> <ol> <li> <p>큰 모델이 earlier layer에서 converging point가 나타난다</p> </li> <li> <p>큰 모델이 더 좋은 peak를 가졌다. 즉, 모델의 사이즈를 키우는 것이 그것의 효과성 뿐만이 아니라 robust internal representation을 형성함을 보인다.</p> </li> </ol> <p>→ 개인적으로는 더 큰 모델일수록 earlier layer라고는 하지만, 결국 개수가 더 많으니까 본 layer의 수는 비슷/동일하지 않을까싶네요! 혹은 당연한 이야기지 않나.. — 결국 개수!</p> <p>→ 그렇지만 데이터셋별로 그래프가 비슷한건 신기!</p> <hr> <h3 id="remark">Remark</h3> <p>By comparing different sizes of models from the same LLM family, we have two observations.</p> <ol> <li> <p>As the number of parameters increases, peak accuracy gradually increases, and the converging point gradually advances.</p> </li> <li> <p>Larger models grasp the concepts earlier and better.</p> </li> </ol> <h2 id="comparison-among-the-llm-families">Comparison Among the LLM Families</h2> <ul> <li>RQ3: Do LLMs’ Concept Depth of the same size behave consistently? (Section 5.3)</li> </ul> <p>결론부터 이야기하자면, peak는 비슷할 수 있으나, converging point는 다 다르다! 즉, 모델별로 어떤 문제가 더 어렵고 쉽고가 다를 수 있다. → 그러나 그래프보면 사실 비슷</p> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_007.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_008.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="ablation-study">Ablation Study</h2> <p>이번 섹션에서는 noise와 precision reduction의 영향력에 대한 실험 결과를 보인다.</p> <p>string noise의 경우 랜덤하게 두 개의 짧은 string을 question앞에 붙였고, quantization은 8,16,32 bit precision을 사용한다.</p> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_009.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>[noise] learning curve가 좀 더 오른쪽으로 shift, 즉, convergence speed가 좀 느려짐.</p> <ul> <li>noise가 학습에 부정적인 역할!</li> </ul> </li> <li> <p>[quantization] 32와 16의 경우 별로 달라지지 않고, 8의 경우에는 slower. 즉, 16이 더 좋은 선택이다!</p> </li> </ul> <p>결론 → 신기한건 없었다! 그럼에도 불구하고 내가 하기 귀찮은 연구를 누군가가 대신해줘서 인용할 때 써먹기 좋은 느낌</p> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>