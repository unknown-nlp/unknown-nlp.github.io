<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers? | Unknown NLP Papers </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content="ë…¼ë¬¸ ë¦¬ë·°"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknownnlp.github.io/blog/2024/exploring-concept-depth-how-large-language-models-acquire/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Papers </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?</h1> <p class="post-meta"> Created on April 23, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> Â  Â· Â  <a href="/blog/tag/classification"> <i class="fa-solid fa-hashtag fa-sm"></i> classification</a> Â  <a href="/blog/tag/language-model"> <i class="fa-solid fa-hashtag fa-sm"></i> language-model</a> Â  <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a> Â  <a href="/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a> Â  <a href="/blog/tag/reasoning"> <i class="fa-solid fa-hashtag fa-sm"></i> reasoning</a> Â  Â· Â  <a href="/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>ë…¼ë¬¸ ì •ë³´</strong></p> <ul> <li> <strong>Date</strong>: 2024-04-23</li> <li> <strong>Reviewer</strong>: hyowon Cho</li> </ul> <h1 id="introduction">Introduction</h1> <p>ìµœê·¼ ë” í° ëª¨ë¸ì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ëŠ” ë¯¿ìŒì— í˜ì…ì–´ ë§ì€ ì—°êµ¬ìë“¤ì´ ëª¨ë¸ì˜ í¬ê¸°ë¥¼ í‚¤ìš°ëŠ”ë° ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë¥¼ ë§Œë“œëŠ”ë° ì§‘ì¤‘í•˜ê³  ìˆë‹¤. í•˜ì§€ë§Œ ì—¬ì „íˆ LLMì˜ ë„¤íŠ¸ì›Œí¬ ê¹Šì´ì™€ conceptual understandingì˜ ì—°ê´€ ê´€ê³„ë¥¼ empiricalí•˜ê²Œ ë³´ì´ëŠ” ì—°êµ¬ëŠ” ë§ì§€ ì•Šë‹¤.</p> <p>ë‘˜ì˜ ì—°ê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” ì—°êµ¬ëŠ” í¬ê²Œ ë‘ ê°€ì§€ ê´€ì ìœ¼ë¡œ ì§„í–‰ëœë‹¤.</p> <ol> <li>analyzing model weights and architectures</li> </ol> <ul> <li>pruningì„ í†µí•´ ì–´ë–¤ layer í˜¹ì€ paramì„ ì œê±°í•´ë„ ì„±ëŠ¥ì— ë³€í™”ê°€ ì—†ëŠ”ì§€ í™•ì¸</li> </ul> <ol> <li>probing representations</li> </ol> <p>ì´ ì—°êµ¬ì—ì„œëŠ” ê°ê¸° ë‹¤ë¥¸ ëª¨ë¸ì´ ê°ê¸° ë‹¤ë¥¸ ë°ì´í„°ì…‹ì—ì„œ ì–´ë–»ê²Œ ì§€ì‹ì„ ì´í•´í•˜ëŠ”ì§€ ì¸¡ì •í•˜ê¸° ìœ„í•´ â€œConcept Depthâ€ë¼ëŠ” ê°œë…ì„ ì œì•ˆí•œë‹¤. ë°©ë²•ì€ ì•„ì£¼ ê°„ë‹¨í•˜ë‹¤.</p> <ol> <li> <p>capture the feature responses of different layers of the LLMs for different datasets</p> </li> <li> <p>use independent linear probes to indicate the best performance that the current layer can achieve</p> </li> </ol> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_000.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>ê°„ë‹¨í•œ ë°©ë²•ë¡ ì´ì§€ë§Œ, ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  1) ë‹¤ì–‘í•œ í¬ê¸°ì˜ LLMë“¤ì´ ì–´ë””ì„œ í•™ìŠµì„ ì§„í–‰í–ˆëŠ”ê°€ì— ëŒ€í•œ ë¹„êµ ë° ì¼ë°˜ì ì¸ ì–‘ìƒ í¬ì°© 2) robustness ì ì¸ ì¸¡ë©´ì—ì„œ ê¸°ì—¬ê°€ ìˆë‹¤ê³  í•  ìˆ˜ ìˆê² ë‹¤!</p> <blockquote> <p>ì¦‰ ì˜¤ëŠ˜ ë°œí‘œëŠ” ì•„ì£¼ ê°€ë³ê²Œ ë“¤ì–´ì£¼ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤ ğŸ˜Š</p> </blockquote> <h1 id="related-work">Related Work</h1> <h3 id="concepts-representation-in-dnns">Concepts representation in DNNs</h3> <p>ì—°êµ¬ìë“¤ì€ DNNì˜ ì§€ì‹ìŠµë“ì˜ ê³¼ì •ì„ ì¸ê°„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë°©ì‹ìœ¼ë¡œ ë¬˜ì‚¬í•œë‹¤. ì£¼ëª©í• ë§Œí•œ ë¶€ë¶„ì€ â€˜representation bottleneck,â€™ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ê²ƒìœ¼ë¡œ, ì‚¬ëŒê³¼ DNNê°„ì˜ ì¸ì§€ì  ë¶€ì¡°í™”ë¥¼ ì˜ë¯¸í•œë‹¤. ì¦‰, ì‚¬ëŒì´ ë‹¤ì–‘í•œ ì˜ˆì‹œë“¤ ì‚¬ì´ì—ì„œ ìœ ì‚¬ì ì„ ì°¾ì•„ ê°œë…ì„ í˜•ì„±í•œë‹¤ê³  í•  ë•Œ, DNNì€ ì¸ê°„ê³¼ ë‹¬ë¦¬, ë„ˆë¬´ ë‹¨ìˆœí•˜ê±°ë‚˜ ì§€ë‚˜ì¹˜ê²Œ ë³µì¡í•œ ê°œë…ì„ íŒŒì•…í•˜ëŠ” ê²½í–¥ì´ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ì¦‰, â€˜ì ë‹¹í•œâ€™ ë³µì¡ì„±ì˜ ê°œë…ì„ ìŠµë“í•˜ëŠ”ë° ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤.</p> <p>ì´ ì—°êµ¬ì—ì„œëŠ” ì´ë ‡ê²Œ ì¸ê°„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ëª…ì„ ì´ì–´ë‚˜ê°€ê¸° ìœ„í•´, ë‹¤ì–‘í•œ ë³µì¡ì„±ì˜ ê°œë…ì„ ë‹¤ë£¨ë©° LLMì„ ì„¤ëª…í•œë‹¤.</p> <h3 id="knowledge-and-concepts-in-llms">Knowledge and concepts in LLMs</h3> <p>LLMì— ê´€í•œ ê°€ì¥ ëœ¨ê±°ìš´ ë…¼ìŸì€ LLMì´ ì •ë§ ê°œë… ìì²´ë¥¼ ì´í•´í•˜ê³  ìˆëŠ”ì§€ í˜¹ì€ ë‹¨ìˆœíˆ ì•µë¬´ìƒˆì¼ ë¿ì¸ì§€ì´ë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” LLMì´ ê°œë… ìì²´ë¥¼ ì´í•´í•˜ê³  ìˆë‹¤ëŠ” ì „ì œí•˜ì—ì„œ ì§„í–‰ë˜ë©° ê·¸ ê·¼ê±°ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:</p> <ul> <li> <p>Gurnee and Tegmark [14] showed that LLMs internally store concepts like latitude, longitude, and time.</p> </li> <li> <p>another work showed that the truth of a statement can be detected from the internal state of LLMs [4].</p> </li> <li> <p>Geva et al. [12] also came to similar conclusions by artificially blocking or â€œknocking outâ€ specific parts of the LLMs to observe their effects on the inference process.</p> </li> </ul> <p>ì¦‰, ê°œë…ì„ ì´í•´í•œë‹¤ëŠ” ì „ì œ í•˜ì—, ê·¸ë ‡ë‹¤ë©´ ê°œë…ì˜ ë³µì¡ë„ì— ë”°ë¼ ì–´ë–»ê²Œ LLMì—ì„œ ë‹¤ë¥´ê²Œ ì´í•´í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•´ë³¸ë‹¤ê³  ë³´ë©´ ë˜ê² ë‹¤!</p> <h1 id="analyzing-method">Analyzing Method</h1> <h3 id="visualizing-layer-wise-representations">Visualizing Layer-wise Representations</h3> <p>ê° ë ˆì´ì–´ì˜ representationë“¤ì„ ë½‘ì•„, ì‹œê°í™”ë¥¼ ìœ„í•´ PCAë¥¼ ì§„í–‰í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒì˜ ê·¸ë¦¼ì„ ë³´ì</p> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_001.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>ìœ„ì˜ ê·¸ë¦¼ì€ Counterfact ë°ì´í„°ì…‹ì—ì„œ factì¸ ë°ì´í„°ì™€ counterfactì¸ ë°ì´í„°ì— ëŒ€í•´ì„œ 80% ê¹Šì´ì˜ Gemma-7b ëª¨ë¸ì— ë„£ì–´ representationì„ êµ¬í•´ ì‹œê°í™”í•œ ê²°ê³¼ì´ë‹¤ ì¦‰, ì´ ê¹Šì´ì—ì„œ ë‘ ê°œë… ìì²´ë¥¼ ì˜ ë¶„ë¦¬í•´ë‚´ê³  ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.</p> <h3 id="linear-classifier-probing">Linear Classifier Probing</h3> <p>ê° ë ˆì´ì–´ê°€ final predictionì— ê¸°ì—¬í•˜ëŠ” ë°”ë¥¼ ë” ìì„¸íˆ ë¶„ì„í•˜ê¸° ìœ„í•´ì„œ, Linear classifierë¥¼ í•™ìŠµì‹œì¼œ ì‚¬ìš©í•œë‹¤.</p> <p>ì£¼ì–´ì§„ ì‘ì—… wì— ëŒ€í•´,</p> <ul> <li> <p>LLMsì˜ hidden feature setì€ x âˆˆ R^nÃ—dmodelë¡œ í‘œí˜„ëœë‹¤.</p> </li> <li> <p>nì€ ìƒ˜í”Œì˜ ìˆ˜ë¥¼,</p> </li> <li> <p>x(i) âˆˆ R^1Ã—dmodelì€ íŠ¹ì • ë ˆì´ì–´ì—ì„œì˜ representationì„ ë‚˜íƒ€ë‚¸ë‹¤.</p> </li> <li> <p>binary ë ˆì´ë¸” y(i)ëŠ” 0 ë˜ëŠ” 1ë¡œ ì„¤ì •ëœë‹¤.</p> </li> </ul> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_002.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>ì¦‰, binary logistic regression classifier with L2 regularizationì´ë‹¤! ê·¸ë¦¬ê³ , ê° layer ë³„ë¡œ ë‹¤ í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.</p> <h1 id="experimental-setting">Experimental Setting</h1> <h3 id="models">Models</h3> <ul> <li> <p>Gemma (2B, 7B)</p> </li> <li> <p>LLaMA (7B, 13B)</p> </li> <li> <p>QWen (0.5B,1.8B, 4B, 7B, and 14B)</p> </li> </ul> <p>linear classifierë¥¼ ë§Œë“¤ ë•ŒëŠ”, each layerì˜ ë§ˆì§€ë§‰ feature representationì„ ì‚¬ìš©.</p> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_003.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="dataset">Dataset</h3> <ul> <li> <p>nine datasets</p> <ul> <li> <p>fact/factual analysis (Cities[22], CommonClaim[7], Counterfact[24])</p> </li> <li> <p>emotion (STSA[17], IMDb[20], Sarcasm[25], HateEval [21])</p> </li> <li> <p>inference/logical reasoning (StrategyQA[11], Coinflip[34])</p> </li> </ul> </li> </ul> <div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Cities [22]: consists of statements about the location of cities and
their veracity labels (e.g., The city of Zagreb is in Japan, which is
wrong).

CommonClaim [7]: A dataset of boolean statements, each labeled
by two humans as common-knowledge-true, common-knowledgefalse, or neither.

Counterfact [24]: Counterfact includes thousands of counterfactuals along with text that allows quantitative testing of specificity and
generalization when learning a counterfactual.

HateEval [21]: HateEval has English tweets which were annotated
hierarchically.

STSA [17]: STSA includes movie reviews, half of which were considered positive and the other half negative. Each label is extracted
from a longer movie review and reflects the writerâ€™s overall intention
for this review.

IMDb [20]: IMDb is a benchmark dataset for binary sentiment classification.
Sarcasm [25]: Sarcasm is a high-quality news headlines dataset that
is annotated as sarcastic or not sarcastic.

StrategyQA [11]: StrategyQA contains questions across all knowledge domains to elicit creative and diverse yes/no questions that require implicit reasoning steps.

Coinflip [34]: Coinflip includes questions about coin flipping. This
task requires the model to determine if a coin remains heads up after
it is either flipped or left unflipped by individuals.

</code></pre></div></div> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_004.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>LLMì˜ ì„±ëŠ¥ì— ë”°ë¼ easy ~ complexë¡œ êµ¬ë¶„</p> <ul> <li> <p>initial or middle depth of the LLMsì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ë°ì´í„°ëŠ” easy</p> </li> <li> <p>large fluctuations and stable classification accuracy occurring at the deep depth of the LLMsì„ ë³´ì´ëŠ” ë°ì´í„°ëŠ” complex</p> </li> </ul> </li> </ul> <h3 id="the-robustness-of-internal-representations">The Robustness of Internal Representations</h3> <h3 id="adding-noise">Adding Noise</h3> <p>input questionì˜ ì•ì— random stringì„ ë¶™ì´ëŠ” ë°©ì‹ìœ¼ë¡œ noise ì¶”ê°€. 50%ì˜ ë°ì´í„°ì— ì¶”ê°€ë˜ì–´ìˆìŒ.</p> <h3 id="quantization-settings">Quantization Settings</h3> <p>quantizationì„ í–ˆì„ ë•ŒëŠ” ì–´ë–»ê²Œ ë‹¬ë¼ì§ˆê¹Œ? -&gt; Quantization is set as 8-bit, 16-bit, and full 32-bit.</p> <h3 id="metrics-for-accuracy-variation">Metrics for Accuracy Variation</h3> <ul> <li> <p>Variation Rate</p> <ul> <li> <p>i-th layerì˜ acc = a_i</p> </li> <li> <p>vartiation rate Î²<em>i = a_i/a</em>{i-1}</p> </li> </ul> </li> </ul> <p>2ê°€ì§€ acc metricì„ ì†Œê°œí•œë‹¤: (1) jump point (2) coveraging point</p> <ol> <li> <p><strong>Jump Point</strong> We denote J(M, D) = min{\frac{i}{d}} s.t. Î²_i &gt;= 1.1, i âˆˆ {1, 2, â€¦, d âˆ’ 1}, as the jump point, where $M$ and $D = (q, y)$ represents the LLM classifier and the dataset. ì¦‰, ì„±ëŠ¥ ìƒ ì£¼ëª©í• ë§Œí•œ í–¥ìƒì´ ìˆì„ ë•Œ, ê·¸ ì§€ì ì„ jump pointë¼ê³  ë¶€ë¥¸ë‹¤.</p> </li> <li> <p><strong>Converging Point</strong> We denote C(M, D) = max{\frac{i}{d}} s.t. |Î²_i âˆ’ 1| &lt; 0.03, i âˆˆ {1, 2, â€¦, d âˆ’ 1} s.t. , as the converging point, where M and D = (q, y) represents the LLM classifier and the dataset.</p> </li> </ol> <p>ì •í™•ë„ê°€ ìœ ì§€ í˜¹ì€ ì¤„ì–´ë“¤ê¸° ì‹œì‘í•˜ë©´, saturationì´ ì¼ì–´ë‚¬ë‹¤ê³  ë³¸ë‹¤.</p> <h1 id="experimental-analysis">Experimental Analysis</h1> <p>ë‹¤ìŒì˜ ì„¸ ê°€ì§€ research questionì„ ê°€ì§€ê³  ì‹¤í—˜ì„ ì§„í–‰í•œë‹¤ .</p> <ul> <li> <p>RQ1: Do different LLMsâ€™ concept depths behave consistently in the same dataset? (Section 5.1)</p> </li> <li> <p>RQ2: Do different size LLMs but the same series (e.g., Gemma series) have consistent Concept Depth? (Section 5.2)</p> </li> <li> <p>RQ3: Do LLMsâ€™ Concept Depth of the same size behave consistently? (Section 5.3)</p> </li> </ul> <h2 id="comparison-among-the-datasets">Comparison Among the Datasets</h2> <blockquote> <p>RQ1: Do different LLMsâ€™ concept depths behave consistently in the same dataset? (Section 5.1)</p> </blockquote> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_005.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ol> <li> <p>LLMsì€ ë‹¤ë£¨ëŠ” ê°œë…ì— ë”°ë¼, layerì—ì„œ ë‹¤ë¥¸ ì–‘ìƒì„ ë³´ì˜€ë‹¤. í•˜ì§€ë§Œ, ê°™ì€ ê°œë…ì€ ë‹¤ì–‘í•œ LLMë“¤ì—ì„œ ì¼ê´€ëœ ì–‘ìƒì„ ë³´ì˜€ë‹¤.</p> </li> <li> <p>ë‹¤ì–‘í•œ ë ˆë²¨ì˜ conceptual understandingì´ í•„ìš”í•œ íƒœìŠ¤í¬ì˜ ê²½ìš°, LLMsì€ ì—¬ëŸ¬ ë ˆì´ì–´ì— ê±¸ì³ê°€ë©° ì²˜ë¦¬ë¥¼ í•˜ëŠ” ì–‘ìƒì„ ë³´ì˜€ë‹¤ ==&gt; indicating a layered approach to processing complex concepts</p> </li> </ol> <h3 id="fact-concept">Fact Concept</h3> <ul> <li> <p>Cities: ë‚®ì€ ë ˆì´ì–´ì—ì„œ sharp increase, stabilize in the highter layer == ê°œë… ìì²´ë¥¼ ì•„ì£¼ ê°•í•˜ê²Œ ì´í•´</p> </li> <li> <p>CommonClaim: stabilize in the lower layer</p> </li> <li> <p>Counterfact: utilizing deeper layers, low acc â€“&gt; complex!</p> </li> </ul> <h3 id="emotional-concept">Emotional Concept</h3> <p>ëª¨ë“  taskê°€ initial layerì—ì„œ rise. intermediate layerì—ì„œ converge</p> <ul> <li>-&gt; LLMì´ low layerì—ì„œ emotional concept ì¡ê³ ìˆìŒ</li> </ul> <h3 id="reasoning-skills">Reasoning Skills</h3> <p>display a bell-shaped accuracy trajectory in all models, ì¦‰ peakëŠ” ì¤‘ê°„ì—ì„œ!</p> <h3 id="remarks">Remarks</h3> <p>classification tasksì˜ ì„±ëŠ¥ì€ ì„¸ ê°€ì§€ íƒ€ì…ìœ¼ë¡œ ë¬¶ì„ ìˆ˜ ì‡ë‹¤.</p> <ol> <li> <p>For Cities, STSA, IMDb, and Sarcasm, the LLMs suddenly understand the tasks at intermediate layers.</p> </li> <li> <p>For CommonClaim and HateEval, the LLMs have already understood the tasks in shallower layers.</p> </li> <li> <p>For Counterfact, StrategyQA, and Coinflip, The tasksare more difficult to understand, compared with others.</p> </li> </ol> <p>ë”°ë¼ì„œ, 1,2ë¥¼ easy, 3ì„ complex taskë¼ê³  ë¶„ë¥˜í•œë‹¤.</p> <h2 id="comparison-among-the-number-of-parameters">Comparison Among the Number of Parameters</h2> <ul> <li>RQ2: Do different size LLMs but the same series (e.g., Gemma series) have consistent Concept Depth? (Section 5.2)</li> </ul> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_006.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>figureëŠ” ë‘ê°€ì§€ì˜ ë°˜ë³µë˜ëŠ” íŒ¨í„´ì„ ë³´ì¸ë‹¤.</p> <ol> <li> <p>í° ëª¨ë¸ì´ earlier layerì—ì„œ converging pointê°€ ë‚˜íƒ€ë‚œë‹¤</p> </li> <li> <p>í° ëª¨ë¸ì´ ë” ì¢‹ì€ peakë¥¼ ê°€ì¡Œë‹¤. ì¦‰, ëª¨ë¸ì˜ ì‚¬ì´ì¦ˆë¥¼ í‚¤ìš°ëŠ” ê²ƒì´ ê·¸ê²ƒì˜ íš¨ê³¼ì„± ë¿ë§Œì´ ì•„ë‹ˆë¼ robust internal representationì„ í˜•ì„±í•¨ì„ ë³´ì¸ë‹¤.</p> </li> </ol> <p>â†’ ê°œì¸ì ìœ¼ë¡œëŠ” ë” í° ëª¨ë¸ì¼ìˆ˜ë¡ earlier layerë¼ê³ ëŠ” í•˜ì§€ë§Œ, ê²°êµ­ ê°œìˆ˜ê°€ ë” ë§ìœ¼ë‹ˆê¹Œ ë³¸ layerì˜ ìˆ˜ëŠ” ë¹„ìŠ·/ë™ì¼í•˜ì§€ ì•Šì„ê¹Œì‹¶ë„¤ìš”! í˜¹ì€ ë‹¹ì—°í•œ ì´ì•¼ê¸°ì§€ ì•Šë‚˜.. â€” ê²°êµ­ ê°œìˆ˜!</p> <p>â†’ ê·¸ë ‡ì§€ë§Œ ë°ì´í„°ì…‹ë³„ë¡œ ê·¸ë˜í”„ê°€ ë¹„ìŠ·í•œê±´ ì‹ ê¸°!</p> <hr> <h3 id="remark">Remark</h3> <p>By comparing different sizes of models from the same LLM family, we have two observations.</p> <ol> <li> <p>As the number of parameters increases, peak accuracy gradually increases, and the converging point gradually advances.</p> </li> <li> <p>Larger models grasp the concepts earlier and better.</p> </li> </ol> <h2 id="comparison-among-the-llm-families">Comparison Among the LLM Families</h2> <ul> <li>RQ3: Do LLMsâ€™ Concept Depth of the same size behave consistently? (Section 5.3)</li> </ul> <p>ê²°ë¡ ë¶€í„° ì´ì•¼ê¸°í•˜ìë©´, peakëŠ” ë¹„ìŠ·í•  ìˆ˜ ìˆìœ¼ë‚˜, converging pointëŠ” ë‹¤ ë‹¤ë¥´ë‹¤! ì¦‰, ëª¨ë¸ë³„ë¡œ ì–´ë–¤ ë¬¸ì œê°€ ë” ì–´ë µê³  ì‰½ê³ ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤. â†’ ê·¸ëŸ¬ë‚˜ ê·¸ë˜í”„ë³´ë©´ ì‚¬ì‹¤ ë¹„ìŠ·</p> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_007.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_008.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="ablation-study">Ablation Study</h2> <p>ì´ë²ˆ ì„¹ì…˜ì—ì„œëŠ” noiseì™€ precision reductionì˜ ì˜í–¥ë ¥ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì¸ë‹¤.</p> <p>string noiseì˜ ê²½ìš° ëœë¤í•˜ê²Œ ë‘ ê°œì˜ ì§§ì€ stringì„ questionì•ì— ë¶™ì˜€ê³ , quantizationì€ 8,16,32 bit precisionì„ ì‚¬ìš©í•œë‹¤.</p> <figure> <picture> <img src="/assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/image_009.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>[noise] learning curveê°€ ì¢€ ë” ì˜¤ë¥¸ìª½ìœ¼ë¡œ shift, ì¦‰, convergence speedê°€ ì¢€ ëŠë ¤ì§.</p> <ul> <li>noiseê°€ í•™ìŠµì— ë¶€ì •ì ì¸ ì—­í• !</li> </ul> </li> <li> <p>[quantization] 32ì™€ 16ì˜ ê²½ìš° ë³„ë¡œ ë‹¬ë¼ì§€ì§€ ì•Šê³ , 8ì˜ ê²½ìš°ì—ëŠ” slower. ì¦‰, 16ì´ ë” ì¢‹ì€ ì„ íƒì´ë‹¤!</p> </li> </ul> <p>ê²°ë¡  â†’ ì‹ ê¸°í•œê±´ ì—†ì—ˆë‹¤! ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ë‚´ê°€ í•˜ê¸° ê·€ì°®ì€ ì—°êµ¬ë¥¼ ëˆ„êµ°ê°€ê°€ ëŒ€ì‹ í•´ì¤˜ì„œ ì¸ìš©í•  ë•Œ ì¨ë¨¹ê¸° ì¢‹ì€ ëŠë‚Œ</p> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>