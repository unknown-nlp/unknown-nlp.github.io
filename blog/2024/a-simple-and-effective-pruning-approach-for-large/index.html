<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> A Simple and Effective Pruning Approach for Large Language Models | You R. Name </title> <meta name="author" content="You R. Name"> <meta name="description" content="논문 리뷰 - Pruning 관련 연구"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/al-folio/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/al-folio/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/al-folio/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/al-folio/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://alshedivat.github.io/al-folio/blog/2024/a-simple-and-effective-pruning-approach-for-large/"> <script src="/al-folio/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/al-folio/"> <span class="font-weight-bold">You</span> R. Name </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/al-folio/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/al-folio/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/al-folio/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">A Simple and Effective Pruning Approach for Large Language Models</h1> <p class="post-meta"> Created on March 12, 2024 </p> <p class="post-tags"> <a href="/al-folio/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/al-folio/blog/tag/fine-tuning"> <i class="fa-solid fa-hashtag fa-sm"></i> fine-tuning</a>   <a href="/al-folio/blog/tag/gpt"> <i class="fa-solid fa-hashtag fa-sm"></i> gpt</a>   <a href="/al-folio/blog/tag/language-model"> <i class="fa-solid fa-hashtag fa-sm"></i> language-model</a>   <a href="/al-folio/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/al-folio/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   <a href="/al-folio/blog/tag/pruning"> <i class="fa-solid fa-hashtag fa-sm"></i> pruning</a>   ·   <a href="/al-folio/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2024-03-12</li> <li> <strong>Reviewer</strong>: hyowon Cho</li> <li> <strong>Property</strong>: Pruning</li> </ul> <h1 id="introduction">Introduction</h1> <p>어제 나눈 우리의 짧은 담론과 같이, 거대 언어모델에는 수많은 지식들이 저장되어있기 때문에 대부분의 파라미터는 우리가 타겟으로 하는 정보와 관련이 없습니다. 오늘은 네트워크를 어떻게 지식을 고려하면서 간단하지만 효과적으로 pruning할 수 있는지, 관련 연구를 살펴봅니다.</p> <p>선행 network pruning 연구에서 가장 문제가 되는 것은 무엇일까요?</p> <ol> <li> <p>대부분의 기법들은 retraining을 요구함 — 작기때문에 가능</p> </li> <li> <p>LLM을 retraining하는 것은 말이 되지 않기 때문에 retrain을 하지는 않지만, 여전히 내부적으로 여러번 iteration을 반복해 weight를 update함.</p> </li> <li> <p>retrain&amp;weight update를 하지 않는 방법으로 magnitude pruning (model merging에서 봤던!) 또한 LLM에서 완벽하게 작동하지는 않음.</p> </li> </ol> <p>오늘 소개하는 연구의 핵심 아이디어는 “model의 output을 만드는데는 model weight와 input이 함께 고려되는데, magnitude만 이용하는 pruning은 말이 되지 않는다. input도 함께 고려해야 된다.”입니다.</p> <p>즉, 3번의 standard weight magnitude pruning metric에 Input activation을 고려하면 더 효과적인 pruning이 가능하다는 것이지요. 이를 통해서 1과 2번과 같이 retraining, 그리고 weight update 없이도 light하게 좋은 pruning 성능을 유지한다고 주장합니다.</p> <h1 id="preliminaries">PRELIMINARIES</h1> <ul> <li> <p>Magnitude Pruning</p> </li> <li> <p>Emergent Large Magnitude Features</p> </li> </ul> <h1 id="wanda-pruning-by-weights-and-activations">WANDA: PRUNING BY WEIGHTS AND ACTIVATIONS</h1> <table> <tbody> <tr> <td>Consider a neuron with two inputs and corresponding weights: y = w_1x_1 + w_2x_2, where</td> <td>w_1</td> <td>≤</td> <td>w_2</td> <td>. 우리의 목표는 최종 output에 영향을 가장 덜 주는 weight를 삭제하는 것이다. 이때, x의 크기가 같거나 거의 차이가 없다면 더 작은 Magnitude를 가지는 w_1을 삭제하는 것이 당연하겠지만, 아쉽게도 input들끼리도 scale이 굉장히 다르다. 즉,</td> <td>x_1</td> <td>≫</td> <td>x_2</td> <td>, and as a result,</td> <td>w_1x_1</td> <td>≫</td> <td>w_2x_2</td> <td>. 이 경우에는 w_2를 삭제하는 것이 output에 가장 적은 차이를 가져온다.</td> </tr> </tbody> </table> <p>저자들의 일관된 주장은: magnitude만이 아닌 input activation을 함께 사용해야한다는 것이다.</p> <h3 id="pruning-metric">Pruning Metric</h3> <ul> <li> <p>a linear layer with weight W of shape <code class="language-plaintext highlighter-rouge">(C_out, C_in)</code></p> </li> <li> <p>input activations X with a shape of <code class="language-plaintext highlighter-rouge">(N × L, C_in)</code></p> </li> </ul> <p>X는 소수의 calibrated input을 통해 만들어내고, 각 layer에 X의 l2 norm을 곱해준다. (다른 norm들보다 좋은 성능)</p> <p>이러한 방식을 통해서 input activation과 weight magnitude를 고루 고려한 importance matrix를 만들 수 있다.</p> <h3 id="comparison-group">Comparison Group</h3> <p>기존의 pruning 방법론에서는 layer-wise locally 혹은 gloablly하게 어떤 weight가 더 작은지 판단한다. 하지만 저자들은 이보다 더 작은 단위로 group을 구성했을 때 더 효과적이었다고 주장한다.</p> <p>즉, 위의 figure와 같이 row별로 pruning을 진행한다 (per-output). drop되는 비율은 pre-defined.</p> <p>이러한 방법이 layer-wise보다 consisitently better. 그리고 wanda에서 뿐만이 아니라 일반적인 magnitude pruning에서도 더 좋은 성능을 보였다고 한다.</p> <p>이러한 양상이 general한지를 평가하기 위해, image classifier에 적용을 해본다. 하지만, image에서는 이러한 양상이 발견되지 않았다. 즉, LLM에서만 발견되는 것이다.</p> <h3 id="procedure">Procedure</h3> <p>한 번의 forward로 완료가 된다는 점이 장점.</p> <ol> <li> <p>calibration data를 통해 X가 만들어짐</p> </li> <li> <p>각 레이어에 도달했을 때, pruning을 하고 forward.</p> </li> </ol> <h3 id="structured-nm-sparsity">Structured N:M Sparsity.</h3> <p>Structured N:M Sparsity란 N개의 contiguous weights 중 M개가 non-zero인 구조를 의미한다. 비록 wanda가 이렇게 개수를 정해놓고 하는 방법론은 아니지만, 근본적으로는 같다고 볼 수 있고, 또한 이러한 구조를 이용하면 NVDIA의 sparse tensor core를 이용해 행렬연산의 속도를 끌어올릴 수 있다. 따라서, 실험에서 사용해 보았다고!</p> <h3 id="remarks">Remarks</h3> <p>이때, 각 layer의 hessian (X^TX + λI)에서 hessian dampening factor가 사라질 때, wanda의 input activation과 거의 유사하다고 주장한다.</p> <p>지금까지의 정리를 하자면 다음과 같다:</p> <ol> <li> <p>It maintains the <strong><em>simplicity</em></strong> of magnitude pruning in the pre-LLM era, requiring no gradient computation via back-propagation or any second-order Hessian inverses, but is also<strong>_ highly effective _</strong>in discovering sparse networks in pretrained LLMs.</p> </li> <li> <p>Wanda can be done with <strong><em>a single forward pass</em></strong> of the LLM. At each layer, the pruned weights can be decided in one shot without an iterative procedure. In practice, computing the pruning metric of Wanda can be <strong><em>300 times faster in pruning LLMs compared with SparseGPT.</em></strong></p> </li> <li> <p>Unlike SparseGPT, our approach entails <strong><em>no weight update _**on pruned networks, suggesting that **_LLMs have effective sparse sub-networks that are exact</em></strong>, instead of them merely existing in the neighborhood of the original weights.</p> </li> </ol> <h2 id="experiments">EXPERIMENTS</h2> <ul> <li> <p>model</p> </li> <li> <p>Eval:</p> </li> <li> <p>Baselines</p> </li> <li> <p>Sparsity</p> </li> </ul> <h2 id="zero-shot-tasks">ZERO-SHOT TASKS</h2> <p>모델 크기가 작을 때는, pruned LLM과 original dense LLM의 gap 차이가 크지만, model size가 카질수록 이 acc gap이 줄어들었다. 실제로, unstructured 50% sparse LLaMA-65B and LLaMA-2-70B의 성능은 Pruining 전과 거의 유사하다.</p> <ul> <li>Large Sparse vs. Small Dense.</li> </ul> <h2 id="language-modeling">LANGUAGE MODELING</h2> <p>For unstructured 50% sparsity, Wanda의 성능은 SparseGPT과 유사하다.</p> <p>그러나, appendix에 실은 것도 확인하면 sparsegpt의 성능에는 따라가지 못하는 듯하다.</p> <h2 id="speedup">SPEEDUP</h2> <p>성능에는 따라가지 못하더라도 너무나도 확실한 pruning 속도 개선!</p> <p>inference speedup은 각 레이어의 Multiplication latency를 측정했다.</p> <h1 id="analysis">ANALYSIS</h1> <h3 id="1-fine-tuning">1. Fine-tuning</h3> <blockquote> <p>finetuning이 pruned LLM의 performance drop을 recover할 수 있는가?</p> </blockquote> <ul> <li> <p>전략: lora, full finetining</p> </li> <li> <p>데이터: C4</p> </li> </ul> <p>Lora의 경우, additional param이 있지만, 0.06% 밖에. Full fietuning의 경우, mask를 계속 적용함.</p> <h3 id="2-robustness-to-calibration-samples">2. Robustness to Calibration Samples</h3> <p>calibration sample을 1~256개로 다양하게 주어보았다.</p> <p>sparseGPT에 비해, wanda는 굉장히 강건한 것을 확인할 수 있는데, 이는 아마 input norm이 full inevrse hessian보다 훨씬 측정하기 쉽기 때문일 것으로 추정된다.</p> <h3 id="3-weight-update">3. Weight Update.</h3> <p>해당 분석에서는 sparseGPT의 weight update가 얼마나 다른 방법론들에서도 도움이 되는지 확인한다.</p> <p>weight update의 선택지는 다음과 같다</p> <ol> <li> <p>sequential</p> </li> <li> <p>iterative</p> </li> </ol> <p>sparesGPT의 경우, 128개의 input channel에 대해 iterative하게 update을 진행한다.</p> <ol> <li> <p>weight update는 magnitude pruning의 성능을 크게 증가시킨다.</p> </li> <li> <p>wanda의 경우, pruning이 강하게 들어간 경우에는 도움이 되었지만, 그 외의 경우에는 큰 도움이 되지 않았다.</p> </li> </ol> <h1 id="conclusion">Conclusion</h1> <p>간단하고, 빠르고, 직관적으로 model pruning을 성공적으로 해낸 연구.</p> <p>model merging쪽에 관심있는 본인으로서는 task vector에 대해 wanda를 살짝 변형해서 적용했더니 훨씬 robust하고 좋은 성능!</p> <p>4~5월에는 이거 적용한 제 연구도 가져오겠슴미당 :)</p> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 You R. Name. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/al-folio/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/al-folio/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/al-folio/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/al-folio/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/al-folio/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/al-folio/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/al-folio/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/al-folio/assets/js/search-data.js"></script> <script src="/al-folio/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>