<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="5EvH841dAH-gE3azIorT3dCfBA_7a3yppKdAm1JWne8"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories | Unknown NLP Lab </title> <meta name="author" content="Jeahee Kim"> <meta name="description" content="논문 리뷰 - Autonomous-Agents, Code Generation 관련 연구"> <meta name="keywords" content="natural language processing, NLP, machine learning, artificial intelligence, research papers, academic collaboration, paper review, computational linguistics, deep learning, transformers, language models"> <meta property="og:site_name" content="Unknown NLP Lab"> <meta property="og:type" content="article"> <meta property="og:title" content="Unknown NLP Lab | SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"> <meta property="og:url" content="https://unknown-nlp.github.io/blog/2024/super-evaluating-agents-on-setting-up-and-executing/"> <meta property="og:description" content="논문 리뷰 - Autonomous-Agents, Code Generation 관련 연구"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"> <meta name="twitter:description" content="논문 리뷰 - Autonomous-Agents, Code Generation 관련 연구"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Jeahee Kim"
        },
        "url": "https://unknown-nlp.github.io/blog/2024/super-evaluating-agents-on-setting-up-and-executing/",
        "@type": "BlogPosting",
        "description": "논문 리뷰 - Autonomous-Agents, Code Generation 관련 연구",
        "headline": "SUPER: Evaluating Agents on Setting Up and Executing Tasks
from Research Repositories",
        
        "sameAs": ["https://inspirehep.net/authors/1010907","https://scholar.google.com/citations?user=qc6CJjYAAAAJ","https://www.alberteinstein.com/"],
        
        "name": "Jeahee Kim",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unknown-nlp.github.io/blog/2024/super-evaluating-agents-on-setting-up-and-executing/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Unknown NLP Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories</h1> <p class="post-meta"> Created on September 23, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/autonomous-agents"> <i class="fa-solid fa-hashtag fa-sm"></i> autonomous-agents</a>   <a href="/blog/tag/bert"> <i class="fa-solid fa-hashtag fa-sm"></i> bert</a>   <a href="/blog/tag/code-generation"> <i class="fa-solid fa-hashtag fa-sm"></i> code generation</a>   <a href="/blog/tag/fine-tuning"> <i class="fa-solid fa-hashtag fa-sm"></i> fine-tuning</a>   <a href="/blog/tag/gpt"> <i class="fa-solid fa-hashtag fa-sm"></i> gpt</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/paper-review"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-review</a>   <a href="/blog/tag/reasoning"> <i class="fa-solid fa-hashtag fa-sm"></i> reasoning</a>   <a href="/blog/tag/transformer"> <i class="fa-solid fa-hashtag fa-sm"></i> transformer</a>   ·   <a href="/blog/category/paper-reviews"> <i class="fa-solid fa-tag fa-sm"></i> paper-reviews</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>논문 정보</strong></p> <ul> <li> <strong>Date</strong>: 2024-09-23</li> <li> <strong>Reviewer</strong>: yukyung lee</li> <li> <strong>Property</strong>: Autonomous-Agents, Code Generation</li> </ul> <h2 id="1-introduction">1. Introduction</h2> <figure> <picture> <img src="/assets/img/posts/2024-09-23-super-evaluating-agents-on-setting-up-and-executing/image_000.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>Can LLMs automate theset up and execution of tasks in research repositories?</p> <ul> <li> <p>Experimentation frequently requires substantial effort to setup and execute them</p> <ul> <li> <p>installing the environment:</p> <ul> <li> <p>conﬁguration changes</p> </li> <li> <p>resolv-ing outdated package dependencies</p> </li> <li> <p>ﬁxing bugs</p> </li> <li> <p>determining the correct execution commands</p> </li> </ul> </li> </ul> </li> </ul> </li> <li> <p>both setting up and executing experiments using research repositories in-the-wild</p> </li> </ul> <h2 id="2-related-work">2. Related work</h2> <h3 id="1-coding-benchmarks">1) Coding benchmarks</h3> <figure> <picture> <img src="/assets/img/posts/2024-09-23-super-evaluating-agents-on-setting-up-and-executing/image_001.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>Contributions</p> <ul> <li>In contrast to these works,SUPER focuses onthe end-to-end task of setting up and executingresearch tasks in lower-proﬁle repositories, pre-senting a unique set of challenges, with tasks thatrequire repository comprehension and reasoning,editing multiple ﬁles, setting up the repository en-vironment for execution while interactively run-ning commands in the environment</li> </ul> </li> </ul> <h3 id="2-llm-agent">2) LLM Agent</h3> <ul> <li>Our benchmark introduces an importantnew domain that encourages the development ofLLM-based agents to assist researchers in their end to end research tasks with arbitrary repositories</li> </ul> <h2 id="3-benchmark-construction">3. Benchmark Construction</h2> <figure> <picture> <img src="/assets/img/posts/2024-09-23-super-evaluating-agents-on-setting-up-and-executing/image_002.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>SUPER benchmark (3 setting)</p> <ul> <li> <p>Expert set - contains manuallywritten problems, solved by experts.</p> </li> <li> <p>Masked set - contains sub-problems extracted from the Expert set using the gold solution, which pro-vide easier and more focused sub-problems.</p> </li> <li> <p>Auto set - contains automatically generated problemswhich can be used for development and improve-ment of agents</p> </li> </ul> </li> <li> <p>Environment setup : Jupyter notebook as engine</p> <ul> <li> <p>Execute cells: system shell command &amp; stateful python command</p> </li> <li> <p>Each execution returns an observation string</p> </li> <li> <p>https://modal.com</p> <ul> <li>2-3 cents per problem in Modal (<strong>not including</strong> API costs)</li> </ul> </li> </ul> </li> </ul> <hr> <figure> <picture> <img src="/assets/img/posts/2024-09-23-super-evaluating-agents-on-setting-up-and-executing/image_003.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Expert</strong>: 45 end-to-end</p> <ul> <li> <p>Manually written by “expert” programmers</p> </li> <li> <p>Ask for git commit hash, and any exceptional implementation decisions they had to make (which are specified to agent)</p> </li> <li> <p>Check that solutions are reproducible (up to error of 10-2)</p> </li> </ul> <p><strong>Masked</strong>: 152 sub-problems from Expert</p> <ul> <li> <p>Removes parts of expert-written code (“masks” them)</p> </li> <li> <p>Pre-execute existing cells and pass as history - code to be written by model not required to fit “in between” existing cells, can follow sequentially</p> <ul> <li>In prompt history as [pre-executed by the user]</li> </ul> </li> </ul> <p><strong>Auto</strong>:** **604 auto-generated examples</p> <ul> <li>state-of-the-art approaches struggle to solve these problems with the best model (GPT-4o) solving only <strong>16.3% of the end-to-end</strong> set, and <strong>46.1% ofthe scenarios</strong>.</li> </ul> <h2 id="4-evaluation"><strong>4. Evaluation</strong></h2> <figure> <picture> <img src="/assets/img/posts/2024-09-23-super-evaluating-agents-on-setting-up-and-executing/image_004.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p>replication of metrics</p> </li> <li> <p>Partial credit through “<strong>landmarks</strong>” (points in code signalling sub-completion, e.g. training stage done)</p> <ul> <li>E.g., the explicit output string “<strong>_training completed _</strong>” or the string “Loading data… 100%”</li> </ul> </li> <li> <p>Auto-generated: check no exceptions when running script (for a minimum duration)</p> <ul> <li>use 10 seconds based on gold expert solutions</li> </ul> </li> </ul> <blockquote> <p>“Open-source models substantially lag behind on both the sub-problems and end-to-end tasks.”</p> </blockquote> <p>“agents are better at resolving well-specified sub-problems, such as solving exceptions, bugs, and other issues, than tasks requiring repository and file exploration to understand code structure”</p> <p><strong>LLMs</strong></p> <p>GPT-4o (gpt-4o-2024-08-06)</p> <p>GPT-4o mini (gpt-4o-mini-2024-07-18)</p> <p>Mixtral-8x22B-Instruct</p> <p>Llama 3.1 70B</p> <figure> <picture> <img src="/assets/img/posts/2024-09-23-super-evaluating-agents-on-setting-up-and-executing/image_005.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Agents</strong></p> <ul> <li>Execute and submit commands</li> </ul> <ol> <li>ReAct</li> </ol> <p>&lt;thought, action, observation&gt;</p> <p><strong>Truncation</strong> strategies to keep context in limit (e.g. reduce size of training file output)</p> <ul> <li>For the <strong>last step, we provide the 50k last characters</strong>, which is usually enough for the entire observation. For <strong>earlier steps, we shorten the observations to show the last 500 characters</strong>.</li> </ul> <ol> <li>ReAct-SUPER</li> </ol> <ul> <li><strong>Result</strong></li> </ul> <figure> <picture> <img src="/assets/img/posts/2024-09-23-super-evaluating-agents-on-setting-up-and-executing/image_006.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Edit</strong> action</p> <ul> <li>“ Specifically, the edit command accepts three parameters: the name of the file, the exact content of the lines to be replaced, and the content to replace it with.”</li> </ul> <p>{filename}</p> <before_edit> (lines before edit) <after_edit> (lines after edit) - The edit command requires the provided replaced lines to be (1) precisely copied, including correct whitespaces and indentations and (2) unique in the contents file, so that the edit command is not ambiguous. To help the agent with these requirements, we configure the edit command to provide specific feedback to the agent in case one of these conditions does not apply. (e.g. one without trailing whitespaces, or multiple occurrences if so, with 1-3 lines before/after for disambiguation) - Execute and submit actions as well 1. SWE-Agent - Can read and scroll through file content 1. Reflection - _k tries to solve problem_ - Only provides minor improvements (1) reproducing numbers from research papers by running specific experiments (2) running **modified** experiments with different datasets, models, or configurations - PapersWithCode repos with “Text” modality research papers (with repos from 2021 or after) - Tasks that involve running experiment in readme/script in repo - “Whenever possible, we make the task more challenging by requiring the experiment to be run on a new dataset or model, other than the one described in the available documentation - Either from HF datasets, or Google Drive link - “The challenge of running on a specific dataset varies in difficulty: it could involve only a single configuration line change if the dataset is already supported, or creating a new dataset reader, adjusting column names, etc. --- <figure> <picture> <img src="/assets/img/posts/2024-09-23-super-evaluating-agents-on-setting-up-and-executing/image_007.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <img src="/assets/img/posts/2024-09-23-super-evaluating-agents-on-setting-up-and-executing/image_008.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> Reduce computational requirements by reducing model size/training time/dataset size - E.g. load first 10 examples only - E.g. run one epoch Other implementation instructions: - Branch - Certain HPs - Seeds <figure> <picture> <img src="/assets/img/posts/2024-09-23-super-evaluating-agents-on-setting-up-and-executing/image_009.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> # 5. Core Examples **Hardest**: data (27%), configuration (38%) and goal (43% accuracy) Examples: - However, I did not yet make any required changes to load the request dataset. Your goal is to successfully load the dataset and complete the remaining steps to achieve the user request. - Now, your goal is to complete the remaining steps and submit the answer. - Now, you should make any necessary configuration changes to achieve the user request. **Easier**: CPU, issues and dependencies (73%, 61% and 54% respectively) - Easier when specific error messages Examples: - Now, you should make the necessary changes to make sure the code runs on a CPU. - Now, you should install all required dependencies. Once dependencies are installed, you can re-run any of the pre-executed steps - Now, you should fix any remaining issues. (generated “template” for each sub-problem type?) Our problems may be more complex? This seems pretty “software-engineery” - Different points of burden on the model in pipeline – more focused on “setting up” existing things rather than modifying, deeply understanding repo content? - vary specifying scripts to run Modifying dataset/model examples - Train a ColBERT model on my data, available on `https://drive.google.com/file/d/1xP0nIRu_aJ_LvQMW1cz3M4nYWIv2orTO/edit` - Use the https://github.com/baoguangsheng/g-transformer repository to fine-tune sentence transformer on the default dataset fine-tuning - Evaluate the safety of `openai-community/gpt2` (from huggingface models) using the english benchmark of this repository. - Train… Additional instructions: 1. Load only the first 10 rows of each set in the dataset. 2. Train only one epoch. 3. Codebase expects one line per sample. - Finetune… Additional instructions: 1. Train only one epoch. 2. Limit the max source and target length to 128. 3. Limit the max generation tokens to 128. 4. Limit the number of beams to 1. Guarantees on code/no “cheating” - **Landmarks kind of help with this process** - Similarly, albeit unlikely by design, a model could correctly solve the task but not hit all of the landmarks (e.g., if it uses an alternate approach or guesses a solution) and have a lower landmark score. For each gold solution we manually extract 2-6 landmark outputs patterns. The landmarks metric evaluates the percentage of these patterns that appear in the outputs of any of the cells executed by the agent “Importantly, a perfect landmark score does not entail a perfect accuracy score, as landmarks only indicate that some action was performed, but it was not necessarily correct (e.g., a training script run successfully but with wrong hyper-parameters could be counted as success).” </after_edit></before_edit> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <br> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'unknown-nlp/unknown-nlp.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeahee Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>