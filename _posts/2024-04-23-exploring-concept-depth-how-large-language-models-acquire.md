---
categories:
- paper-reviews
date: '2024-04-23 00:00:00'
description: ë…¼ë¬¸ ë¦¬ë·°
giscus_comments: true
layout: post
related_posts: false
tags:
- classification
- language-model
- llm
- paper-review
- reasoning
thumbnail: assets/img/posts/2024-04-23-exploring-concept-depth-how-large-language-models-acquire/thumbnail.jpg
title: 'Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different
  Layers?'
---

**ë…¼ë¬¸ ì •ë³´**
- **Date**: 2024-04-23
- **Reviewer**: hyowon Cho

# Introduction

ìµœê·¼ ë” í° ëª¨ë¸ì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ëŠ” ë¯¿ìŒì— í˜ì…ì–´ ë§ì€ ì—°êµ¬ìë“¤ì´ ëª¨ë¸ì˜ í¬ê¸°ë¥¼ í‚¤ìš°ëŠ”ë° ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë¥¼ ë§Œë“œëŠ”ë° ì§‘ì¤‘í•˜ê³  ìˆë‹¤. í•˜ì§€ë§Œ ì—¬ì „íˆ LLMì˜ ë„¤íŠ¸ì›Œí¬ ê¹Šì´ì™€ conceptual understandingì˜ ì—°ê´€ ê´€ê³„ë¥¼ empiricalí•˜ê²Œ ë³´ì´ëŠ” ì—°êµ¬ëŠ” ë§ì§€ ì•Šë‹¤.

ë‘˜ì˜ ì—°ê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” ì—°êµ¬ëŠ” í¬ê²Œ ë‘ ê°€ì§€ ê´€ì ìœ¼ë¡œ ì§„í–‰ëœë‹¤.

1. analyzing model weights and architectures

1. probing representations

ì´ ì—°êµ¬ì—ì„œëŠ” ê°ê¸° ë‹¤ë¥¸ ëª¨ë¸ì´ ê°ê¸° ë‹¤ë¥¸ ë°ì´í„°ì…‹ì—ì„œ ì–´ë–»ê²Œ ì§€ì‹ì„ ì´í•´í•˜ëŠ”ì§€ ì¸¡ì •í•˜ê¸° ìœ„í•´ "Concept Depth"ë¼ëŠ” ê°œë…ì„ ì œì•ˆí•œë‹¤. ë°©ë²•ì€ ì•„ì£¼ ê°„ë‹¨í•˜ë‹¤.

1. capture the feature responses of different layers of the LLMs for different datasets

1. use independent linear probes to indicate the best performance that the current layer can achieve

ê°„ë‹¨í•œ ë°©ë²•ë¡ ì´ì§€ë§Œ, ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  1) ë‹¤ì–‘í•œ í¬ê¸°ì˜ LLMë“¤ì´ ì–´ë””ì„œ í•™ìŠµì„ ì§„í–‰í–ˆëŠ”ê°€ì— ëŒ€í•œ ë¹„êµ ë° ì¼ë°˜ì ì¸ ì–‘ìƒ í¬ì°© 2) robustness ì ì¸ ì¸¡ë©´ì—ì„œ ê¸°ì—¬ê°€ ìˆë‹¤ê³  í•  ìˆ˜ ìˆê² ë‹¤!

> ì¦‰ ì˜¤ëŠ˜ ë°œí‘œëŠ” ì•„ì£¼ ê°€ë³ê²Œ ë“¤ì–´ì£¼ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤ ğŸ˜Š

# Related Work

### Concepts representation in DNNs

ì—°êµ¬ìë“¤ì€ DNNì˜ ì§€ì‹ìŠµë“ì˜ ê³¼ì •ì„ ì¸ê°„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë°©ì‹ìœ¼ë¡œ ë¬˜ì‚¬í•œë‹¤. ì£¼ëª©í• ë§Œí•œ ë¶€ë¶„ì€ â€˜representation bottleneck,â€™ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ê²ƒìœ¼ë¡œ, ì‚¬ëŒê³¼ DNNê°„ì˜ ì¸ì§€ì  ë¶€ì¡°í™”ë¥¼ ì˜ë¯¸í•œë‹¤.
ì¦‰, ì‚¬ëŒì´ ë‹¤ì–‘í•œ ì˜ˆì‹œë“¤ ì‚¬ì´ì—ì„œ ìœ ì‚¬ì ì„ ì°¾ì•„ ê°œë…ì„ í˜•ì„±í•œë‹¤ê³  í•  ë•Œ, DNNì€ ì¸ê°„ê³¼ ë‹¬ë¦¬, ë„ˆë¬´ ë‹¨ìˆœí•˜ê±°ë‚˜ ì§€ë‚˜ì¹˜ê²Œ ë³µì¡í•œ ê°œë…ì„ íŒŒì•…í•˜ëŠ” ê²½í–¥ì´ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ì¦‰, 'ì ë‹¹í•œ' ë³µì¡ì„±ì˜ ê°œë…ì„ ìŠµë“í•˜ëŠ”ë° ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤.

ì´ ì—°êµ¬ì—ì„œëŠ” ì´ë ‡ê²Œ ì¸ê°„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ëª…ì„ ì´ì–´ë‚˜ê°€ê¸° ìœ„í•´, ë‹¤ì–‘í•œ ë³µì¡ì„±ì˜ ê°œë…ì„ ë‹¤ë£¨ë©° LLMì„ ì„¤ëª…í•œë‹¤.

### Knowledge and concepts in LLMs

LLMì— ê´€í•œ ê°€ì¥ ëœ¨ê±°ìš´ ë…¼ìŸì€ LLMì´ ì •ë§ ê°œë… ìì²´ë¥¼ ì´í•´í•˜ê³  ìˆëŠ”ì§€ í˜¹ì€ ë‹¨ìˆœíˆ ì•µë¬´ìƒˆì¼ ë¿ì¸ì§€ì´ë‹¤.
ì´ ì—°êµ¬ì—ì„œëŠ” LLMì´ ê°œë… ìì²´ë¥¼ ì´í•´í•˜ê³  ìˆë‹¤ëŠ” ì „ì œí•˜ì—ì„œ ì§„í–‰ë˜ë©° ê·¸ ê·¼ê±°ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:

- Gurnee and Tegmark [14] showed that LLMs internally store concepts like latitude, longitude, and time.

- another work showed that the truth of a statement can be detected from the internal state of LLMs [4].

- Geva et al. [12] also came to similar conclusions by artificially blocking or â€œknocking out" specific parts of the LLMs to observe their effects on the inference process.

ì¦‰, ê°œë…ì„ ì´í•´í•œë‹¤ëŠ” ì „ì œ í•˜ì—, ê·¸ë ‡ë‹¤ë©´ ê°œë…ì˜ ë³µì¡ë„ì— ë”°ë¼ ì–´ë–»ê²Œ LLMì—ì„œ ë‹¤ë¥´ê²Œ ì´í•´í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•´ë³¸ë‹¤ê³  ë³´ë©´ ë˜ê² ë‹¤!

# Analyzing Method

### Visualizing Layer-wise Representations

ê° ë ˆì´ì–´ì˜ representationë“¤ì„ ë½‘ì•„, ì‹œê°í™”ë¥¼ ìœ„í•´ PCAë¥¼ ì§„í–‰í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒì˜ ê·¸ë¦¼ì„ ë³´ì

ìœ„ì˜ ê·¸ë¦¼ì€ Counterfact ë°ì´í„°ì…‹ì—ì„œ factì¸ ë°ì´í„°ì™€ counterfactì¸ ë°ì´í„°ì— ëŒ€í•´ì„œ 80% ê¹Šì´ì˜ Gemma-7b ëª¨ë¸ì— ë„£ì–´ representationì„ êµ¬í•´ ì‹œê°í™”í•œ ê²°ê³¼ì´ë‹¤ ì¦‰, ì´ ê¹Šì´ì—ì„œ ë‘ ê°œë… ìì²´ë¥¼ ì˜ ë¶„ë¦¬í•´ë‚´ê³  ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

### Linear Classifier Probing

ê° ë ˆì´ì–´ê°€ final predictionì— ê¸°ì—¬í•˜ëŠ” ë°”ë¥¼ ë” ìì„¸íˆ ë¶„ì„í•˜ê¸° ìœ„í•´ì„œ, Linear classifierë¥¼ í•™ìŠµì‹œì¼œ ì‚¬ìš©í•œë‹¤.

ì£¼ì–´ì§„ ì‘ì—… wì— ëŒ€í•´,

- LLMsì˜ hidden feature setì€ x âˆˆ R^nÃ—dmodelë¡œ í‘œí˜„ëœë‹¤.

- nì€ ìƒ˜í”Œì˜ ìˆ˜ë¥¼,

- x(i) âˆˆ R^1Ã—dmodelì€ íŠ¹ì • ë ˆì´ì–´ì—ì„œì˜ representationì„ ë‚˜íƒ€ë‚¸ë‹¤.

- binary ë ˆì´ë¸” y(i)ëŠ” 0 ë˜ëŠ” 1ë¡œ ì„¤ì •ëœë‹¤.

ì¦‰, binary logistic regression classifier with L2 regularizationì´ë‹¤! ê·¸ë¦¬ê³ , ê° layer ë³„ë¡œ ë‹¤ í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

# Experimental Setting

### Models

- Gemma (2B, 7B)

- LLaMA (7B, 13B)

- QWen (0.5B,1.8B, 4B, 7B, and 14B)

linear classifierë¥¼ ë§Œë“¤ ë•ŒëŠ”, each layerì˜ ë§ˆì§€ë§‰ feature representationì„ ì‚¬ìš©.

### Dataset

- nine datasets

```latex
Cities [22]: consists of statements about the location of cities and
their veracity labels (e.g., The city of Zagreb is in Japan, which is
wrong).

CommonClaim [7]: A dataset of boolean statements, each labeled
by two humans as common-knowledge-true, common-knowledgefalse, or neither.

Counterfact [24]: Counterfact includes thousands of counterfactuals along with text that allows quantitative testing of specificity and
generalization when learning a counterfactual.

HateEval [21]: HateEval has English tweets which were annotated
hierarchically.

STSA [17]: STSA includes movie reviews, half of which were considered positive and the other half negative. Each label is extracted
from a longer movie review and reflects the writerâ€™s overall intention
for this review.

IMDb [20]: IMDb is a benchmark dataset for binary sentiment classification.
Sarcasm [25]: Sarcasm is a high-quality news headlines dataset that
is annotated as sarcastic or not sarcastic.

StrategyQA [11]: StrategyQA contains questions across all knowledge domains to elicit creative and diverse yes/no questions that require implicit reasoning steps.

Coinflip [34]: Coinflip includes questions about coin flipping. This
task requires the model to determine if a coin remains heads up after
it is either flipped or left unflipped by individuals.

```

- LLMì˜ ì„±ëŠ¥ì— ë”°ë¼ easy ~ complexë¡œ êµ¬ë¶„

### The Robustness of Internal Representations

### Adding Noise

input questionì˜ ì•ì— random stringì„ ë¶™ì´ëŠ” ë°©ì‹ìœ¼ë¡œ noise ì¶”ê°€. 50%ì˜ ë°ì´í„°ì— ì¶”ê°€ë˜ì–´ìˆìŒ.

### Quantization Settings

quantizationì„ í–ˆì„ ë•ŒëŠ” ì–´ë–»ê²Œ ë‹¬ë¼ì§ˆê¹Œ?
-> Quantization is set as 8-bit, 16-bit, and full 32-bit.

### Metrics for Accuracy Variation

- Variation Rate

2ê°€ì§€ acc metricì„ ì†Œê°œí•œë‹¤:  (1) jump point (2) coveraging point

1. **Jump Point**
We denote J(M, D) = min{\frac{i}{d}} s.t.
Î²_i >= 1.1, i âˆˆ {1, 2, ..., d âˆ’ 1}, as the jump point, where $M$ and $D = (q, y)$ represents the LLM classifier and the dataset. ì¦‰, ì„±ëŠ¥ ìƒ ì£¼ëª©í• ë§Œí•œ í–¥ìƒì´ ìˆì„ ë•Œ, ê·¸ ì§€ì ì„ jump pointë¼ê³  ë¶€ë¥¸ë‹¤.

1. **Converging Point**
We denote C(M, D) = max{\frac{i}{d}} s.t. |Î²_i âˆ’ 1| < 0.03, i âˆˆ {1, 2, ..., d âˆ’ 1} s.t. , as the converging point, where M and D = (q, y) represents the LLM classifier and the dataset.

ì •í™•ë„ê°€ ìœ ì§€ í˜¹ì€ ì¤„ì–´ë“¤ê¸° ì‹œì‘í•˜ë©´, saturationì´ ì¼ì–´ë‚¬ë‹¤ê³  ë³¸ë‹¤.

# Experimental Analysis

ë‹¤ìŒì˜ ì„¸ ê°€ì§€ research questionì„ ê°€ì§€ê³  ì‹¤í—˜ì„ ì§„í–‰í•œë‹¤ .

- RQ1: Do different LLMsâ€™ concept depths behave consistently in the same dataset? (Section 5.1)

- RQ2: Do different size LLMs but the same series (e.g., Gemma series) have consistent Concept Depth? (Section 5.2)

- RQ3: Do LLMsâ€™ Concept Depth of the same size behave consistently? (Section 5.3)

## Comparison Among the Datasets

> RQ1: Do different LLMsâ€™ concept depths behave consistently in the same dataset? (Section 5.1)

1. LLMsì€ ë‹¤ë£¨ëŠ” ê°œë…ì— ë”°ë¼, layerì—ì„œ ë‹¤ë¥¸ ì–‘ìƒì„ ë³´ì˜€ë‹¤.
í•˜ì§€ë§Œ, ê°™ì€ ê°œë…ì€ ë‹¤ì–‘í•œ LLMë“¤ì—ì„œ ì¼ê´€ëœ ì–‘ìƒì„ ë³´ì˜€ë‹¤.

1. ë‹¤ì–‘í•œ ë ˆë²¨ì˜ conceptual understandingì´ í•„ìš”í•œ íƒœìŠ¤í¬ì˜ ê²½ìš°, LLMsì€ ì—¬ëŸ¬ ë ˆì´ì–´ì— ê±¸ì³ê°€ë©° ì²˜ë¦¬ë¥¼ í•˜ëŠ” ì–‘ìƒì„ ë³´ì˜€ë‹¤ ==> indicating a layered approach to processing complex concepts

### Fact Concept

- Cities: ë‚®ì€ ë ˆì´ì–´ì—ì„œ sharp increase, stabilize in the highter layer == ê°œë… ìì²´ë¥¼ ì•„ì£¼ ê°•í•˜ê²Œ ì´í•´

- CommonClaim: stabilize in the lower layer

- Counterfact: utilizing deeper layers, low acc --> complex!

### Emotional Concept

ëª¨ë“  taskê°€ initial layerì—ì„œ rise.
intermediate layerì—ì„œ converge

- -> LLMì´ low layerì—ì„œ emotional concept ì¡ê³ ìˆìŒ

### Reasoning Skills

display a bell-shaped accuracy trajectory in all models, ì¦‰ peakëŠ” ì¤‘ê°„ì—ì„œ!

### Remarks

classification tasksì˜ ì„±ëŠ¥ì€ ì„¸ ê°€ì§€ íƒ€ì…ìœ¼ë¡œ ë¬¶ì„ ìˆ˜ ì‡ë‹¤.

1. For Cities, STSA, IMDb, and Sarcasm, the LLMs suddenly understand the tasks at intermediate layers.

1. For CommonClaim and HateEval, the LLMs have already understood the tasks in shallower layers.

1. For Counterfact, StrategyQA, and Coinflip, The tasksare more difficult to understand, compared with others.

ë”°ë¼ì„œ, 1,2ë¥¼ easy, 3ì„ complex taskë¼ê³  ë¶„ë¥˜í•œë‹¤.

## Comparison Among the Number of Parameters

- RQ2: Do different size LLMs but the same series (e.g., Gemma series) have consistent Concept Depth? (Section 5.2)

figureëŠ” ë‘ê°€ì§€ì˜ ë°˜ë³µë˜ëŠ” íŒ¨í„´ì„ ë³´ì¸ë‹¤.

1. í° ëª¨ë¸ì´ earlier layerì—ì„œ converging pointê°€ ë‚˜íƒ€ë‚œë‹¤

1. í° ëª¨ë¸ì´ ë” ì¢‹ì€ peakë¥¼ ê°€ì¡Œë‹¤. ì¦‰, ëª¨ë¸ì˜ ì‚¬ì´ì¦ˆë¥¼ í‚¤ìš°ëŠ” ê²ƒì´ ê·¸ê²ƒì˜ íš¨ê³¼ì„± ë¿ë§Œì´ ì•„ë‹ˆë¼ robust internal representationì„ í˜•ì„±í•¨ì„ ë³´ì¸ë‹¤.

â†’ ê°œì¸ì ìœ¼ë¡œëŠ” ë” í° ëª¨ë¸ì¼ìˆ˜ë¡ earlier layerë¼ê³ ëŠ” í•˜ì§€ë§Œ, ê²°êµ­ ê°œìˆ˜ê°€ ë” ë§ìœ¼ë‹ˆê¹Œ ë³¸ layerì˜ ìˆ˜ëŠ” ë¹„ìŠ·/ë™ì¼í•˜ì§€ ì•Šì„ê¹Œì‹¶ë„¤ìš”! í˜¹ì€ ë‹¹ì—°í•œ ì´ì•¼ê¸°ì§€ ì•Šë‚˜.. â€” ê²°êµ­ ê°œìˆ˜!

â†’ ê·¸ë ‡ì§€ë§Œ ë°ì´í„°ì…‹ë³„ë¡œ ê·¸ë˜í”„ê°€ ë¹„ìŠ·í•œê±´ ì‹ ê¸°!
