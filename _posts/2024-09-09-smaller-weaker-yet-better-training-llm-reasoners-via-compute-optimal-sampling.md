---
categories: paper-reviews
date: "2024-09-09 00:00:00"
description: " ë…¼ë¬¸ ë¦¬ë·° - Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal
  Sampling"
giscus_comments: true
layout: post
related_posts: false
tags: llm paper-review nlp
title: "Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling"
---

**ë…¼ë¬¸ ì •ë³´**

- **Date**: 2024-09-09
- **Reviewer**: hyowon Cho
- **Property**: Knowledge Distillation, LLM, Limited Budget

> Google DeepMind (2024-08-30)

<br/>

ë§ì€ ì—°êµ¬ë“¤ì´ ì´ë¯¸ ì–¸ì–´ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë° synthetic ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤. ì´ë“¤ ì¤‘, reasoning taskì—ì„œ ê°€ì¥ ì¼ë°˜ì ì¸ ë°©ë²•ì€ í•˜ë‚˜ì˜ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ì—¬ëŸ¬ ê°€ì§€ í›„ë³´ ë‹µë³€ë“¤ì„ ìƒì„±í•˜ê²Œ í•˜ê³ , ì´ë¥¼ gold answerì™€ ë¹„êµí•´, ë§ëŠ” ì •ë‹µì„ ê°€ì§„ ê²ƒë“¤ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ë²„ë¦¬ëŠ” ê²ƒì´ë‹¤.

<br/>

í•˜ì§€ë§Œ, ì´ë ‡ê²Œ ì—¬ëŸ¬ ê°œì˜ ë°ì´í„°ë¥¼ strong LMsë¡œ ë¶€í„° ìƒì„±í•´ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ë¹„ì‹¸ê³ , resource-intensiveí•˜ë‹¤. ë˜í•œ í˜„ì‹¤ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜ˆì‚°ì€ ì •í•´ì ¸ìˆê¸° ë•Œë¬¸ì— ë§Œë“¤ ìˆ˜ ìˆëŠ” solutionë„ ê·¸ë¦¬ ë§ì§€ëŠ” ëª»í•˜ë‹¤.

<br/>

ì´ ë…¼ë¬¸ì—ì„œëŠ” fixed compute budget ìƒí™©ì—ì„œ, weaker but cheaper (WC) modelì´ ìš°ë¦¬ê°€ ì¼ë°˜ì ìœ¼ë¡œ ìƒê°í•˜ëŠ” ê²ƒê³¼ ë‹¤ë¥´ê²Œ stronger but more expensive (SE) modelì„ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë‚«ë‹¤ê³  ì£¼ì¥í•œë‹¤.

<br/>

ì´ë¥¼ ì¦ëª…í•˜ê¸° ìœ„í•´ ì €ìë“¤ì€ í¬ê²Œ 3ê°€ì§€ ì¶•ì—ì„œ ë°ì´í„°ë“¤ì— ëŒ€í•œ ë¹„êµë¥¼ ì§„í–‰í•œë‹¤.

1. coverage, the number of unique problems that are solved,

1. diversity, the average number of unique solutions we obtain per problem,

1. false positive rate (FPR), the percentage of problems that arrive at the correct final answer but with a wrong reasoning.

<br/>

ë‹¹ì—°íˆ ê³ ì •ëœ ì˜ˆì‚° í•˜ì—ì„œ, WC modelì´ SE modelë³´ë‹¤ ë” ë§ì€ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ SEê°€ ë‹¹ì—°íˆ í€„ë¦¬í‹°ëŠ” ë†’ì„ ê²ƒ. ê·¸ë ‡ê¸° ë•Œë¬¸ì—, WCê°€ ë” ë†’ì€ coverage and diversity ê·¸ë¦¬ê³  ë™ì‹œì— higher FPRë¥¼ ê°€ì§ˆ ê²ƒì´ë¼ê³  ì´ì•¼ê¸°í•œë‹¤.

<br/>

ì´í›„, ì €ìë“¤ì€ ì´ ì¶”ì¸¡ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ì„œ SE and WCë¡œ ë§Œë“  ë°ì´í„°ë¥¼ ì´ìš©í•´ì„œ ëª¨ë¸ë“¤ì„ finetuningí•œë‹¤. ë‹¨ìˆœ í•˜ë‚˜ì˜ ë°©ë²•ì´ ì•„ë‹ˆë¼ ì—¬ëŸ¬ ê°€ì§€ë¡œ.

1. knowledge distillation, where a student LM learns from a teacher LM (Hinton et al., 2015);

1. self-improvement, where an LM learns from self-generated data (Huang et al., 2022); and

1. a new paradigm we introduce called Weak-to-Strong Improvement, where a strong student LM improves using synthetic data from a weaker teacher LM.

<br/>

ì €ìë“¤ì€ ì—¬ëŸ¬ ê°œì˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì•„ì£¼ ì¼ê´€ì  SE-generated data ë³´ë‹¤ WC-generated dataë¡œ í•™ìŠµí•œ ê²°ê³¼ê°€ í›¨ì”¬ ì¢‹ìŒì„ ë³´ì¸ë‹¤ (ì¼ë°˜ì ì¸ ë¯¿ìŒê³¼ ë‹¬ë¦¬) ì¦‰, WC-generated dataì—ì„œ ìƒ˜í”Œë§í•˜ëŠ” ê²ƒì´ í›¨ì”¬ compute optimalí•˜ë‹¤ëŠ” ê²ƒ.

<br/>

ì–´ëŠ ì •ë„ í° ìŠ¤ì¼€ì¼ì—ì„œ ë” ì‘ì€ ëª¨ë¸ê³¼ í° ëª¨ë¸ì˜ ì„±ëŠ¥ ê°­ì´ ì ì°¨ ì¤„ì–´ë“¤ê³  ìˆëŠ” ìš”ì¦˜, LM reasonersë¥¼ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í•™ìŠµí• ì§€ ìƒê°ì„ í•˜ê²Œ í•œë‹¤.

- D = {ğ‘ğ‘–, ğ‘ğ‘–} = training

- reasoning questions = ğ‘ğ‘–

- final answers = ğ‘ğ‘–

<br/>

ë‹¤ ì•„ì‹œê² ì§€ë§Œ, ì´ë“¤ì„ ê°€ì§€ê³  synthetic dataë¥¼ ë§Œë“œëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:

1. sample multiple solutions for each ğ‘ğ‘– at a non-zero temperature

1. create the synthetic data with reasoning chain & generated answer

1. filter the incorrect solutions by comparing ğ‘Ë†ğ‘– ğ‘— to ğ‘ğ‘– and removing the solutions whose final answer do not match that of the gold answer

### Metric

- ğ‘ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘”ğ‘’@ğ‘˜ (aka ğ‘ğ‘ğ‘ ğ‘ @ğ‘˜)

  - kê°œì˜ ì†”ë£¨ì…˜ì„ ìƒì„±í–ˆì„ ë•Œ, ìµœì†Œ í•˜ë‚˜ ì´ìƒì´ ì •ë‹µì„ ë§ì¶¤

- ğ‘‘ğ‘–ğ‘£ğ‘’ğ‘Ÿğ‘ ğ‘–ğ‘¡ğ‘¦@ğ‘˜

  - kê°œì˜ ë‹µë³€ì„ ìƒì„±í–ˆì„ ë•Œ, kê°œì¤‘ ì •ë‹µì„ ë§ì¶˜ solution ê°œìˆ˜ì˜ í‰ê· 

- false positive rate

  - ë‹µì€ ë§ì•˜ëŠ”ë°, reasoningì´ ì˜ëª»ëœ ë¹„ìœ¨

ë‹¹ì—°íˆ ê³ ì •ëœ ì˜ˆì‚°, ê³ ì •ëœ sampling budget (FLOPs) ìƒì—ì„œ, ì‚¬ëŒë“¤ì€ ë” weaker but cheaper (WC) modelì„ í†µí•´ì„œ ë” ë§ì€ ìƒ˜í”Œë“¤ì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ë„ ìˆê³  í˜¹ì€ stronger but more expensive (SE) modelì„ í†µí•´ ë” ì ì§€ë§Œ ì–‘ì§ˆì˜ ë°ì´í„°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤.

<br/>

WC modelê°€ ğ‘ƒ*ğ‘Šğ¶ parametersë¥¼ ê°€ì§€ê³ , SEê°€ ğ‘ƒ*ğ‘†ğ¸ parametersë¥¼ ê°€ì§„ë‹¤ê³  í•˜ê³ , ë‘ ëª¨ë¸ì„ ì´ìš©í•´ì„œ ë¬´ì¡°ê±´ ê°™ì€ ì˜ˆì‚°ë§Œì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ê³  í•˜ë©´, ë§Œë“¤ ìˆ˜ ìˆëŠ” ë°ì´í„°ì˜ ê°œìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì°¨ì´ê°€ ë‚œë‹¤.

- Following (Kaplan et al., 2020), FLOPs per inference token = 2ğ‘ƒ

- FLOPs for ğ‘‡ inference tokens = 2ğ‘ƒğ‘‡

- assume that generating each solution requires an average of ğ‘Š inference tokens

- ğ‘†*ğ‘Šğ¶ and ğ‘†*ğ‘†ğ¸ = number of samples we generate per question

- total cost

  - ğ¶ğ‘œğ‘ ğ‘¡ğ‘Šğ¶ = ğ‘›Ã—ğ‘†*ğ‘Šğ¶ Ã—ğ‘Š Ã— (2ğ‘ƒ*ğ‘Šğ¶)

  - ğ¶ğ‘œğ‘ ğ‘¡ğ‘†ğ¸ = ğ‘›Ã—ğ‘†*ğ‘†ğ¸ Ã—ğ‘Š Ã— (2ğ‘ƒ*ğ‘†ğ¸)

  - ğ‘†*ğ‘Šğ¶ =(ğ‘ƒ*ğ‘†ğ¸/ğ‘ƒ*ğ‘Šğ¶)\* ğ‘†*ğ‘†ğ¸

<br/>

ì¦‰, ê³ ì • ì˜ˆì‚°ì—ì„œ ğ‘ƒ_ğ‘†ğ¸/ğ‘ƒ_WC ë§Œí¼ WCì—ì„œ ë” ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆë‹¤ëŠ” ë§. ì´ë ‡ê²Œ ë‘˜ ì¤‘ í•˜ë‚˜ë¡œ ë°ì´í„°ë¥¼ ë§Œë“  ì´í›„, ê³ ì •ëœ ìŠ¤í…ìœ¼ë¡œ ëª¨ë¸ë“¤ì„ í•™ìŠµì‹œì¼œë³´ê³  ë¹„êµí•˜ì—¬ ë°ì´í„°ë“¤ì˜ ìœ ìš©ì„±ì„ íŒë‹¨í•  ìˆ˜ ìˆë‹¤.

ì–¸ê¸‰í–ˆë“¯ í•™ìŠµ ë°©ë²•ì€ 3ê°€ì§€:

1. knowledge distillation(Student-LM finetuning)

   - ì¼ë°˜ì ìœ¼ë¡œ, student ëª¨ë¸ì˜ í•™ìŠµìš©ìœ¼ë¡œ ë§Œë“¤ì–´ì§€ëŠ” ë°ì´í„°ëŠ” ë” ë˜‘ë˜‘í•˜ê³  ê°•í•œ ëª¨ë¸ì—ì„œ ë§Œë“¤ì–´ì§€ëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•œë‹¤. ë†’ì€ í€„ë¦¬í‹°ë¥¼ ë³´ì¥í•˜ê¸° ìœ„í•´ì„œ.

1. self-improvement

   - Prior work (Singh et al., 2023)ëŠ” finetuning a WC model through self-generated dataëŠ” 1ì˜ ë°©ì‹ë³´ë‹¤ í›¨ì”¬ ë³„ë¡œë¼ê³  ì¦ëª…í•´ëƒˆë‹¤. í•˜ì§€ë§Œ, í•´ë‹¹ ì—°êµ¬ì˜ ë¹„êµ ë°©ì‹ì€ ê°™ì€ ì˜ˆì‚°ì„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ì •ë‹¹í•˜ì§€ ì•Šë‹¤ê³  ì–¸ê¸‰í•œë‹¤. ë”°ë¼ì„œ, ë‹¤ì‹œ ì •ë‹¹í•˜ê²Œ ë™ì¼í•œ ì„¸íŒ…ìœ¼ë¡œ ë‹¤ì‹œ í•˜ì—¬ ì‹¤í—˜ì„ ì¬ê°œí•œë‹¤.

1. ê·¸ë¦¬ê³  ì´ë“¤ì´ ì œì•ˆí•˜ëŠ” novel weak-to-strong improvement paradigm

   - weak-to-strong improvement (W2S-I)ì€ ì¼ë°˜ì ì¸ ë°©ë²•ê³¼ ë‹¬ë¦¬, ê°•í•œ ëª¨ë¸ì€ ì•½í•œ ëª¨ë¸ì˜ ë°ì´í„°ë¡œ í•™ìŠµí•˜ëŠ” ë°©ì‹ì´ë‹¤.

   - ì¦‰, ì•½í•œ ëª¨ë¸ë„ ê°•í•œ ëª¨ë¸ì„ ë°œì „ì‹œí‚¬ ìˆ˜ ìˆë‹¤

- Datasets

  - MATH

  - GSM-8K

- Data Generation

  - Gemma2 models for synthetic data generation

  - Gemma2-9B : Gemma2-27B = WC : SE models

  - MATH using a 4-shot prompt

  - GSM-8K using an 8-shot prompt

  <br/>

  - 9B modelê°€ 27Bì™€ 3ë°° ì •ë„ í¬ê¸° ì°¨ì´ê°€ ë‚˜ë¯€ë¡œ, ë°ì´í„°ë¥¼ 3ë°° ì •ë„ ë” ë§Œë“¤ ìˆ˜ ìˆë‹¤.

  - ì‹¤í—˜ì—ì„œëŠ” ë‘˜ ë‚˜ ë‚®ì€ ì˜ˆì‚°ì˜ ê²½ìš°: a low budget, where we generate 1 and 3 candidate solutions per problem from Gemma2-27B and Gemma2-9B

  - ë†’ì€ ì˜ˆì‚°ì˜ ê²½ìš°: high budget, where we generate 10 and 30 candidate solutions per problem

- Synthetic Data Evaluation

  - ê°™ì€ ë¹„ìš©ì„ ê°€ì§€ëŠ” ê°œìˆ˜ë¼ë¦¬ coverge/diversity@k ê³„ì‚°

  - FRPëŠ” 50ê°œ for each modelì— ëŒ€í•œ human eval & 500ê°œì— ëŒ€í•œ LLM eval

- Evaluating Finetuned Models:

  - pass@1 accuracy

- (Â§5.1) we analyze the data along various quality metrics .

- (Â§5.2) Subsequently, we present the supervised finetuning results for the different setups .

- (Â§5.3) Finally, we perform ablation studies to study the impact of dataset size, sampling
  strategy, and the role of quality dimensions in the model performance.

## 1. Synthetic Data Analysis

### 1) Coverage

### ê²°ë¡  Gemma2-9B (WC)ì´ Gemma2-27B (SE)ë³´ë‹¤ í›¨ì”¬ ì¢‹ì•˜ë‹¤.

- MATH:

- 11% and 6% at the low and high sampling budgets,

- 8% and 1% for GSM-8K.

ì¦‰, ë” ë§ì´ ë§Œë“œëŠ” ê²ƒì´ í€„ë¦¬í‹°ê°€ ë” ë‚®ë”ë¼ë„ ë” ë§ì´ ë¬¸ì œë¥¼ í‘¸ëŠ”ë° ë„ì›€ì´ ë˜ì—ˆë‹¤. converge trendëŠ” ë‹¤ì–‘.

ì¶”ê°€ì ìœ¼ë¡œ, ë” ë§ì´ ë°ì´í„°ë¥¼ ë§Œë“œëŠ” ê²ƒì€ ë¹„ë‹¨ ë‚®ì€ ë‚œì´ë„ì˜ ë¬¸ì œ ë¿ë§Œ ì•„ë‹ˆë¼ ë†’ì€ ë‚œì´ë„ì—ì„œë„ ê³µí†µì ì´ì—ˆë‹¤.

ì˜¤íˆë ¤ ë°˜ëŒ€ë¡œ, ë” í° ëª¨ë¸ë¡œ 10ê°œ ë§Œë“¤ ë•ŒëŠ” í’€ì§€ ëª»í–ˆë˜ ì–´ë ¤ìš´ ë¬¸ì œë„ ë” ì•½í•œ ëª¨ë¸ë¡œ 30ë²ˆ ë§Œë“œëŠ” ê²½ìš°ì— ìì£¼ í’€ë ¸ë‹¤ê³ .

### 2) Diversity

Gemma2-9Bì—ì„œ ìƒì„±ëœ ë°ì´í„°ì˜ ë‹¤ì–‘ì„±ì€ Gemma2-27Bë³´ë‹¤ MATH ë°ì´í„°ì…‹ì˜ ì €ì˜ˆì‚°ì—ì„œ 86%, ê³ ì˜ˆì‚°ì—ì„œ 125% ë” ë†’ì•˜ìœ¼ë©°, GSM-8K ë°ì´í„°ì…‹ì—ì„œëŠ” ê°ê° 134%ì™€ 158% ë” ë†’ìŒ.

### 3) FPR

human í‰ê°€ì— ë”°ë¥´ë©´ WC ëª¨ë¸ì´ ìƒì„±í•œ í•´ê²°ì±…ì˜ FPRì´ MATHì—ì„œëŠ” SE ëª¨ë¸ë³´ë‹¤ 7% ë†’ì•˜ê³ , GSM-8Kì—ì„œëŠ” 2% ë†’ì•˜ìŒ.
-> ìƒê°ë³´ë‹¤ ì°¨ì´ëŠ” ì•ˆë‚˜ì§€ë§Œ, ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ì¢‹ì§€ëŠ” ì•ŠìŒ.

## 2. Compute-Optimality Results for Training

ê·¸ë ‡ë‹¤ë©´ ì´ë“¤ì€ ë‹¤ì–‘í•˜ê²Œ í•™ìŠµí•´ë´¤ì„ ë•ŒëŠ” ì–´ë–¨ê¹Œ.

1. Student-LM Finetuning
   Gemma-7Bë¥¼ WCì™€ SCë¡œ í•™ìŠµí•œ ê²°ê³¼.
   WC consistently outperforms the one finetuned on data from SC. ì¼ë°˜ì ì¸ ë¯¿ìŒê³¼ ë‹¤ë¥´ë‹¤.

1. WC-LM Finetuning
   Gemma2-9Bë¥¼ Gemma2-9Bê°€ ë§Œë“  WCì™€ 27Bê°€ ë§Œë“  SCë¡œ í•™ìŠµí•œ ê²°ê³¼. ëŒ€ë¶€ë¶„ WCê°€ ë” ë‚˜ì•˜ì§€ë§Œ, ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ë„ ì¡´ì¬. ì €ìë“¤ì€ ì´ê²ƒì´ ë°ì´í„°ê°€ ë„ˆë¬´ ì‰¬ì›Œì„œë¼ê³  ì£¼ì¥.

1. SE-LM finetuning
   Gemma2-27Bë¥¼ ì–‘ ë°ì´í„°ë¡œ í•™ìŠµ. ë” ì‘ì€ ëª¨ë¸ë¡œ ë§Œë“  ë°ì´í„°ê°€ ë†€ëê²Œë„ ë” ë„ì›€ì´ ë˜ì—ˆë‹¤.

> Takeaway: Overall, our findings challenge the conventional wisdom that advocates training on samples from the SE model, by showing that training on samples from the WC model may be more compute-optimal across various tasks and setups.

## 3. Ablation Studies

### Impact of Dataset Size

### Default vs Compute-Optimal Sampling from Cheap LMs

ê·¸ë ‡ë‹¤ë©´, ê¸°ì¡´ì— SEë¥¼ ì‚¬ìš©í•˜ë˜ ì¼ë°˜ì ì¸ ë°©ë²•ì²˜ëŸ¼ ë°ì´í„° ê°œìˆ˜ë¥¼ í†µì¼í•˜ë©´?

ë³¼ ìˆ˜ ìˆëŠ” ê²ƒì²˜ëŸ¼, ë” í€„ë¦¬í‹° ì¢‹ì€ ê²ƒì„ ì‚¬ìš©í•˜ëŠ”ê²Œ ë” ì¢‹ì€ ê²ƒì€ í™•ì‹¤í•˜ë‹¤.

### Coverage and Diversity:

[//]: # "column_list is not supported"

    [//]: # (column is not supported)

    	ë°ì´í„°ì˜ ì •ë‹µë¥ ê³¼ ë‹¤ì–‘ì„±ì˜ ì¸¡ë©´ì—ì„œ ì–¼ë§ˆë‚˜ ì˜í–¥ë ¥ì´ í°ê°€ë¥¼ small scaleë¡œ ì‹¤í—˜í•œ ê²°ê³¼ë¬¼. 30ê°œì˜ ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„±.

    	1. high coverage, high diversity

    	1. high coverage, low diversity

    		- í•˜ë‚˜ì˜ ì§ˆë¬¸ ë‹¹ ë§ëŠ”ê±° í•˜ë‚˜ë§Œ

    		- reduces the diversity of the original WC dataset from 11 to 1, while maintaining the coverage.

    	1. low coverage, low diversity

    		- one solution per problem from the WC model + ë‚®ì€ ì •ë‹µë¥  ê°€ì§€ë„ë¡ ì¼ë¶€ëŸ¬ í•„í„°

    [//]: # (column is not supported)

    	# Scaling to state-of-the-art language models

[//]: # "column_list is not supported"

    [//]: # (column is not supported)

    	ìœ„ì˜ ë¶€ë¶„ì—ì„œëŠ” open LMë“¤ì— ëŒ€í•´ì„œ ì‹¤í—˜í•œ ê²°ê³¼. ì´ ì„¹ì…˜ì—ì„œëŠ” Gemini-1.5-Pro and Gemini-1.5-Flashë¥¼ ì‚¬ìš©í•´ë³¸ë‹¤.

    	ëª¨ë¸ ì‚¬ì´ì¦ˆê°€ ê³µì‹ì ìœ¼ë¡œ ê³µê°œë˜ì§€ ì•Šì•˜ê¸°ì—, compute-matched samplingì—ëŠ” pricing per output tokenì„ Proxyë¡œ ì‚¬ìš©í•œë‹¤ê³ ..

    	- synthetic data from the Pro (SE) - $10.5

    	- Flash (WC) models. - $0.3

    [//]: # (column is not supported)

    	<br/>

> Takeaway: We demonstrate that price-matched sampling from weaker SoTA LMs produces
> superior reasoners compared to finetuning with data from stronger SoTA models.

<br/>
