---
categories: paper-reviews
date: '2024-07-30 00:00:00'
description: ' ë…¼ë¬¸ ë¦¬ë·° - In-Context Retrieval-Augmented Language Models'
giscus_comments: true
layout: post
related_posts: false
tags: llm paper-review
title: In-Context Retrieval-Augmented Language Models
---

**ë…¼ë¬¸ ì •ë³´**
- **Date**: 2024-07-30
- **Reviewer**: ê¹€ì¬í¬
- **Property**: Retrieval, ICL, In Context Learning

---

[//]: # (table_of_contents is not supported)

---

## 1-1. Contributions

2023ë…„ 01ì›”ì— ë°œí‘œëœ ë…¼ë¬¸ì´ë¼ëŠ” ì ì„ ê°ì•ˆ

ğŸ’¡ 1. Off-the-shelf Retrieverì„ ì´ìš©í•œ RAG í”„ë ˆì„ì›Œí¬ ìœ íš¨ì„± ì…ì¦
2. RAG í”„ë ˆì„ì›Œí¬ ë‚´ ì„¤ê³„ ìš”ì†Œ(retriever, stride, reranker)ì— ëŒ€í•œ ì‹¤í—˜ ì§„í–‰

- ì „ë°˜ì ì¸ ë…¼ë¬¸ì˜ ì„œìˆ ì€ ìµœê·¼ í™œë°œíˆ ì‚¬ìš©ë˜ëŠ” RAG í”„ë ˆì„ì›Œí¬ì—ì„œ í¬ê²Œ ë‹¤ë¥´ì§€ ì•ŠìŒ

	- ë‹¹ì—°í•œ ë‚´ìš©ì„ ë‹¹ì—°í•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•œ ë…¼ë¬¸!

<br/>

## 1-2. TL;DR

1. Off-the-shelf Retriever ì—­ì‹œ Reader ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì„ ì¤€ë‹¤.

1. Retrieverì˜ ì¢…ë¥˜(sparse, dense)ì™€ ê´€ê³„ì—†ì´ ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì„ ì¤€ë‹¤.

1. strideëŠ” ì ì ˆíˆ ì§§ê²Œ, retrieved passageì˜ ìˆ˜ëŠ” ë§ì„ìˆ˜ë¡ ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ëœë‹¤.

	1. í•˜ì§€ë§Œ strideê°€ ì§§ì„ìˆ˜ë¡, retrieved passageê°€ ë§ì„ìˆ˜ë¡ ì—°ì‚°ëŸ‰ ì¦ê°€

1. RerankerëŠ” ë‹¹ì—°í•˜ê²Œë„ ë„ì›€ì´ ëœë‹¤.

<br/>

> RALMì˜ Design ChoiceëŠ” ì´ˆë¡ìƒ‰ ê¸€ì”¨ë¡œ í‘œì‹œí•˜ì˜€ìŠµë‹ˆë‹¤.

## [2-1. Retriever-Augmented Generation(RAG)](https://arxiv.org/abs/2005.11401)

- Knowledge Intensive Task ì‹œ ì™¸ë¶€ Documentë¥¼ ì ì ˆíˆ ì´ìš©í•˜ë„ë¡ Retrieverë¥¼ ì´ìš©í•˜ëŠ” ë°©ë²•ë¡  ì œì•ˆ

- Retriever(query encoder)ì™€ Generator(T5)ë¥¼ ë™ì‹œì— í›ˆë ¨í•˜ëŠ” í•™ìŠµ ë°©ë²•ë¡  ì œì•ˆ

### 2-1-1. í•™ìŠµ ë°©ë²•

1. Retriever í›ˆë ¨: Knowledge Intensive Dataset(NQ, TriviaQA)ìœ¼ë¡œ í›ˆë ¨ëœ DPR ëª¨ë¸ ì´ìš©

1. End-to-End í›ˆë ¨: (Retrieveëœ document kê°œ, relevance score kê°œ, Generation Prob)ì„ ì´ìš©í•˜ì—¬ Generatorì™€ Retriever í›ˆë ¨

### 2-1-2. ì„±ëŠ¥

- ë‹¤ì–‘í•œ Knowledge Intensive Taskì—ì„œ ê¸°ì¡´ ë°©ë²•ë¡  ëŒ€ë¹„ ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±

[//]: # (column_list is not supported)

	[//]: # (column is not supported)

		- ê¸°ì¡´ ë°©ë²•ë¡ :

			- Closed Book: ì™¸ë¶€ Documentë¥¼ ì´ìš© X

			- Open Book: ì™¸ë¶€ documentë¥¼ ì´ìš©í•˜ë˜, Encoder-only Reader ì‚¬ìš©

	[//]: # (column is not supported)

		## 2-2. **[Improving language models by retrieving from trillions of tokens(RETRO)](https://arxiv.org/abs/2112.04426)**

- RAGë¥¼ í™•ì¥í•˜ì—¬ ë‹¤ì–‘í•œ ì¼ë°˜ íƒœìŠ¤í¬ì— ì ìš©í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ ì œì•ˆ

- Retriever(BERT)ë¥¼ Freezeí•˜ê³  queryì™€ ê°€ì¥ ê°€ê¹Œìš´ ë¬¸ì„œì˜ representationì— ëŒ€í•œ attention(Chunked Cross-Attention)êµ¬ì¡° ì œì•ˆ

### 2-2-1. ì„±ëŠ¥

- ëª¨ë¸ í¬ê¸°(million to billion)ì— ê´€ê³„ì—†ì´ ì¼ê´€ëœ ì„±ëŠ¥ ê°œì„  ê´€ì°°

- Retriever ì‚¬ìš© ì—¬ë¶€(on/off)ê°€ ì„±ëŠ¥ ê°œì„ ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒ í™•ì¸

<br/>

## 2-3. ìš”ì•½

**2023ë…„ì˜ ìƒí™©**

- LLaMAì˜ ë“±ì¥ ì´í›„ Open Source LLMì— ëŒ€í•œ ì—°êµ¬ ì§„í–‰

	- Zero/Few-shot ì„±ëŠ¥ì„ ê°œì„ ì‹œí‚¤ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ë°©ë²•ë¡  ì œì•ˆ

	- CoT, In-Context Learning

- Million Scaleì˜ RAG í”„ë ˆì„ì›Œí¬ ì—°êµ¬ë“¤ì´ ëë¬¼ì„ í–¥í•´ ê°€ê³  ìˆìŒ

	- [FiD](https://arxiv.org/abs/2007.01282), [Atlas](https://arxiv.org/abs/2208.03299), [FiD-Light ](https://arxiv.org/abs/2209.14290)

- LLMì— RAG í”„ë ˆì„ì›Œí¬ ì ìš©ì´ í™œë°œíˆ ì‹œì‘ë˜ë˜ ì‹œê¸°

## 3-1. In-Context RALM(Retriever-Augmented Language Modeling)

### 3-1-1. Language Modeling

$$ p\left(x_1, \ldots, x_n\right)=\prod_{i=1}^n p_\theta\left(x_i \mid x_{<i}\right) $$

- Prefix($ x_{<i} $)ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ì‹œì (i)ì˜ í† í° ë¶„í¬ë¥¼ ìƒì„±í•˜ëŠ” ì‘ì—…

### 3-1-2. Naive In-Context RALM

$$  p\left(x_1, \ldots, x_n\right)= \quad \prod_{i=1}^n p_\theta\left(x_i \mid\left[\mathcal{R}_{\mathcal{C}}\left(x_{<i}\right) ; x_{<i}\right]\right) $$

- ê¸°ì¡´ LMì— Retriever ì¶”ê°€

- $ \mathcal{R}_{\mathcal{C}}(x_{<i}) $: Prefixë¥¼ queryë¡œ Retriever ìˆ˜í–‰í•œ Top-k document

- ë§¤ ì‹œì ë§ˆë‹¤ ë‹¤ìŒ ê³¼ì • ìˆ˜í–‰

	1. Retrieval: í˜„ì¬ ì‹œì ê¹Œì§€ì˜ prefixë¥¼ queryë¡œ document retrieval

	1. Concatenation: ê¸°ì¡´ í…ìŠ¤íŠ¸($ x_{<i} $)ì™€ Retrieved Documentë¥¼ concat

		1. <span style='color:green'>concatëœ í…ìŠ¤íŠ¸ê°€ modelì˜ max lengthë¥¼ ë„˜ì„ ê²½ìš° ê¸°ì¡´ í…ìŠ¤íŠ¸(</span>$ x_{<i} $<span style='color:green'>)ë¥¼ truncation</span>

	1. Generation: ê¸°ì¡´ì— ìƒì„±ëœ í…ìŠ¤íŠ¸($ x_{<i} $)ì™€ Retrieved Documentë¥¼ ëª¨ë‘ ì…ë ¥ìœ¼ë¡œ í•˜ì—¬ i ì‹œì ì˜ token dist. ìƒì„±

<br/>

## 3-2. RALM Design Choices

### 3-2-1. Retrieval Stride($ s $)

$$ p\left(x_1, \ldots, x_n\right)= \quad \prod_{j=0}^{n_s-1} \prod_{i=1}^s p_\theta\left(x_{s \cdot j+i} \mid\left[\mathcal{R}_{\mathcal{C}}\left(x_{\leq s \cdot j}\right) ; x_{<(s \cdot j+i)}\right]\right) $$

ğŸ’¡ <span style='color:orange'>ì˜¤ëŠ˜ ì„œìš¸ì—ì„œ </span><span style='color:green'>ëŒ€ì „ê¹Œì§€ ê°€ëŠ” ë™ì•ˆ</span> <span style='color:blue'>ë‚ ì”¨ê°€ ì–´ë–»ê²Œ</span> <span style='color:pink'>ë³€í•  ê²ƒ ê°™ì•„?
</span><span style='color:orange'>ê¸ˆì¼ ì„œìš¸ì˜ ë‚ ì”¨ëŠ” 28ë„ë¡œ ì˜¨í™” â€¦
</span><span style='color:green'>ê¸ˆì¼ ëŒ€ì „ì˜ ë‚ ì”¨ëŠ” 35ë„ë¡œ ë§¤ìš° ë”ìš¸ ì˜ˆì • â€¦
</span><span style='color:blue'>ì „êµ­ ë‚ ì”¨ëŠ” ë¹„ê°€ ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤. </span>

- Naive RALM: ë§¤ í† í°ë§ˆë‹¤ Retrieval ì§„í–‰

	- Retrieval ë¹„ìš© + ìƒˆë¡­ê²Œ representation ê³„ì‚° ë¹„ìš© ë°œìƒ â†’ High cost

- Retrieval Stride($ s $): retrievalì„ ìˆ˜í–‰í•  ê°„ê²©

	- $ s=3 $: 3í† í° ìƒì„± ì‹œë§ˆë‹¤ ìƒˆë¡­ê²Œ retrievalì„ ìˆ˜í–‰

- $ n_s(=n/s) $: ì „ì²´ text lengthê°€ $ n $ì¼ ë•Œ, retrieval íšŸìˆ˜

- $ s $ì˜ í¬ê¸°ëŠ” ì†ë„(ì—°ì‚°ëŸ‰)ê³¼ ì„±ëŠ¥ ê°„ trade-off ê´€ê³„

	- $ s $ê°€ ì»¤ì§ˆìˆ˜ë¡ ì†ë„ëŠ” ë¹¨ë¼ì§€ì§€ë§Œ, ì„±ëŠ¥ì€ ì €í•˜ë¨

<br/>

### 3-2-2. Retrieval Query Length($ \ell $)

$$ p\left(x_1, \ldots, x_n\right)= \prod_{j=0}^{n_s-1} \prod_{i=1}^s p_\theta\left(x_{s \cdot j+i} \mid\left[\mathcal{R}_{\mathcal{C}}\left(q_j^{s, \ell}\right) ; x_{<(s \cdot j+i)}\right]\right) $$

ğŸ’¡ <span style='color:orange'>ì˜¤ëŠ˜ ì„œìš¸ì—ì„œ </span><span style='color:green'>ëŒ€ì „ê¹Œì§€ ê°€ëŠ” ë™ì•ˆ</span> â€¦<span style='color:orange'>
</span>$ \mathcal{R}_{\mathcal{C}} $<span style='color:orange'>(ì˜¤ëŠ˜ ì„œìš¸ì—ì„œ ëŒ€ì „ê¹Œì§€ ê°€ëŠ” ë™ì•ˆ)</span> â†’ ì„œìš¸? ëŒ€ì „?
$ \mathcal{R}_{\mathcal{C}} $<span style='color:green'>(ëŒ€ì „ê¹Œì§€ ê°€ëŠ” ë™ì•ˆ)</span> â†’ ëŒ€ì „ì˜ ë‚ ì”¨!

- Naive RALM: í˜„ì¬ê¹Œì§€ ìƒì„±ëœ ëª¨ë“  textë¥¼ queryë¡œ ì‚¬ìš©

	- í˜„ì¬ ì‹œì  token dist. ìƒì„± ì‹œ ì¤‘ìš”í•œ ì •ë³´ê°€ í¬ì„ë  ìˆ˜ ìˆìŒ

- $ q_j^{s, \ell}:=x_{s \cdot j-\ell+1}, \ldots, x_{s \cdot j} $: í˜„ì¬ê¹Œì§€ ìƒì„±ëœ í† í° ì¤‘ ì§ì „ $ \ell $ ê¸¸ì´ì˜ í† í°ë§Œ queryë¡œ í™œìš©

<br/>

## 3-3. Reranking

### 3-3-1. LM as Zero-Shot Rerankers

- LMì„ í•™ìŠµì—†ì´ Rerankerë¡œ í™œìš©í•˜ëŠ” ë°©ë²•ë¡  ì œì‹œ

- k: Top-kê°œì˜ Retrieved Document

- Objective: kê°œì˜ Document ì¤‘ ì„±ëŠ¥ ê°œì„ ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” top-1 docì„ rerank

	â‡’ train dataê°€ ì—†ëŠ” í™˜ê²½ì—ì„œ í•´ë‹¹ ì •ë³´ê°€ ë°˜ì˜ëœ Reranker êµ¬ì¶• X

	$$ i^*=\arg \max _{i \in[k]} p_\theta\left(y \mid\left[d_i ; x_{\leq s \cdot j}\right]\right) . $$

- ì…ë ¥ëœ textì˜ ì¼ë¶€ë¥¼ validation dataë¡œ í™œìš©

$$ \hat{i}=\arg \max _{i \in[k]} p_\phi\left(y^{\prime} \mid\left[d_i ; x_{\leq\left(s \cdot j-s^{\prime}\right)}\right]\right) . $$

- reranking: ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ $ s' $ê°œ í† í° PPLì„ ìµœì†Œí™”í•˜ëŠ” document íƒìƒ‰ ì‘ì—…

	- LMì„ ì´ìš©í•˜ì—¬ zero-shot reranker êµ¬ì¶• ê°€ëŠ¥

<br/>

### 3-3-2. Training LM-dedicated Rerankers

- RoBERTaë¥¼ í›ˆë ¨í•˜ì—¬ Rerankerë¡œ í™œìš©í•˜ëŠ” ë°©ì•ˆ ì œì‹œ

	- Language Modeling ìƒí™©ì—ì„œ í™œìš© ê°€ëŠ¥í•œ reranker í›ˆë ¨ ë°©ë²•ë¡ 

- Relevance Score: Rerankerì˜ scoreë¥¼ normalizeí•˜ì—¬ ì‚¬ìš©

	$$ p_{\text {rank }}\left(d_i \mid x_{\leq s \cdot j}\right)=\frac{\exp \left(f\left(x_{\leq s \cdot j}, d_i\right)\right)}{\sum_{i^{\prime}=1}^k \exp \left(f\left(x_{\leq s \cdot j}, d_{i^{\prime}}\right)\right)} \\ \hat{i}=\arg \max _{i \in[k]} p_{\text {rank }}\left(d_i \mid x_{\leq s \cdot j}\right) . $$

- Training Objectives: PPLì„ ë‚®ì¶”ëŠ” Documentì˜ Relevance Scoreë¥¼ ë†’ì´ë„ë¡ í•™ìŠµ

$$ -\log \sum_{i=1}^k p_{\text {rank }}\left(d_i \mid x_{\leq s \cdot j}\right) \cdot p_\theta\left(y \mid\left[d_i ; x_{\leq s \cdot j}\right]\right) $$

## 4-1. Experiment Setup

### 4-1-1. Datasets

1. **Language Modeling(Perplexity)**

	1. WikiText-103: ì¼ë°˜ì ì¸ LM ì„±ëŠ¥ í‰ê°€ìš© corpus

	1. The Pile(ArXiv, Stack Exchange, FreeLaw): íŠ¹ì • ë„ë©”ì¸(ê³¼í•™, ì½”ë“œ, ë²•ë¥ )ì— ëŒ€í•œ LM ì„±ëŠ¥ í‰ê°€ ëª©ì 

	1. RealNews: ì¼ë°˜ì ì¸ RALM í”„ë ˆì„ì›Œí¬ ì‚¬ìš© í™˜ê²½(Knowledge-Intensive task)ì— ëŒ€í•œ ì„±ëŠ¥ í‰ê°€ ëª©ì 

1. **Open-Domain Question Answering(Exact Match)**

	1. RALMì˜ ì‹¤ì œ ì •ë‹µ ìƒì„± ëŠ¥ë ¥ í‰ê°€ ëª©ì 

	1. ì§€ì‹ ê¸°ë°˜ì˜ ì§ˆì˜ì‘ë‹µ ë°ì´í„°ì…‹ ì´ìš©

	1. Natural Questions, TriviaQA

<br/>

### 4-1-2. Models

1. **Language Models**

	1. GPT-2(110M ~ 1.5B): Wikipedia ë¬¸ì„œê°€ ì œì™¸ë˜ì–´ í•™ìŠµ

		â‡’ WikiText-103ì„ ì´ìš©í•˜ì—¬ ì™„ì „í•œ zero-shot ìƒí™©ì—ì„œì˜ ì„±ëŠ¥ í™•ì¸ ê°€ëŠ¥

	1. GPT-Neo, GPT-J(1.2B ~ 6B)

	1. OPT(125M ~ 66B)

	1. LLaMA1(7B ~ 33B)

		1. ë‹¤ì–‘í•œ scaleì˜ ëª¨ë¸ì— ëŒ€í•œ íš¨ê³¼ ê²€ì¦

		1. Wikipediaê°€ í•™ìŠµì— ì´ìš©ë˜ì—ˆìœ¼ë¯€ë¡œ í•™ìŠµë°ì´í„°ì˜ RALM íš¨ê³¼ í™•ì¸

	<span style='color:green'>**Context Length: 1024**</span>

1. **Retriever**

	1. Sparse Retriever: BM25

	1. Dense Retriever

		1. BERT: RETROì™€ ë™ì¼í•˜ê²Œ retriever finetuneë˜ì§€ ì•Šì€ ê²½ìš°ì˜ ì„±ëŠ¥ í™•ì¸

		1. Contriever, Spider: Unsupervised Mannerë¡œ í•™ìŠµëœ Retriever

1. **Reranker**

	1. RoBERTa-base ì‚¬ìš©

		1. í–¥í›„ ì‹¤í—˜ì—ì„œ í•™ìŠµ ì—¬ë¶€ì— ë”°ë¥¸ ì„±ëŠ¥ ì‹¤í—˜ ì§„í–‰

	<span style='color:green'>**Retrieved Document Length: 256**</span>

<br/>

## 4-2. Effectiveness of Retriever

### 4-2-1. ëª¨ë¸ ë³„ RALM ì ìš© ì‹œ ì„±ëŠ¥ ë³€í™”(s=4, l=32)

***ëª¨ë¸ í¬ê¸°ì™€ ê´€ê³„ì—†ì´ RALM ì ìš© ì‹œ ì„±ëŠ¥ì´ ê°œì„ ë¨***

- BM25: RETRO ë° RAGì™€ ë‹¤ë¥´ê²Œ LMê³¼ í•¨ê»˜ í•™ìŠµëœ Retriever X, Sparse Retriever

- ëª¨ë“  ëª¨ë¸ì—ì„œ RALM ì ìš© ì‹œ PPLì´ ê°œì„ ë˜ëŠ” ëª¨ìŠµ

- í° ëª¨ë¸ w/o Retriever < ì‘ì€ ëª¨ë¸ w/ Retriever

	- OPT-66B w/o Retriever < OPT-6.7B w/ Retriever

<br/>

### 4-2-2. Retrieval ì¢…ë¥˜ ë³„ ì„±ëŠ¥ ì–‘ìƒ

***Sparse Retrieverê°€ Dense Retrieverë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ ë‹¬ì„± ê°€ëŠ¥***

- Language Modeling íƒœìŠ¤í¬ì—ì„œ Sparse Retriever(BM25)ê°€ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ ë‹¬ì„±

- ëª¨ë¸ í¬ê¸°ì— ê´€ê³„ì—†ì´ ë™ì¼í•œ ì–‘ìƒ ìœ ì§€

- Wikipedia(Spider), Wikepedia + CCNet(Contriever)ì˜ ê²½ìš° ë¹„ìŠ·í•œ ì„±ëŠ¥ ë„ì¶œ

	- BM25ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šìœ¼ë‚˜, Retrievalì„ ì‚¬ìš©í•˜ì§€ ì•Šì€ ê²½ìš°ë³´ë‹¤ ê°œì„ 

- BERTì˜ ê²½ìš° ì„±ëŠ¥ ê°œì„  X

	- RETRO: BERTë¥¼ Freezeí•˜ì—¬ Retrieval Moduleë¡œì„œ í™œìš©

	- RALM í”„ë ˆì„ì›Œí¬ì—ì„œ Retrievalì˜ ì„±ëŠ¥ì´ ì¤‘ìš”

<br/>

## 4-3. Design Choice of RALM

### 4-3-1. Retrieval Stride

***Strideì— ë”°ë¥¸ ì„±ëŠ¥ê³¼ ì†ë„ Trade-off ê´€ê³„ ì¡´ì¬ í™•ì¸***

- Strideê°€ ì§§ì„ìˆ˜ë¡ ì„±ëŠ¥ì´ ê°œì„ ë˜ëŠ” ê²½í–¥ì„± í¬ì°©

- ì§§ì€ Retrieval Stride: ìì£¼ Retrieve â†’ í˜„ì¬ ìƒì„±í•˜ê³ ì í•˜ëŠ” ì •ë³´ì™€ ìœ ì‚¬í•œ ì •ë³´ë¥¼ Retrieveí•  ìˆ˜ ìˆìŒ

### 4-3-2. Retrieval Query Length

***ì ì ˆí•œ ê¸¸ì´ì˜ Query Lengthê°€ Retrieval íš¨ê³¼ ê²°ì •***

- BM25 ì´ìš© ì‹œ Query Lengthì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”

- Query Length=32ì¼ ë•Œ ìµœì ì˜ ì„±ëŠ¥ ë„ì¶œ

- Dense Retrieval ì‚¬ìš© ì‹œ 64 ê¸¸ì´ê°€ ìµœì 

- ë„ˆë¬´ ê¸´ Query Length: Retrieveí•´ì•¼ í•˜ëŠ” ì •ë³´ê°€ í¬ì„

- ë„ˆë¬´ ì§§ì€ Query Length: Retrieveí•´ì•¼ í•˜ëŠ” ì •ë³´ê°€ ì¶©ë¶„íˆ ë°˜ì˜ X

<br/>

## 4-4. Effect of Reranker

### 4-4-1. Reranker ì‚¬ìš©ì˜ íš¨ê³¼

***w/o Retrieval < w/ Retrieval < w/ Reranker < w/ Trained Reranker***

- ëª¨ë“  ë°ì´í„° ë° ëª¨ë¸ì—ì„œ ë™ì¼í•œ ê²½í–¥ì„± í¬ì°©

	- Retrieval ì‚¬ìš©(top-1) ì‹œ ê°€ì¥ í° ì„±ëŠ¥ ê°œì„  í™•ì¸

	- Reranker ì‚¬ìš©(top-16) ì‹œ ì¶”ê°€ì ì¸ ì„±ëŠ¥ ê°œì„  í™•ì¸

<br/>

### 4-4-2. Reranker íš¨ê³¼ì˜ ì›ì¸

***Retrieved Document ì¤‘ ìµœì„ ì˜ ë¬¸ì„œëŠ” ë”°ë¡œ ìˆë‹¤. ***

- Oracle: Top-16 document ì¤‘ ê°€ì¥ ì„±ëŠ¥ ê°œì„ ì´ í° Documentì˜ ì„±ëŠ¥

	- Retrieval íŠ¹ì„± ìƒ Top-1 Documentê°€ í•­ìƒ ìµœì„ ì˜ ë¬¸ì„œ X

	- Document ì¤‘ ì‹¤ì œ ì„±ëŠ¥ ê°œì„ ì´ ë” ë„ì›€ì´ ë˜ëŠ” Docì„ íƒìƒ‰í•˜ëŠ” ì‘ì—…ì´ ì¤‘ìš”

<br/>

### 4-4-3. Zero-Shot Reranker

***Zero-shot Rerankerì˜ í¬ê¸°ëŠ” ì¤‘ìš”í•˜ì§€ ì•Šë‹¤***

- Zero-shot Reranker: ì‚¬ì „í•™ìŠµëœ LMì„ ì´ìš©í•˜ì—¬ Reranking ì‘ì—… ìˆ˜í–‰

	- ì‹¤ì œ Language Modelingì„ ìˆ˜í–‰í•˜ëŠ” LMì¼ í•„ìš” X

		â‡’ ì‘ì€ LMì„ Rerankerë¡œ ì´ìš©í•œë‹¤ë©´ íš¨ìœ¨ì  reranking ê°€ëŠ¥

		<br/>

## 4-5. Open-Domain Question Answering

### 4-5-1. ODQA w/ RALM

***LLMì„ ODQAì— í™œìš©í•  ë•Œë„ RALMì€ ë§¤ìš° íš¨ê³¼ì ì´ë‹¤. ***

- DPR: NQì™€ TriviaQAë¡œ í•™ìŠµëœ Retriever

	- ì´ì „ê³¼ ë‹¤ë¥´ê²Œ In-Domain Retriever í™œìš©

- RALMì„ í†µí•´ LLMì˜ Knowledge Intensive Task ì„±ëŠ¥ì„ ë¹„ì•½ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŒ

### 4-5-2. # of Document for ODQA

***ODQAì—ì„œëŠ” Documentì˜ ìˆ˜ê°€ ë§ì„ í•„ìš”ê°€ ì—†ë‹¤. ***

- ë‹¤ì†Œ í˜¼ì¬ëœ ì‹¤í—˜

	- Retrieval: DPR

	- ì´ì „ê³¼ ë‹¤ë¥´ê²Œ In-Domain Retriever: Retrieved Documentì˜ í’ˆì§ˆì´ Language Modeling ì‹œë³´ë‹¤ ì¢‹ì„ ìˆ˜ ë°–ì— ì—†ìŒ

		â‡’ Contriever, Spider ë“±ì˜ Unsupervised Dense Retriever ì‚¬ìš© ì‹œì—ë„ ë¹„ìŠ·í•œ ì„±ëŠ¥ ì–‘ìƒì´ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸ í•„ìš”

- ëª¨ë¸ í¬ê¸°ì™€ ê´€ê³„ì—†ì´ ì¼ê´€ëœ Optimal Document ìˆ˜ê°€ ì •í•´ì§(1, 2)

<br/>

## 7. Conclusion

ğŸ’¡ 1. Off-the-shelf Retrieverì„ ì´ìš©í•œ RAG í”„ë ˆì„ì›Œí¬ ìœ íš¨ì„± ì…ì¦
2. RAG í”„ë ˆì„ì›Œí¬ ë‚´ ì„¤ê³„ ìš”ì†Œ(retriever, stride, reranker)ì— ëŒ€í•œ ì‹¤í—˜ ì§„í–‰

- BM25: Language Modeling ì‹œ ê°•ë ¥í•œ Retriever baselineìœ¼ë¡œ ë™ì‘

	- ìµœê·¼ ì—°êµ¬ë˜ëŠ” ë‹¤ì–‘í•œ embedding modelë“¤ì´ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì„

		â†’ ëª¨ë¸ í¬ê¸° ì¦ê°€(~7B)ë¥¼ í†µí•œ ì¼ë°˜í™” Retrieval ì„±ëŠ¥ ê°œì„ 

- Off-the-Shelf Retrieverì˜ Language Modeling ì‹œì˜ ì„±ëŠ¥ ê°œì„  íš¨ê³¼ í™•ì¸

	- ê¸°ì¡´ ì—°êµ¬: Retrieverë¥¼ LMê³¼ í•¨ê»˜ í•™ìŠµ â†’ LLMê³¼ joint train ì‹œ ë§¤ìš° í° ë¹„ìš© ë°œìƒ

	- ë³„ë„ë¡œ í•™ìŠµëœ Retriever or BM25ë¥¼ í™œìš©í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œë„ ì„±ëŠ¥ ê°œì„ ì´ ê°€ëŠ¥í•¨

- ì´í›„ RAG ê¸°ë°˜ ì—°êµ¬ë“¤ì˜ baselineìœ¼ë¡œì„œ ë™ì‘í•˜ëŠ” ì—°êµ¬