---
categories: paper-reviews
date: '2025-03-04 00:00:00'
description: ' ë…¼ë¬¸ ë¦¬ë·° - SWE-RL: Advancing LLM Reasoning via Reinforcement Learning
  on Open Software Evolution'
giscus_comments: true
layout: post
related_posts: false
tags: llm paper-review
title: 'SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software
  Evolution'
---

**ë…¼ë¬¸ ì •ë³´**
- **Date**: 2025-03-04
- **Reviewer**: ì „ë¯¼ì§„
- **Property**: RL

ğŸ’¡ SWE-benchì—ì„œë„ rule-based RLì´ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì„!

	RLìœ„ì£¼ë¡œ ê°„ë‹¨í•˜ê²Œë§Œ ì •ë¦¬

## Abstract

- DeepSeek-R1 ì¶œì‹œ ì´í›„, RLì´ ëª¨ë¸ì˜ ì¼ë°˜ì ì¸ reasoning ability ëŒì–´ì˜¬ë¦´ ìˆ˜ ìˆë‹¤ëŠ” ì ì¬ë ¥ì´ ì¦ëª…ë¨

	- í•˜ì§€ë§Œ DeepSeek-R1ì€ ìˆ˜í•™ê³¼ ê°„ë‹¨í•œ codeì—ì„œë§Œ ì ìš©

	â‡’ real-world software engineeringì—ì„œë„ ë ê¹Œ?

	- real-world software engineeringì— ëŒ€í•´ì„œ ì²˜ìŒìœ¼ë¡œ RL-based LLMì„ í•™ìŠµí•œ SWE-RLì„ ì œì•ˆ

- ê°„ë‹¨í•œ rule-based reward(ì •ë‹µê³¼ ëª¨ë¸ì´ ìƒì„±í•œ ë‹µë³€ê³¼ì˜ ìœ ì‚¬ë„)ì„ í™œìš©í•´ì„œ í•™ìŠµ, SWE-RLì€ in-domainë¿ë§Œ ì•„ë‹ˆë¼ out-of-domainì—ì„œë„ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì„

## Introduction

- DeepSeek-R1ì€ rule-based RLì´ ìš©ì´í•œ ë„ë©”ì¸ì— ëŒ€í•´ì„œë§Œ í•™ìŠµ, ì‹¤í—˜ ì§„í–‰

	- ìˆ˜í•™ì˜ ê²½ìš° ëª…í™•í•œ ë‹µì´ ì¡´ì¬, codeì˜ ê²½ìš° ì‹¤í–‰í•´ë³´ë©´ ê²°ê³¼ê°€ ëª…í™•í•˜ê²Œ ë‚˜ì˜´

		- self-containedë˜ê³ , ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì½”ë“œ

	- ë‹¨, ì´ëŸ¬í•œ ì½”ë“œëŠ” í•œì •ì , real-world SE taskì— ë°”ë¡œ ì ìš©í•˜ê¸°ëŠ” ì–´ë ¤ì›€

- SE taskì— ëŒ€í•´ì„œ LLMì„ í–¥ìƒì‹œí‚¤ëŠ” ì²«ë²ˆì§¸ RL method, SWE-RLì„ ì œì•ˆ

	- githubì—ì„œ seed dataset êµ¬ì¶•

		- ê° í•™ìŠµë°ì´í„°ëŠ” issue, code context, oracle patchë¡œ êµ¬ì„±

	- ì½”ë“œ ë³€í™”(ìˆ˜ì •ì‚¬í•­)ì€ ì¼ê´€ëœ patch formatìœ¼ë¡œ ë³€í™˜, ì •ë‹µê³¼ì˜ ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ reward ë§¤ê¹€

		- difflib.SequenceMatcher ì‚¬ìš© (ì•ŒíŒŒë²³ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬ë„ 0-1ì‚¬ì´ë¡œ ì¸¡ì •) - ê²ë‚˜ ë‚˜ì´ë¸Œ

	- ì‹¤í—˜ ê²°ê³¼, Llama3-SWE-RL-70BëŠ” SWE-bench Verifiedì—ì„œ 41.0%ì„±ëŠ¥ì„ ëƒ„ (<100B ëª¨ë¸ë“¤ ì¤‘ì—ì„œëŠ” ìµœê³  ì„±ëŠ¥), ì´ ë¿ë§Œ ì•„ë‹ˆë¼ í•™ìŠµê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ì´ ì—†ëŠ” out-of-domain (function-level docing, practical code generation wtih library use, code reasoning, mathematics, general language understanding)ì—ì„œë„ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë¨

## SWE-RL

### Raw pull request data curation

- Github events and clones

	- 2ê°€ì§€ ì •ë³´ë¥¼ í¬í•¨í•˜ë„ë¡ ë°ì´í„°ë¥¼ ìˆ˜ì§‘

		- PRë‚´ì—ì„œ ë°œìƒí•œ ëª¨ë“  event, PRì— ì˜í•´ì„œ merge ë˜ê¸° ì „ì˜ repo ì†ŒìŠ¤ì½”ë“œ

	- ì†ŒìŠ¤ ì½”ë“œë¥¼ ì–»ê¸° ìœ„í•´ì„œ, Github APIë³´ë‹¤ git cloneì„ ì£¼ë¡œ ì‚¬ìš© â‡’ 4.6Mì˜ repositoriesë¥¼ ìˆ˜ì§‘

- PR data aggregation â‡’ ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ ì°¸ê³ .. ì´í•´ ëª»í–ˆìŒ..

	- ê° PRì„ ê°œë³„ì ìœ¼ë¡œ ë³´ê³ , ê·¸ì™€ ê´€ë ¨ ìˆëŠ” ì •ë³´ë¥¼ ëª¨ë‘ í•©ì¹¨

	- ìš°ì„ , merged PRì„ ìœ ì§€, ê° PRì˜ ê´€ë ¨ëœ conversational eventë¥¼ ìˆ˜ì§‘, chronological orderë¡œ ì •ë ¬

	- ë‘ë²ˆì§¸ë¡œ base_commitê³¼ head_commitì„ ì‚¬ìš©í•´ì„œ, ìˆ˜ì •ëœ íŒŒì¼ ë‚´ìš©ì„ ê²€ìƒ‰

	- ë§ˆì§€ë§‰ìœ¼ë¡œ ê° í•©ì³ì§„ PRë¥¼ ë³´ê³  íŒ¨í„´ ì‹ë³„, ìœ ì‚¬í•œ ì• ë“¤ë¼ë¦¬ ë˜ ê²°í•©

	- ìµœì¢…ì ìœ¼ë¡œ 24Mì˜ PR instanceë¥¼ ì–»ìŒ

- Relevant files prediction

	- í˜„ì¬ ëª¨ë“  pull requestëŠ” ìˆ˜ì •ëœ íŒŒì¼ë§Œ í¬í•¨ë¨

	- ì´ˆê¸° ì‹¤í—˜ì—ì„œ, ì´ëŸ¬í•œ ë°ì´í„°ë¡œ í•™ìŠµí•˜ë‹ˆ, LLMì´ ì£¼ì–´ì§„ ëª¨ë“  ì½”ë“œë¥¼ ìˆ˜ì •í•˜ë ¤ê³  í•¨

	- ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ, Llama-3.1-70B-Instructë¡œ PRê³¼ ê´€ë ¨ ìˆì§€ë§Œ ìˆ˜ì •ë˜ì§€ ì•Šì€ íŒŒì¼ì„ ìƒì„±í•˜ë„ë¡ prompt

- Data filtering

	- ìš°ë¦¬ì˜ ëª©í‘œëŠ” ì–´ëŠì •ë„ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ìƒíƒœì—ì„œ ê³ í’ˆì§ˆì˜ PRì— ëŒ€í•œ recallì„ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì—, êµ¬ë¦° ë°ì´í„°ë¥¼ í•„í„°ë§

	- í•„í„°ë§ ëŒ€ìƒ

		- botì´ ìƒì„±í•œ PRì œê±°

		- ë³€í™”ê°€ ì—†ê±°ë‚˜ ë„ˆë¬´ ë§ì´ ë°”ë€ PR

		- ì´ì™¸ì— CodeLlamaë¡œ ì¢€ ë” ì„¬ì„¸í•˜ê²Œ í•„í„°ë§(e.g., with only lock file changes or version updates)

	- ìµœì¢…ì ìœ¼ë¡œ 11Mì˜ unique PR instanceê°€ êµ¬ì¶•ë¨

		- data = (issue, code context, oracle patch)

### Reward modeling

- logic-RLê³¼ ìœ ì‚¬í•˜ê²Œ system promptë„£ì–´ì¤Œ, formatì´ í‹€ë¦´ ê²½ìš° -1ì„, ë§ì„ ê²½ìš° ì •ë‹µê³¼ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ rewardë¥¼ ì¤Œ

	- lossì‹ì€ GRPOì™€ ë™ì¼

	- SWE-RLì—ì„œì˜ í•™ìŠµì„ ì‚´í´ë³´ë©´, í•™ìŠµë°ì´í„°ì—ëŠ” ë‚´ì¬ì ìœ¼ë¡œ bug ì§„ë‹¨, ìˆ˜ì •ì‚¬í•­ ìƒì„± task 2ê°€ì§€ ì •ë„ë§Œ ì»¤ë²„

	- í•˜ì§€ë§Œ agentless mini(SE taskì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” Inference framework ì •ë„ë¡œ ì´í•´)ëŠ” ìˆ˜ì •ì‚¬í•­ ìƒì„±ì„ ë„˜ì–´ì„œ, íŒŒì¼ ìˆ˜ì¤€ì˜ ì˜¤ë¥˜ íƒì§€, test ìƒì„± ì¬í˜„ ë“±ì˜ í•™ìŠµ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ taskë¥¼ ìˆ˜í–‰í•˜ë„ë¡ í•˜ì§€ë§Œ, ê·¸ë˜ë„ ì„±ëŠ¥ì´ ë†’ê²Œ ë‚˜ì˜´!

### Aha Moments and generalized reasoning capabilities

- SWE-RLì—ì„œë„ ì•„í•˜ëª¨ë¨¼íŠ¸(ì‹¬í™”ëœ reasoning ability)ê°€ ë‚˜íƒ€ë‚¨, íŠ¹íˆ SE taskì—ì„œ í•„ìš”í•œ reasoning abilityê°€ ì•„ë‹ˆë¼ ë²”ìš©ì ì¸ reasoning ability(self reflection, exploring multiple approaches, divide-and-conquer)ë“±ì´ ë°œí˜„ë¨

## Evaluation

### Experimental Setup

- Training configs

	- Llama-3.3-70B-Instructë¥¼ ê¸°ë°˜ìœ¼ë¡œ Llama3-SWE-RL-70Bë¥¼ í•™ìŠµ

		- 1600 steps with 16k context window

		- global batch size 512, sampling 16 rollouts from each of the 32 problems in every batch

		- For every global step, a single optimization step is performed

- Scaffolding

	- Agentlessë¥¼ ê¸°ë°˜ìœ¼ë¡œ Agentless Minië¥¼ ê²Œë°œ

	- Agentlessì˜ multi-step localizationê³¼ ë‹¬ë¦¬, miniì—ì„œëŠ” file-level localizationì—ë§Œ ì§‘ì¤‘, ì „ì²´ íŒŒì¼ì„ ì œê³µí•˜ê³  detailed reasoningì„ repair stepì—ì„œ ìˆ˜í–‰

		(ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ ì°¸ê³ )

- Evaluation setup

	- SWE-bench Verifiedë¡œ í‰ê°€

		- SWE-benchì—ì„œ ì‚¬ëŒì´ ê²€ì¦í•œ 500ê°œì˜ ë¬¸ì œ

	- ê° ë¬¸ì œë§ˆë‹¤ 500ê°œì˜ patchìƒì„±(with 1.0 temperature), executionê³¼ rerankingì—ì„œ top 30 reproduction testë¥¼ ì‚¬ìš©, ìµœì¢…ì ìœ¼ë¡œ 1ë“± patchë¥¼ pass@1 scoreë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ ì‚¬ìš©

- SFT baseline

	- í•™ìŠµ ë°©ë²•ì˜ ì°¨ì´ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•´ Llama-3-SWE-SFT-70Bë„ í•™ìŠµ

	- seed datasetìœ¼ë¡  ë™ì¼í•œ ë°ì´í„°ì…‹ ì‚¬ìš©, SFTëŠ” ë°ì´í„°ì…‹ ë‹¤ì–‘ìƒê³¼ ëª¨ë¸ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ CoT, mixture dataí•„ìš”
 â‡’ PR data with CoT, Llama3 coding SFT data, Llama 3general SFT dataë“±ì„ ì„ì–´ì„œ í•™ìŠµ

### Main results

- GPT-4o í˜¹ì€ Claude-3.5-Sonnetì˜ ê²°ê³¼ë¥¼ Distillationí•œ Lingma-SWE-GPT, SWE-Gym, SWE-Fixer ë“±ì„ ë¹„êµêµ°ìœ¼ë¡œ ì‚¬ìš©

- distillation data êµ¬ì¶• ì—†ì´ë„ ì„±ëŠ¥ ì••ë„

### Baseline comparison

- Repair performanceì— ì§‘ì¤‘í•´ ì„±ëŠ¥ ë¶„ì„

- Llama-3.3ëª¨ë¸ì€ 20ê°œ ìƒ˜í”Œë§í•´ì„œ ë‹¤ìˆ˜ê²°í•´ë„ formattingì— ì–´ë ¤ì›€ì„ ê²ªìŒ

- RLì€ formattingë„ ì˜í•˜ë©´ì„œ repair performanceë„ ìš°ìˆ˜

### Scaling analysis with more samples

- repair sample, test sampleì˜ ìˆ˜ë¥¼ ì¡°ì ˆí•˜ë©´ì„œ ì„±ëŠ¥ ë¹„êµ

- ì–´ëŠì •ë„ í° ìˆ˜ê°€ ë˜ë©´ ì„±ëŠ¥ì´ ìˆ˜ë ´

### Generalizability of RL

- SWE-bench ì™¸ì—ë„ function coding, library use, code reasoningë“±ì˜ code ë„ë©”ì¸ì˜ ë‹¤ë¥¸ taskì—ì„œë„ ì„±ëŠ¥ì´ í–¥ìƒë¨

- ëŒ€ë‹¨í•œê±´ MATH ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒ, MMLU ì„±ëŠ¥ì„ ìƒì§€ ì•ŠìŒ..!!!

### Reward ablation

- rewardë¥¼ 0-1ì‚¬ì´ì˜ continuousê°’ì´ ì•„ë‹ˆë¼ discreteí•œ ê°’ìœ¼ë¡œ ì£¼ì—ˆì„ ë•Œì˜ ê²°ê³¼

- continuousê°€ ë‚«ë‹¤!