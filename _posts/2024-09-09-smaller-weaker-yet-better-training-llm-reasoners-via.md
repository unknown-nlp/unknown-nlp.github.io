---
categories:
  - paper-reviews
date: "2024-09-09 00:00:00"
description: ë…¼ë¬¸ ë¦¬ë·° - Knowledge Distillation, LLM, Limited Budget ê´€ë ¨ ì—°êµ¬
giscus_comments: true
layout: post
related_posts: false
tags:
  - knowledge distillation
  - language-model
  - limited budget
  - llm
  - paper-review
  - reasoning
thumbnail: assets/img/posts/2024-09-09-smaller-weaker-yet-better-training-llm-reasoners-via/thumbnail.jpg
title: "Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling"
---

**ë…¼ë¬¸ ì •ë³´**

- **Date**: 2024-09-09
- **Reviewer**: hyowon Cho
- **Property**: Knowledge Distillation, LLM, Limited Budget

> Google DeepMind (2024-08-30)

# Introduction

ë§Žì€ ì—°êµ¬ë“¤ì´ ì´ë¯¸ ì–¸ì–´ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë° synthetic ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê³  ìžˆë‹¤. ì´ë“¤ ì¤‘, reasoning taskì—ì„œ ê°€ìž¥ ì¼ë°˜ì ì¸ ë°©ë²•ì€ í•˜ë‚˜ì˜ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ì—¬ëŸ¬ ê°€ì§€ í›„ë³´ ë‹µë³€ë“¤ì„ ìƒì„±í•˜ê²Œ í•˜ê³ , ì´ë¥¼ gold answerì™€ ë¹„êµí•´, ë§žëŠ” ì •ë‹µì„ ê°€ì§„ ê²ƒë“¤ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ë²„ë¦¬ëŠ” ê²ƒì´ë‹¤.

í•˜ì§€ë§Œ, ì´ë ‡ê²Œ ì—¬ëŸ¬ ê°œì˜ ë°ì´í„°ë¥¼ strong LMsë¡œ ë¶€í„° ìƒì„±í•´ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ë¹„ì‹¸ê³ , resource-intensiveí•˜ë‹¤. ë˜í•œ í˜„ì‹¤ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ” ì˜ˆì‚°ì€ ì •í•´ì ¸ìžˆê¸° ë•Œë¬¸ì— ë§Œë“¤ ìˆ˜ ìžˆëŠ” solutionë„ ê·¸ë¦¬ ë§Žì§€ëŠ” ëª»í•˜ë‹¤.

ì´ ë…¼ë¬¸ì—ì„œëŠ” fixed compute budget ìƒí™©ì—ì„œ, weaker but cheaper (WC) modelì´ ìš°ë¦¬ê°€ ì¼ë°˜ì ìœ¼ë¡œ ìƒê°í•˜ëŠ” ê²ƒê³¼ ë‹¤ë¥´ê²Œ stronger but more expensive (SE) modelì„ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë‚«ë‹¤ê³  ì£¼ìž¥í•œë‹¤.

ì´ë¥¼ ì¦ëª…í•˜ê¸° ìœ„í•´ ì €ìžë“¤ì€ í¬ê²Œ 3ê°€ì§€ ì¶•ì—ì„œ ë°ì´í„°ë“¤ì— ëŒ€í•œ ë¹„êµë¥¼ ì§„í–‰í•œë‹¤.

1. coverage, the number of unique problems that are solved,

1. diversity, the average number of unique solutions we obtain per problem,

1. false positive rate (FPR), the percentage of problems that arrive at the correct final answer but with a wrong reasoning.

ë‹¹ì—°ížˆ ê³ ì •ëœ ì˜ˆì‚° í•˜ì—ì„œ, WC modelì´ SE modelë³´ë‹¤ ë” ë§Žì€ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìžˆë‹¤. í•˜ì§€ë§Œ SEê°€ ë‹¹ì—°ížˆ í€„ë¦¬í‹°ëŠ” ë†’ì„ ê²ƒ. ê·¸ë ‡ê¸° ë•Œë¬¸ì—, WCê°€ ë” ë†’ì€ coverage and diversity ê·¸ë¦¬ê³  ë™ì‹œì— higher FPRë¥¼ ê°€ì§ˆ ê²ƒì´ë¼ê³  ì´ì•¼ê¸°í•œë‹¤.

ì´í›„, ì €ìžë“¤ì€ ì´ ì¶”ì¸¡ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ì„œ SE and WCë¡œ ë§Œë“  ë°ì´í„°ë¥¼ ì´ìš©í•´ì„œ ëª¨ë¸ë“¤ì„ finetuningí•œë‹¤. ë‹¨ìˆœ í•˜ë‚˜ì˜ ë°©ë²•ì´ ì•„ë‹ˆë¼ ì—¬ëŸ¬ ê°€ì§€ë¡œ.

1. knowledge distillation, where a student LM learns from a teacher LM (Hinton et al., 2015);

1. self-improvement, where an LM learns from self-generated data (Huang et al., 2022); and

1. a new paradigm we introduce called Weak-to-Strong Improvement, where a strong student LM improves using synthetic data from a weaker teacher LM.

ì €ìžë“¤ì€ ì—¬ëŸ¬ ê°œì˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì•„ì£¼ ì¼ê´€ì  SE-generated data ë³´ë‹¤ WC-generated dataë¡œ í•™ìŠµí•œ ê²°ê³¼ê°€ í›¨ì”¬ ì¢‹ìŒì„ ë³´ì¸ë‹¤ (ì¼ë°˜ì ì¸ ë¯¿ìŒê³¼ ë‹¬ë¦¬) ì¦‰, WC-generated dataì—ì„œ ìƒ˜í”Œë§í•˜ëŠ” ê²ƒì´ í›¨ì”¬ compute optimalí•˜ë‹¤ëŠ” ê²ƒ.

ì–´ëŠ ì •ë„ í° ìŠ¤ì¼€ì¼ì—ì„œ ë” ìž‘ì€ ëª¨ë¸ê³¼ í° ëª¨ë¸ì˜ ì„±ëŠ¥ ê°­ì´ ì ì°¨ ì¤„ì–´ë“¤ê³  ìžˆëŠ” ìš”ì¦˜, LM reasonersë¥¼ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í•™ìŠµí• ì§€ ìƒê°ì„ í•˜ê²Œ í•œë‹¤.

# Preliminaries

- D = {ð‘žð‘–, ð‘Žð‘–} = training

- reasoning questions = ð‘žð‘–

- final answers = ð‘Žð‘–

ë‹¤ ì•„ì‹œê² ì§€ë§Œ, ì´ë“¤ì„ ê°€ì§€ê³  synthetic dataë¥¼ ë§Œë“œëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:

1. sample multiple solutions for each ð‘žð‘– at a non-zero temperature

1. create the synthetic data with reasoning chain & generated answer

1. filter the incorrect solutions by comparing ð‘ŽË†ð‘– ð‘— to ð‘Žð‘– and removing the solutions whose final answer do not match that of the gold answer

### Metric

- ð‘ð‘œð‘£ð‘’ð‘Ÿð‘Žð‘”ð‘’@ð‘˜ (aka ð‘ð‘Žð‘ ð‘ @ð‘˜)

- ð‘‘ð‘–ð‘£ð‘’ð‘Ÿð‘ ð‘–ð‘¡ð‘¦@ð‘˜

- false positive rate

# Compute-Matched Sampling and Training

ë‹¹ì—°ížˆ ê³ ì •ëœ ì˜ˆì‚°, ê³ ì •ëœ sampling budget (FLOPs) ìƒì—ì„œ, ì‚¬ëžŒë“¤ì€ ë” weaker but cheaper (WC) modelì„ í†µí•´ì„œ ë” ë§Žì€ ìƒ˜í”Œë“¤ì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ë„ ìžˆê³  í˜¹ì€ stronger but more expensive (SE) modelì„ í†µí•´ ë” ì ì§€ë§Œ ì–‘ì§ˆì˜ ë°ì´í„°ë¥¼ ë§Œë“¤ ìˆ˜ ìžˆë‹¤.

WC modelê°€ ð‘ƒ*ð‘Šð¶ parametersë¥¼ ê°€ì§€ê³ , SEê°€ ð‘ƒ*ð‘†ð¸ parametersë¥¼ ê°€ì§„ë‹¤ê³  í•˜ê³ , ë‘ ëª¨ë¸ì„ ì´ìš©í•´ì„œ ë¬´ì¡°ê±´ ê°™ì€ ì˜ˆì‚°ë§Œì„ ì‚¬ìš©í•  ìˆ˜ ìžˆë‹¤ê³  í•˜ë©´, ë§Œë“¤ ìˆ˜ ìžˆëŠ” ë°ì´í„°ì˜ ê°œìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì°¨ì´ê°€ ë‚œë‹¤.

- Following (Kaplan et al., 2020), FLOPs per inference token = 2ð‘ƒ

- FLOPs for ð‘‡ inference tokens = 2ð‘ƒð‘‡

- assume that generating each solution requires an average of ð‘Š inference tokens

- ð‘†*ð‘Šð¶ and ð‘†*ð‘†ð¸ = number of samples we generate per question

- total cost

ì¦‰, ê³ ì • ì˜ˆì‚°ì—ì„œ ð‘ƒ_ð‘†ð¸/ð‘ƒ_WC ë§Œí¼ WCì—ì„œ ë” ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìžˆë‹¤ëŠ” ë§. ì´ë ‡ê²Œ ë‘˜ ì¤‘ í•˜ë‚˜ë¡œ ë°ì´í„°ë¥¼ ë§Œë“  ì´í›„, ê³ ì •ëœ ìŠ¤í…ìœ¼ë¡œ ëª¨ë¸ë“¤ì„ í•™ìŠµì‹œì¼œë³´ê³  ë¹„êµí•˜ì—¬ ë°ì´í„°ë“¤ì˜ ìœ ìš©ì„±ì„ íŒë‹¨í•  ìˆ˜ ìžˆë‹¤.

ì–¸ê¸‰í–ˆë“¯ í•™ìŠµ ë°©ë²•ì€ 3ê°€ì§€:

1. knowledge distillation(Student-LM finetuning)

1. self-improvement

1. ê·¸ë¦¬ê³  ì´ë“¤ì´ ì œì•ˆí•˜ëŠ” novel weak-to-strong improvement paradigm

# Experimental Setup

- Datasets

- Data Generation

- Synthetic Data Evaluation

- Evaluating Finetuned Models:

# Experiments and Results

- (Â§5.1) we analyze the data along various quality metrics .

- (Â§5.2) Subsequently, we present the supervised finetuning results for the different setups .

- (Â§5.3) Finally, we perform ablation studies to study the impact of dataset size, sampling
  strategy, and the role of quality dimensions in the model performance.

## 1. Synthetic Data Analysis

### 1) Coverage

ê²°ë¡ : Gemma2-9B (WC)ì´ Gemma2-27B (SE)ë³´ë‹¤ í›¨ì”¬ ì¢‹ì•˜ë‹¤.

- MATH:

- 11% and 6% at the low and high sampling budgets,

- 8% and 1% for GSM-8K.

ì¦‰, ë” ë§Žì´ ë§Œë“œëŠ” ê²ƒì´ í€„ë¦¬í‹°ê°€ ë” ë‚®ë”ë¼ë„ ë” ë§Žì´ ë¬¸ì œë¥¼ í‘¸ëŠ”ë° ë„ì›€ì´ ë˜ì—ˆë‹¤. converge trendëŠ” ë‹¤ì–‘.

ì¶”ê°€ì ìœ¼ë¡œ, ë” ë§Žì´ ë°ì´í„°ë¥¼ ë§Œë“œëŠ” ê²ƒì€ ë¹„ë‹¨ ë‚®ì€ ë‚œì´ë„ì˜ ë¬¸ì œ ë¿ë§Œ ì•„ë‹ˆë¼ ë†’ì€ ë‚œì´ë„ì—ì„œë„ ê³µí†µì ì´ì—ˆë‹¤.

ì˜¤ížˆë ¤ ë°˜ëŒ€ë¡œ, ë” í° ëª¨ë¸ë¡œ 10ê°œ ë§Œë“¤ ë•ŒëŠ” í’€ì§€ ëª»í–ˆë˜ ì–´ë ¤ìš´ ë¬¸ì œë„ ë” ì•½í•œ ëª¨ë¸ë¡œ 30ë²ˆ ë§Œë“œëŠ” ê²½ìš°ì— ìžì£¼ í’€ë ¸ë‹¤ê³ .

### 2) Diversity

Gemma2-9Bì—ì„œ ìƒì„±ëœ ë°ì´í„°ì˜ ë‹¤ì–‘ì„±ì€ Gemma2-27Bë³´ë‹¤ MATH ë°ì´í„°ì…‹ì˜ ì €ì˜ˆì‚°ì—ì„œ 86%, ê³ ì˜ˆì‚°ì—ì„œ 125% ë” ë†’ì•˜ìœ¼ë©°, GSM-8K ë°ì´í„°ì…‹ì—ì„œëŠ” ê°ê° 134%ì™€ 158% ë” ë†’ìŒ.

### 3) FPR

human í‰ê°€ì— ë”°ë¥´ë©´ WC ëª¨ë¸ì´ ìƒì„±í•œ í•´ê²°ì±…ì˜ FPRì´ MATHì—ì„œëŠ” SE ëª¨ë¸ë³´ë‹¤ 7% ë†’ì•˜ê³ , GSM-8Kì—ì„œëŠ” 2% ë†’ì•˜ìŒ.
-> ìƒê°ë³´ë‹¤ ì°¨ì´ëŠ” ì•ˆë‚˜ì§€ë§Œ, ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ì¢‹ì§€ëŠ” ì•ŠìŒ.

## 2. Compute-Optimality Results for Training

ê·¸ë ‡ë‹¤ë©´ ì´ë“¤ì€ ë‹¤ì–‘í•˜ê²Œ í•™ìŠµí•´ë´¤ì„ ë•ŒëŠ” ì–´ë–¨ê¹Œ.

1. Student-LM Finetuning
   Gemma-7Bë¥¼ WCì™€ SCë¡œ í•™ìŠµí•œ ê²°ê³¼.
   WC consistently outperforms the one finetuned on data from SC. ì¼ë°˜ì ì¸ ë¯¿ìŒê³¼ ë‹¤ë¥´ë‹¤.

1. WC-LM Finetuning
   Gemma2-9Bë¥¼ Gemma2-9Bê°€ ë§Œë“  WCì™€ 27Bê°€ ë§Œë“  SCë¡œ í•™ìŠµí•œ ê²°ê³¼. ëŒ€ë¶€ë¶„ WCê°€ ë” ë‚˜ì•˜ì§€ë§Œ, ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ë„ ì¡´ìž¬. ì €ìžë“¤ì€ ì´ê²ƒì´ ë°ì´í„°ê°€ ë„ˆë¬´ ì‰¬ì›Œì„œë¼ê³  ì£¼ìž¥.

1. SE-LM finetuning
   Gemma2-27Bë¥¼ ì–‘ ë°ì´í„°ë¡œ í•™ìŠµ. ë” ìž‘ì€ ëª¨ë¸ë¡œ ë§Œë“  ë°ì´í„°ê°€ ë†€ëžê²Œë„ ë” ë„ì›€ì´ ë˜ì—ˆë‹¤.

> Takeaway: Overall, our findings challenge the conventional wisdom that advocates training on samples from the SE model, by showing that training on samples from the WC model may be more compute-optimal across various tasks and setups.

## 3. Ablation Studies

### Impact of Dataset Size

### Default vs Compute-Optimal Sampling from Cheap LMs

ê·¸ë ‡ë‹¤ë©´, ê¸°ì¡´ì— SEë¥¼ ì‚¬ìš©í•˜ë˜ ì¼ë°˜ì ì¸ ë°©ë²•ì²˜ëŸ¼ ë°ì´í„° ê°œìˆ˜ë¥¼ í†µì¼í•˜ë©´?

ë³¼ ìˆ˜ ìžˆëŠ” ê²ƒì²˜ëŸ¼, ë” í€„ë¦¬í‹° ì¢‹ì€ ê²ƒì„ ì‚¬ìš©í•˜ëŠ”ê²Œ ë” ì¢‹ì€ ê²ƒì€ í™•ì‹¤í•˜ë‹¤.

### Coverage and Diversity:

# Scaling to state-of-the-art language models

> Takeaway: We demonstrate that price-matched sampling from weaker SoTA LMs produces
> superior reasoners compared to finetuning with data from stronger SoTA models.

# Conclusion
