---
categories:
  - paper-reviews
date: "2023-01-26 00:00:00"
description: ë…¼ë¬¸ ë¦¬ë·° - Retrieval, Instruction Tuning ê´€ë ¨ ì—°êµ¬
giscus_comments: true
layout: post
related_posts: false
tags:
  - bert
  - generative
  - gpt
  - instruction tuning
  - language-model
  - llm
  - neural
  - nlp
  - paper-review
  - retrieval
  - rlhf
thumbnail: assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/thumbnail.jpg
title: Task-aware Retrieval with Instructions
---

**ë…¼ë¬¸ ì •ë³´**

- **Date**: 2023-01-26
- **Reviewer**: ê±´ìš° ê¹€
- **Property**: Retrieval, Instruction Tuning

# 1. Introduction

**Information Retrieval: **the task of finding **_relevant _**documents from a large colection of texts

- **Relevance**

  - amorphous (ì²´ê³„ë‚˜ í†µì¼ì„±ì´ ì—†ëŠ”)

  - a query alone may not fully caputre user information needs

â†’ ì•„ë˜ Figure ì˜ˆì‹œì—ì„œ ë³´ì´ëŠ” ë°”ì™€ ê°™ì´, **_â€˜Implementing batch normalization in Pythonâ€™_** queryê°€ ì£¼ì–´ì§ˆ ë•Œ, queryë§Œ ê°€ì§€ê³ ëŠ” <(1) queryì˜ ëœ»ì„ python í•¨ìˆ˜ë¡œ êµ¬í˜„í•˜ëŠ”ì§€, (2) query ìì²´ì— ëŒ€í•œ ë™ì¼í•œ ì§ˆë¬¸ì„ ì°¾ëŠ”ì§€, (3) ë‹¨í¸ì ì¸ í•¨ìˆ˜ë¥¼ ì°¾ëŠ”ì§€> ì•Œ ìˆ˜ê°€ ì—†ë‹¤.

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_000.png" class="img-fluid rounded z-depth-1" %}

ì§€ê¸ˆê¹Œì§€ ì—°êµ¬ëœ Retrieval moduleì€ ì´ëŸ¬í•œ **_Implicit Intent_**ë¥¼ labeled dataì„ í™œìš©í•´ì„œ ë…ë¦½ì ì¸ ëª¨ë¸ë¡œë¶€í„° í•™ìŠµì„ ì‹œí‚¨ë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ë‹¹ì—°íˆ ëª‡ ê°€ì§€ Limitationsë“¤ì´ ì¡´ì¬í•˜ëŠ”ë°,

1. task-specific notion of relevanceë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œ modelì€ labeled dataê°€ ë§ì´ í•„ìš”

2. í•˜ë‚˜ì˜ taskì— í•™ìŠµëœ modelì€ ë‹¤ë¥¸ ìƒˆë¡œìš´ taskì— ì‰½ê²Œ transfer í•  ìˆ˜ ì—†ìŒ

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_001.png" class="img-fluid rounded z-depth-1" %}

- **_Retrieval with instructions_**: explicitlyí•˜ê²Œ Userì˜ ì˜ë„ë¥¼ ìì—°ì–´ë¡œ êµ¬ì„±ëœ descriptionì„ í†µí•´ ëª¨ë¸ë§í•˜ëŠ” task â†’ ì´ taskì˜ ëª©í‘œëŠ” queryì™€ relevantí•˜ë©´ì„œ instructionì— ì˜ ë°˜ì˜ëœ documentë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤.

  - **BERRI**: ëŒ€ëµ 40ê°œì˜ retrieval datasetìœ¼ë¡œ ë‹¤ì–‘í•œ Instructionì„ í¬í•¨í•˜ë©° êµ¬ì„±ëœ ë°ì´í„°ì…‹ (10ê°œ ì´ìƒì˜ domain)

  - **TART**: BERRI datasetì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ ì‹œí‚¨ single multi-task retrieval system (task-aware retriever)

    - TART-dual: dual-encoder êµ¬ì¡°

    - TART-full: cross-encoder êµ¬ì¡° â†’ (show state-of-the-art on **BEIR**, **LOTTE**-pooled)

  - **X^2 \*\***-Retrieval\*\* (Cross-task Cross-domain Retrieval) Evaluation ì œì‹œ: ë‹¤ì–‘í•œ intentsë“¤ì´ ìˆëŠ” queryë“¤ì´ large-scale + cross-domainí•œ corpusì—ì„œ relevant documentsë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ”ì§€ í‰ê°€í•˜ëŠ” task

# 2. Background and Related Work

### Zero-shot training of retrievers

- **ìµœê·¼ì— Neural Netwrokë¥¼ í™œìš©í•´ì„œ term-based retrievers (BM25)ë³´ë‹¤ retrieval taskì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì¸ ì—°êµ¬ë“¤ì´ ë‹¤ìˆ˜ ì¡´ì¬í•˜ì§€ë§Œ, ê·¸ì— ë§ëŠ” training dataê°€ ë§ì´ í•„ìš”í•œ ë¬¸ì œê°€ ìˆìŒ**

  - Dense Passage Retrieval for Open-Domain Question Answering (Karpukhin et al. 2020)

    - Dual-encoder êµ¬ì¡°ë¡œ ODQA taskì—ì„œ ì²˜ìŒìœ¼ë¡œ BM25ë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì„

  - One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval (Asai et al. 2021)

    - DPRì˜ multilingual version

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_002.png" class="img-fluid rounded z-depth-1" %}

- KILT: a Benchmark for Knowledge Intensive Language Tasks (Petroni et al. 2021)

  - KILT benchmakr ì œì•ˆ â†’ Wiki ê¸°ë°˜ìœ¼ë¡œ ì—¬ëŸ¬ê°€ì§€ Knowledge Intensive task í•©ì¹œ ê²ƒ

- **ë”°ë¼ì„œ, zero-shot settingì—ì„œ Neural Network ê¸°ë°˜ Retrievalì„ ì—°êµ¬í•˜ëŠ” ì‹œë„ê°€ ë§ì•„ì§**

  1. Unsupervised approach

  1. Contriever

  1. Train a single retreival on large-scale supervised dataset

  1. MS MARCOì— í•™ìŠµì„ í•œ ë’¤ ë‹¤ë¥¸ datasetì— ì ìš©

  1. Train customized retrievers for each task on unlabeled corpora

  1. GPL: Generative Pseudo Labeling for Unsupervised Domain Adaptation
     of Dense Retrieval (Wang et al. 2022)

### Instruction tuning

- **ìµœê·¼ì— instructionsì— LLMsì— ë”í•´ ë‹¤ì–‘í•œ taskì—ì„œ zero-shot, few-shot ì„±ëŠ¥ì„ ë†’ì¸ ì—°êµ¬ë“¤ì´ ë§ì´ ì¡´ì¬í•¨.**

  - FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS (Wei et al. 2022)

    - FLAN ì œì‹œí•œ ë…¼ë¬¸: Instruction tuning (LMsì„ instructionì´ ìˆëŠ” datasetì— finetuning)

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_003.png" class="img-fluid rounded z-depth-1" %}

- MULTITASKPROMPTEDTRAININGENABLES ZERO-SHOTTASKGENERALIZATION (Sanh et al. 2022)

  - T0 ì œì‹œí•œ ë…¼ë¬¸: zero-shot generalizationì„ multitask learningìœ¼ë¡œ explicití•˜ê²Œ í•™ìŠµí•´ì„œ êµ¬í˜„

  - NLP tasksë¥¼ human-readable prompted formatìœ¼ë¡œ ë§Œë“¤ì–´ multi-task trainingìœ¼ë¡œ Enc-Dec ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , testí•  ë•Œ zero-shotìœ¼ë¡œ ì§„í–‰

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_004.png" class="img-fluid rounded z-depth-1" %}

- Training language models to follow instructions with human feedback (Ouyang et al. 2022)

  - InstructGPT ì œì‹œí•œ ë…¼ë¬¸: ì‚¬ì „í•™ìŠµëœ GPT-3ë¥¼ RLHFë¥¼ í†µí•´ ê°•í™”ì‹œí‚¨ ëª¨ë¸

    - Samplingëœ promptì— ëŒ€í•´ GPT-3ê°€ ì¶œë ¥í•œ ê²°ê³¼ì— ëŒ€í•´ ì‚¬ëŒì´ ì§ì ‘ Ranking ë§¤ê¹€

    - PPOë¥¼ í†µí•´ Reward Model training

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_005.png" class="img-fluid rounded z-depth-1" %}

- Scaling Instruction-Finetuned Language Models (Chung et al. 2022)

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_006.png" class="img-fluid rounded z-depth-1" %}

- **í•˜ì§€ë§Œ large-sacle instruction-annotated datasetsì€ retrieval taskë¥¼ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤â€¦.ì •ë§ ëŒ€ë¶€ë¶„ì˜ taskì— ëŒ€í•œ instruction-annotated datasetì´ ìˆëŠ”ë° retrievalë§Œ ë¶€ì¬**

  - PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts (Bach et al. 2022)

    - Open-source systemì„ ì§ì ‘ êµ¬ì¶•í•´ì„œ, communityì— ìˆëŠ” ë‹¤ì–‘í•œ ì‚¬ëŒë“¤ë¡œ í•˜ì—¬ê¸ˆ Natural Language Prompt êµ¬ì¶•

    - 2022ë…„ 1ì›” ê¸°ì¤€ìœ¼ë¡œ 170ê°œ ë°ì´í„°ì…‹ì— ëŒ€í•´ 2000ê°œì˜ promptsê°€ êµ¬ì¶•ë˜ì–´ ìˆìŒ. (í•„ìš”í•  ë•Œ, ì‚¬ìš© ê°€ëŠ¥ ğŸ˜€)

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_007.png" class="img-fluid rounded z-depth-1" %}

- SUPER-NATURALINSTRUCTIONS: Generalization via Declarative Instructions on 1600+ NLP Tasks (Wang et al. 2022)

  - Super-NaturalInstructionì´ë¼ëŠ” benchmark dataset ì œì‹œ (1616ê°œ NLP task + expert-written instructions)

  - í•´ë‹¹ ë°ì´í„°ì…‹ì— í•™ìŠµì‹œí‚¨ Tk-INSTRUCTë¥¼ ì œì‹œí•˜ë©°, InstructGPTë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì„

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_008.png" class="img-fluid rounded z-depth-1" %}

- ëŒ€ë¶€ë¶„ì˜ Instructionì„ ë”°ë¥¸ LLMsë“¤ì€ generationì´ ëª©ì ì¸ architectureë¥¼ ì£¼ë¡œ ê°–ê³  ìˆëŠ”ë° (encoder-decoder, decoder-only), ìˆ˜ ë°±ë§Œ ê±´ì˜ documentsë¥¼ encodingì„ í•´ì•¼í•˜ëŠ” retrieval taskì—ëŠ” ë¶€ì ì ˆí•¨

### Retrieval with descriptions

- ì´ì „ì— retrieval moduleì— descriptionì„ í™œìš©í•œ ì—°êµ¬ëŠ” titleì„ í™œìš©í•œ baselineì— ë¹„í•´ ì‚´ì§ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„

- ìµœê·¼ì— ì™€ì„œ BERT ê¸°ë°˜ LMsë“¤ì´ ë“±ì¥í•˜ë©´ì„œ ë” í’ë¶€í•œ linguistic contextë¥¼ ì¡ì•„ë‚¼ ìˆ˜ ìˆìŒ

  - Context-Aware Document Term Weighting for Ad-Hoc Search (Dai and Callan 2020)

  - Deeper Text Understanding for IR with Contextual Neural Language Modeling (Dai and Callan 2019)

# 3. Task Formulation

- **_Retrieval with instructions (New Task)_**

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_009.png" class="img-fluid rounded z-depth-1" %}

- Given,

  - N documents: D={d_1,...d_N}

  - **Task Instruction: \*\***t\*\*

  - Query: q

**â†’ Find out optimal document \*\***d\*\* (instruction të¥¼ ì˜ ë”°ë¥´ë©° qì™€ relevantê°€ ë†’ì€ ë¬¸ì„œ)

Retrieval with instructionìœ¼ë¡œ í•˜ì—¬ê¸ˆ generalí•˜ê³  task-awareí•œ retrievalì„ ë§Œë“¤ì–´ë³´ì. ì´ë ‡ê²Œ retrieval taskë¥¼ ìƒˆë¡­ê²Œ ì •ì˜í•˜ë©´, ë‹¤ë¥¸ ë°ì´í„°ì…‹ë“¤ì´ í•˜ë‚˜ì˜ retrieverë¥¼ í•™ìŠµì‹œí‚¤ëŠ”ë° ê°™ì´ ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” _(LLMì˜ Instruction tuningì—ì„œ ë³´ì¸ ê²ƒê³¼ ë§ˆì°¬ê°€ì§€ë¡œ Cross-task interdependenceì— ìˆì–´ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥)_ ë³€í™”ê°€ ìˆë‹¤.

â†’ zero-shot transferì´ ê°€ëŠ¥í•˜ê³  multi-task instruction-following retrieverëŠ” ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ task-specific retrieversë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ë„ ëœë‹¤.

# 4. BERRI: Collections of Instruction-annotated Retrieval Tasks

- BERRI (Bank of Explicit RetRieval Instructions): retrieval dataset + other NLP datasets

- BERRIì—ì„œ ê° taskëŠ” í•˜ë‚˜ì˜ corpusì™€, kê°œì˜ query ê·¸ë¦¬ê³  í•˜ë‚˜ì˜ instructionìœ¼ë¡œ ì´ë£¨ì–´ì§„ë‹¤. ê° taskì˜ í•˜ë‚˜ì˜ instanceëŠ” query (q), gold documents (d^+), negative documents (d^-)ê³¼ í•˜ë‚˜ì˜ explicití•œ intent tê°€ ìˆë‹¤.

- Instruction Tuningì—ì„œ informative + diverseí•œ instructionsë“¤ì´ ì£¼ëœ ì„±ê³µ ìš”ì¸ìœ¼ë¡œ ê¼½íˆëŠ”ë°, retrieval taskì—ì„œ ë‹¤ìŒì„ ë§Œì¡±í•˜ëŠ” instructionì„ ì„¤ê³„í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ schemeì„ ë§Œë“¬.

  - ì„ì˜ì˜ retrieval taskë¥¼ ì„¤ëª…í•˜ëŠ” instructionì€: **\*intent\*\*\*\***, **\*\***domain**\*\***, **\*\***unit\*\*\*ì„ í¬í•¨í•œë‹¤.

    - **_intent _**: retrieved textê°€ queryì™€ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ì§€ í™•ì¸

    - **_domain _**: retrieved textì˜ expected source (ex. Wikipedia, PubMed articles)

    - **_unit _**: retrieved textì˜ text block (ex. sentence, paragraph)

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_010.png" class="img-fluid rounded z-depth-1" %}

- **Dataset Collection**

  - BERRIëŠ” retrieval-centric datasets + non-retrieval datasets ì‚¬ìš©í•´ì„œ êµ¬ì¶•ë¨

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_011.png" class="img-fluid rounded z-depth-1" %}

- **Selecting source datasets**

  - Wikipediaì™€ ê°™ì€ ëª‡ëª‡ domainì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë°ì´í„°ì…‹ì€ retrieval datasetì´ ì—†ëŠ” ë¬¸ì œê°€ ìˆë‹¤. ê·¸ë˜ì„œ non-retrieval taskì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì…‹ì„ retrieval taskì— ë§ê²Œë” ë³€í˜• ì‹œì¼œì„œ ì‚¬ìš©í•¨.

- **Unification and instruction annotations**

  - MS MARCOì™€ ê°™ì€ retrieval datasetì€ query qì— ëŒ€í•œ annotated gold documentë¥¼ d^+ë¡œ ì„¤ì •í•˜ì§€ë§Œ, non-retrieval datasetì— ëŒ€í•´ì„œëŠ” input sequenceë¥¼ query, output sequenceë¥¼ gold documentë¡œ ì„¤ì •í–ˆë‹¤.

ex) Summarization: x: source, y: summary â†’ x: query, y: label

    - ê° ë°ì´í„°ì…‹ì— ëŒ€í•˜ì—¬ ì €ìë“¤ì´ ì§ì ‘ instructionì„ ì‘ì„±í•¨ (avg: 3.5ê°œ)

- **Negative documents selection**

  - ê¸°ì¡´ì— ì‚¬ìš©ë˜ëŠ” negative documentì™€ ë‹¤ë¥´ê²Œ ì´ë²ˆ ë…¼ë¬¸ì—ì„œëŠ” ìƒˆë¡œìš´ negative documentë„ ì •ì˜í•¨.

    - **Random negative documents**

    - **Denoised hard negative documents: \*\***d^{HD}\*\*

      - Contrieverì™€ ê°™ì€ off-the-shelf retrieverë¥¼ ì´ìš©í•´ì„œ target corpusì—ì„œ kê°œì˜ top documents (False Negative)ë¥¼ ì¶”ì¶œí•œ ë‹¤ìŒì— cross-encoder model (ms-marco-MiniLM-L-12-v2)ì™€ ê°™ì€ off-the-shelf rerankerë¥¼ ì´ìš©í•´ì„œ normalized scoreê°€ 0.1ë³´ë‹¤ ë‚®ì€ ê°’ì„ d^{HD}ë¡œ ì„¤ì •

    - **Instruction-unfollowing negative documents: \*\***d^{UF}\*\*

      - retrieval (TART)ê°€ instructionì„ ì œëŒ€ë¡œ í•™ìŠµí•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ negative sampleì„ ìƒˆë¡­ê²Œ ì •ì˜í•¨.

      - Instructionì„ ë”°ë¥´ì§€ ì•ŠëŠ” negative documentë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•´ì„œ, ë‹¤ë¥¸ taskì˜ target corpusì—ì„œ off-the-shelf Contrieverë¥¼ ì´ìš©í•´ k ê°œì˜ ë¬¸ì„œë“¤ì„ ì¶”ì¶œí•˜ë©´, ì¶”ì¶œëœ ëª¨ë“  ë¬¸ì„œë“¤ì´ instruction ìì²´ë¥¼ ë”°ë¥´ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— d^{UF}ë¥¼ ë§Œì¡±í•œë‹¤.

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_012.png" class="img-fluid rounded z-depth-1" %}

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_013.png" class="img-fluid rounded z-depth-1" %}

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_014.png" class="img-fluid rounded z-depth-1" %}

# 5. TART: Multi-task Instructed Retriever

- TART (TAsk-aware ReTriever): BERRI datasetì„ ê¸°ë°˜ìœ¼ë¡œ multi-task instruction tuningì„ í†µí•´ í•™ìŠµí•œ single unified retriever

- **TART-dual**: DPRê³¼ ë™ì¼í•œ êµ¬ì¡°ë¥¼ ê°–ê³  ìˆì–´ DPRì´ ê°–ëŠ” ì¥/ë‹¨ì  ë™ì¼

  - í•œ ê°€ì§€ ë‹¤ë¥¸ ì ì€, queryì™€ instructionì´ concatë˜ì–´ query encoder í†µê³¼í•¨.

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_015.png" class="img-fluid rounded z-depth-1" %}

- **Training**

  - In-batch negative ê¸°ë²• ì ìš©í•´ì„œ í•™ìŠµ (Contrastive learning)

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_016.png" class="img-fluid rounded z-depth-1" %}

- **TART-full**: ë‹¤ë“¤ ì•„ì‹œë‹¤ì‹œí”¼ dual-encoderëŠ” queryì™€ documentê°€ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ë˜ê¸° ë•Œë¬¸ì—, limited interactionsì´ ìˆìŒ. ë‹¤ë¥¸ cross-encdoer êµ¬ì¡°ì˜ retrieverì™€ ë§ˆì°¬ê°€ì§€ë¡œ queryì™€ documentë¥¼ í•¨ê»˜ ì…ë ¥í•˜ì—¬ relevance ê³„ì‚°. ê·¸ëŸ°ë° ìˆ˜ ë°±ë§Œ ê±´ì˜ documentì— ëŒ€í•´ í•™ìŠµí•˜ê¸°ì— ë§¤ìš° costê°€ ë¹„ì‹¸ê¸° ë•Œë¬¸ì—,

  - off-the-shelf retrieval (bi-encoder)ë¥¼ ì‚¬ìš©í•´ kê°œë¥¼ ì¶”ì¶œí•˜ê³ , ì¶”ì¶œëœ kê°œë¥¼ TART-fullì— íƒœì›Œì„œ similarity score ê³„ì‚° ì§„í–‰ (TART-dualê³¼ ë§ˆì°¬ê°€ì§€ë¡œ instruction + query + documentë¥¼ concatí•œ êµ¬ì¡°ë¡œ ì…ë ¥)

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_017.png" class="img-fluid rounded z-depth-1" %}

- ì‚¬ì „í•™ìŠµëœ T0-3B, FLAN-T5ë¥¼ TART-fullì˜ backboneìœ¼ë¡œ ì‚¬ìš©í•¨

- T5ë¥¼ non-autoregressive taskì— ì ‘ëª©ì‹œí‚¨ EncT5ì™€ ë™ì¼í•˜ê²Œ ì‚¬ìš©

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_018.png" class="img-fluid rounded z-depth-1" %}

- **Training**

  - cross-entropy lossë¡œ í•™ìŠµ ì§„í–‰

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_019.png" class="img-fluid rounded z-depth-1" %}

- **Knowledge distillation from TART-full to TART-dual**

  - BERRIì—ì„œ default hard negativeëŠ” MS MARCOì— fine-tunedëœ off-the-shelf retrievalsì„ ê¸°ë°˜ìœ¼ë¡œ ì •í•´ì§€ëŠ”ë°, ë‹¤ë¥¸ ëª‡ëª‡ domainì—ì„œëŠ” ì´ë ‡ê²Œ ë½‘íŒ hard negativeê°€ ì„±ëŠ¥ì´ ì•ˆ ì¢‹ì„ ìˆ˜ ìˆë‹¤.

  - TART-fullì„ ë¨¼ì € trainingì„ ì‹œí‚¤ê³  ë‚˜ì„œ, denoising step (hard negative d^{HD}ì–»ëŠ” ê³¼ì •)ì„ ë‹¤ì‹œ ì§„í–‰í•´ì„œ, TART-fullì„ ìƒˆë¡œìš´ d^{HD} ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì‹œ í•™ìŠµì‹œí‚¤ë©´ ì„±ëŠ¥ì´ ì˜¤ë¥¸ë‹¤â€¦

  - êµ³ì´..? ì‹¤í—˜ì¸ ê²ƒ ê°™ìŒ..;;

# 6. Experiments

- **Zero-shot retrieval**

  - BEIR: NQ, MS MARCO, HotpotQA, FEVER, CQADupStackì€ í‰ê°€ì—ì„œ ì œì™¸

  - LOTTE-pooled: ë‹¤ì–‘í•œ domainì˜ datasetì„ í•©ì³ì„œ í‰ê°€ ì‹œì— instruction ì•ˆì— (_domain_)ì´ ë“¤ì–´ê°€ê²Œ ì„¤ì • (ex. â€œRetrieve a *cooking *StackExchange forum ~â€)

  â†’ BERRIë‘ ê²¹ì¹˜ëŠ” datasetì€ ì—†ìŒ

  - Metrics

    - BEIR â†’ NDCG@10 (ë­í‚¹ê¸°ë°˜ ì¶”ì²œì‹œìŠ¤í…œì—ì„œ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì§€í‘œì¸ë°, retrieval taskì—ì„œ ìì£¼ ì‚¬ìš©)

    - LOTTE-pooled â†’ Recall@5

- **X^2 \*\***-Retrieval (Cross-task Cross-domain Retrieval)\*\*

  - Normal benchmark: í•˜ë‚˜ì˜ intentì™€ í•˜ë‚˜ì˜ corpus ê°–ê³  retrievalì„ ì‹œí–‰í•¨ (oversimplify real-world)

  - X^2-Retrievalì€ ëª¨ë¸ë¡œ í•˜ì—¬ê¸ˆ ìƒˆë¡œìš´ taskì—ì„œ zero-shotìœ¼ë¡œ ìˆ˜í–‰ ê°€ëŠ¥í•˜ê³  userì˜ intentë¥¼ ì´í•´í•˜ëŠ” ê²ƒì„ ìš”êµ¬í•œë‹¤

  - 3ê°€ì§€ domains (Wikipedia, Science, Technical)ì„ í¬í•¨í•˜ëŠ” 6ê°€ì§€ ë°ì´í„°ì…‹ ì‚¬ìš©

  - Source document: 3.7 million â†’ oracle setupê³¼ ë¹„êµí•˜ê¸° ìœ„í•´ *closed *setupë„ ì‚¬ìš© (ê¸°ì¡´ benchmarkì¸ BEIRì™€ ë™ì¼í•œ í™˜ê²½)

  - Metrics

    - NDCG@10

    - gap between *closed *and *pooled *setups â†’ to check **_robustness_**

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_020.png" class="img-fluid rounded z-depth-1" %}

- **Baselines**

  - Unsupervised models (trained only on unlabeled text / not trained)

    - BM25

    - Contriever

    - UPR (Contrieverì˜ ê²°ê³¼ ê°’ì„ T0-3Bë¡œ rerankingí•œ ëª¨ë¸)

  - Train retrievers and rerankers on MS MARCO â†’ ìƒˆë¡œìš´ taskì— adaptationì—†ì´ ì ìš©

    - MonoT5

    - Contriever-MS MARCO

    - Contriever-MS MARCO + CE

    - ColBERT v2

    - GTR

    - SGPT-BE

  - ê° taskì— ë§ê²Œ í•™ìŠµë˜ê³  + additional dataë¡œ target corpusì—ì„œ ìƒì„±í•œ data ì¶”ê°€ í•™ìŠµ

    - Promptagator (FLANì„ ì‚¬ìš©í•´ì„œ in-domain data ìƒì„±)

    - GPL (DocT5Queryë¥¼ ì‚¬ìš©í•´ì„œ in-domain data ìƒì„±)

- **Experimental Settings**

  - **TART-full**

    - T0-3B , FLAN-T5 ì˜ encoderë¥¼ initializeí•˜ì—¬ ì‚¬ìš©

    - positive passages : negative passages = 1 : 4

    - 8 GPUs ì‚¬ìš©

    - Contriever-MS MARCOë¥¼ ì‚¬ìš©í•´ì„œ initial documentì˜ candidates ì¶”ì¶œ

  - **TART-dual**

    - Contriever-MS MARCOë¥¼ initializeí•˜ì—¬ ì‚¬ìš©

    - positive passages : negative passages = 1 : 5

    - Negative passages

      - random: 90%

      - d^{HD}: 10%

      - d^{UF}: 10%

    - 64 GPUs ì‚¬ìš© + GPU ë‹¹ batch size: 16 (ë„ˆë¬´ í¬ë‹¤..)

# 7. Results

- **Zero-shot Evaluation Results**

  - 3ë²ˆì§¸ rowì— ìˆëŠ” GPL, Promptagator.. ì¹œêµ¬ë“¤ì€ additional dataì‚¬ìš©í•´ì„œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì§€ë§Œ, TARTëŠ” human-instructionë§Œ ìˆìœ¼ë©´ ëœë‹¤

  - ê·¸ ì™€ì¤‘ì— BM 25ì˜ ì„±ëŠ¥ì´ ì •ë§ ì¢‹ë‹¤ (í•™ìŠµì„ x â†’ ì´ ì •ë„ë©´ ..ã„·ã„·)

  - BM25+MonoT5ì˜ ì„±ëŠ¥ë„ ë†’ì§€ë§Œ rerankingí•  ë•Œ, passage ê°œìˆ˜ê°€ 1000 (TART-fullì€ 100)

  - TART-dualê³¼ Contriever-MS MARCOë¥¼ ë¹„êµí•´ë³´ë©´ BEIRì—ì„œ (6/9)ê°œê°€ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ê¸´ í•˜ì§€ë§Œ, Touche-2020, Climate-Feverì—ì„œ performance degradationì´ ë„ˆë¬´ ì»¤ì„œ í‰ê·  ê°’ì´ ë‚®ê²Œ ì„ ì •ë¨

    â†’ ì´ì— ëŒ€í•´ ì €ìëŠ” dual-encoderì˜ í•œê³„ (queryì™€ documentì˜ limited interaction)ë•Œë¬¸ì´ë¼ê³  í•‘ê³„ë¥¼ ëŒ€ì§€ë§Œ, Contrieverë„ ë™ì¼ êµ¬ì¡°ê¸° ë•Œë¬¸ì— í•‘ê³„ê°€ ê³¼ì—° ë ê¹Œ ì˜ë¬¸..) + ë‹¤ë§Œ, BERT (base) ì‘ì€ í¬ê¸°ì˜ LMì— Instruction tuningì„ ì ‘ëª© ì‹œí‚¨ ê²ƒì´ ì´ìœ  (ì´ì „ ì—¬ëŸ¬ê°€ì§€ Instruction tuning ì—°êµ¬ë“¤ì€ LLMsë§Œ ITê°€ ê°€ëŠ¥í•˜ê³ , ëª¨ë¸ì˜ í¬ê¸°ê°€ ì‘ìœ¼ë©´ ì ìš©í•˜ê¸° í˜ë“¤ë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ„)

  - LOTTE-pooled ê²°ê³¼ë¥¼ ë³´ë©´ baselinesë“¤ì— ë¹„í•´ TARTê°€ í° ì°¨ì´ë¡œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ëŠ”ë°, ì´ëŠ” testì‹œì— ë‹¨ìˆœíˆ instructionì„ ì¶”ê°€í•˜ëŠ” ê²ƒì€ í¬ê²Œ ë„ì›€ì´ ì•ˆëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤Œ

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_021.png" class="img-fluid rounded z-depth-1" %}

- **X^2\*\***-Retreival Evaluation Results\*\*

  - Contrieverì™€ Contriever+CEëŠ” closed setupì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ”ë°, pooled setupì—ì„œëŠ” ì €ì¡°í•œ ì„±ëŠ¥ì„ ë³´ì„. (íŠ¹íˆ Contriever+CEê°€ ì‹¬í•¨)

â†’ ê·¸ëŸ°ë°, Contriever ìì²´ì˜ robustnessëŠ” ë˜ ê°•í•¨â€¦ìŒ..ê·¸ëƒ¥ Contrieverë„ ë§¤ìš° ê°•ë ¥í•œ retrievalì¸ ê±°ë¥¼ ì´ ì‹¤í—˜ì—ì„œ í™•ì¸í–ˆìŒ

- TART-full (T0)ê°€ ì „ì²´ì—ì„œ pooled setupì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ ë§¤ìš° ê°•ë ¥í•œ zero-shot adaptaion + cross-task abilityë¥¼ ê°–ê³  ìˆìŒì„ ë³´ì´ëŠ”ë°, ìœ„ì— zero-shot evaluationì—ì„œëŠ” TART-full (FLAN)ì´ ë” ì¢‹ê¸´ í–ˆìŒ. ì´ê±°ì— ëŒ€í•œ ì–¸ê¸‰ì€ ë”°ë¡œ ì—†ëŠ”ë°..

- ë¬´ì—‡ë³´ë‹¤ TART-dual ìì²´ì˜ ì„±ëŠ¥ì€ Contrieverë³´ë‹¤ closed setupì—ì„œë„ ë‚®ê²Œ ë‚˜ì™”ìŒ.

â†’ ê·¸ëŸ°ë°, **_robustness _**ì²™ë„ê°€ ê°€ì¥ ë†’ê²Œ ë‚˜ì™”ë‹¤ê³  í•´ì„œ, ì €ìê°€ ë˜ ë§ì„ â€œeven smaller models can be guided by instructionsâ€ì´ ê°€ëŠ¥í•˜ë‹¤ê³  í•˜ë„¤â€¦ìœ„ì— ì‹¤í—˜ì´ë‘ ë‹¤ë¥¸ ë§¥ë½ì˜ ë§ì¸ë° ì´ëŠ” ê°€ë³ê²Œ ë¬´ì‹œ. ê·¸ëƒ¥ ì‘ì€ LMì—ëŠ” instruction ì ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¢‹ì€ ì „ëµì¸ë“¯

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_022.png" class="img-fluid rounded z-depth-1" %}

# 8. Analysis

- **Effects of Instruction at training and inference**

  - Red: TART-full (train with instruction + test with instruction)

  - Green: train without instruction + test with instruction

  - Blue: train with instructions + test without instruction

  - Yellow: train without instruction + test without instruction

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_023.png" class="img-fluid rounded z-depth-1" %}

- **Effects of dataset scale + Effects of model scale **

  â†’ ëª¨ë¸ í¬ê¸° í¬ë©´ ì¢‹ê³  + ë°ì´í„°ì…‹ number/domain/task ë§ìœ¼ë©´ ì¢‹ë‹¤

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_024.png" class="img-fluid rounded z-depth-1" %}

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_025.png" class="img-fluid rounded z-depth-1" %}

- **Effects of carefully-designed negative samples**

  - d^{HD}, d^{UF}ë¥¼ ë” ì¶”ê°€í•˜ë©´ (challenge negatives) TART-ful ì„±ëŠ¥ í–¥ìƒ

  - without instruction-folloiwng samples (w/o d^{UF})ì¸ ê²½ìš°ì—ì„œëŠ” BEIR í‰ê°€í•  ë•Œ, ê·¸ëƒ¥ TARTë‘ ë™ì¼ ì„±ëŠ¥ì„ ë³´ì¸ ë°˜ë©´ì—, X^2-Retrieval taskì—ì„œëŠ” í° í•˜ë½ì„ ë³´ì„

    â†’ instructionì„ ë¼ê³  í•™ìŠµ ì‹œí‚¤ëŠ” ê²ƒì´ ëª¨ë¸ì˜ robust task-aware retrieval ability í–¥ìƒ

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_026.png" class="img-fluid rounded z-depth-1" %}

# 9. Dicussion and Conclusion

- **ì‹¤ì œ ë™ì¼ queryì— ìˆì–´ instructionì„ ë‹¤ë¥´ê²Œ ì£¼ë©´ retrieveë˜ëŠ” textëŠ” ë‹¤ë¦„**

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_027.png" class="img-fluid rounded z-depth-1" %}

- **ì •ì„± í‰ê°€ ì˜ˆì‹œ (ë¬¼ë¡  ì²´ë¦¬í”¼í‚¹)**

{% include figure.liquid loading="eager" path="assets/img/posts/2023-01-26-task-aware-retrieval-with-instructions/image_028.png" class="img-fluid rounded z-depth-1" %}

- **NLPì—ì„œ ìµœì´ˆë¡œ Instruction Tuningì„ retrieval taskì— ì ‘ëª© ì‹œí‚¨ paper**

- **dramaticí•œ performance gainì´ ìˆì§€ëŠ” ì•Šì•˜ì§€ë§Œ, ë°©í–¥ì„ ì œì‹œí•œ ê²ƒì— ìˆì–´ì„œ ì˜ì˜ê°€ ìˆìŒ**
