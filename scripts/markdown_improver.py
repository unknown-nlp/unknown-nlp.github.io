#!/usr/bin/env python3
"""
ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ê°€ë…ì„±ì„ ê°œì„ í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python scripts/markdown_improver.py --input "input.md" --output "output.md"
    python scripts/markdown_improver.py --input "input.md"  # ê°™ì€ íŒŒì¼ì— ë®ì–´ì“°ê¸°
"""

import re
import argparse
from pathlib import Path

def improve_markdown_readability(content):
    """
    ë§ˆí¬ë‹¤ìš´ì˜ ê°€ë…ì„±ì„ ëŒ€í­ ê°œì„ í•˜ëŠ” í•¨ìˆ˜
    """
    
    # 1. ì œëª© ê³„ì¸µ êµ¬ì¡° ì •ë¦¬
    content = fix_heading_hierarchy(content)
    
    # 2. ë¦¬ìŠ¤íŠ¸ êµ¬ì¡° ê°œì„ 
    content = improve_lists(content)
    
    # 3. ì½”ë“œ ë¸”ë¡ ì •ë¦¬
    content = improve_code_blocks(content)
    
    # 4. í…Œì´ë¸” ì •ë¦¬
    content = improve_tables(content)
    
    # 5. ê°•ì¡° í‘œì‹œ ì¼ê´€ì„± ê°œì„ 
    content = improve_emphasis(content)
    
    # 6. ë§í¬ ì •ë¦¬
    content = improve_links(content)
    
    # 7. ê³µë°± ë° ì¤„ë°”ê¿ˆ ì •ë¦¬
    content = fix_spacing(content)
    
    # 8. ì¸ìš©êµ¬ ê°œì„ 
    content = improve_quotes(content)
    
    # 9. íŠ¹ìˆ˜ ì„¹ì…˜ ê°•ì¡°
    content = enhance_special_sections(content)
    
    # 10. í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°œì„ 
    content = improve_korean_text(content)
    
    return content.strip()

def fix_heading_hierarchy(content):
    """ì œëª© ê³„ì¸µ êµ¬ì¡° ì •ë¦¬"""
    lines = content.split('\n')
    result = []
    
    for line in lines:
        # ì œëª© ë ˆë²¨ ì •ë¦¬ (ë„ˆë¬´ ê¹Šì€ ì œëª© ë°©ì§€)
        if line.strip().startswith('#'):
            # 7ë ˆë²¨ ì´ìƒì˜ ì œëª©ì„ 6ë ˆë²¨ë¡œ ì œí•œ
            if line.startswith('#######'):
                line = re.sub(r'^#{7,}', '######', line)
            
            # ì œëª©ê³¼ # ì‚¬ì´ì— ê³µë°± í™•ë³´
            line = re.sub(r'^(#{1,6})([^#\s])', r'\1 \2', line)
            
            # ì œëª© ëì˜ ë¶ˆí•„ìš”í•œ # ì œê±°
            line = re.sub(r'\s*#+\s*$', '', line)
        
        result.append(line)
    
    return '\n'.join(result)

def improve_lists(content):
    """ë¦¬ìŠ¤íŠ¸ êµ¬ì¡° ê°œì„ """
    lines = content.split('\n')
    result = []
    in_list = False
    
    for i, line in enumerate(lines):
        # ë¦¬ìŠ¤íŠ¸ ë§ˆì»¤ í†µì¼ (*, +ë¥¼ -ë¡œ)
        if re.match(r'^\s*[\*\+]\s+', line):
            line = re.sub(r'^(\s*)[\*\+](\s+)', r'\1-\2', line)
        
        # ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ ì •ë¦¬
        if re.match(r'^\s*\d+\.\s+', line):
            # ë²ˆí˜¸ì™€ ë‚´ìš© ì‚¬ì´ ê³µë°± ì •ë¦¬
            line = re.sub(r'^(\s*\d+\.)\s+', r'\1 ', line)
        
        # ë¦¬ìŠ¤íŠ¸ í•­ëª© ë“¤ì—¬ì“°ê¸° ì •ë¦¬
        if re.match(r'^\s*[-\*\+]\s+', line):
            in_list = True
            # ë“¤ì—¬ì“°ê¸° ê³µë°±ì„ 2ì˜ ë°°ìˆ˜ë¡œ ì •ë¦¬
            indent_match = re.match(r'^(\s*)', line)
            if indent_match:
                indent = len(indent_match.group(1))
                normalized_indent = (indent // 2) * 2
                line = ' ' * normalized_indent + line.lstrip()
        elif in_list and line.strip() == '':
            # ë¦¬ìŠ¤íŠ¸ ì¤‘ê°„ì˜ ë¹ˆ ì¤„ ìœ ì§€
            pass
        elif in_list and not re.match(r'^\s*[-\*\+\d]', line) and line.strip():
            # ë¦¬ìŠ¤íŠ¸ê°€ ëë‚¬ìŒì„ ê°ì§€
            in_list = False
        
        result.append(line)
    
    return '\n'.join(result)

def improve_code_blocks(content):
    """ì½”ë“œ ë¸”ë¡ ì •ë¦¬"""
    # ì½”ë“œ ë¸”ë¡ ì „í›„ ì¤„ë°”ê¿ˆ ì •ë¦¬
    content = re.sub(r'\n+```', '\n\n```', content)
    content = re.sub(r'```\n+', '```\n\n', content)
    
    # ì¸ë¼ì¸ ì½”ë“œ ì •ë¦¬
    content = re.sub(r'`([^`]+)`', lambda m: f'`{m.group(1).strip()}`', content)
    
    # ì½”ë“œ ë¸”ë¡ ì–¸ì–´ ì§€ì • ì •ë¦¬
    content = re.sub(r'```(\w+)\n', r'```\1\n', content)
    
    return content

def improve_tables(content):
    """í…Œì´ë¸” ì •ë¦¬"""
    lines = content.split('\n')
    result = []
    
    for line in lines:
        # í…Œì´ë¸” í–‰ ì •ë¦¬
        if '|' in line and not line.strip().startswith('|'):
            # í…Œì´ë¸” í–‰ ì‹œì‘ì— | ì¶”ê°€
            if re.match(r'^\s*[^|]*\|', line):
                line = '|' + line
        
        # í…Œì´ë¸” í–‰ ëì— | ì¶”ê°€
        if '|' in line and not line.strip().endswith('|'):
            line = line.rstrip() + '|'
        
        result.append(line)
    
    return '\n'.join(result)

def improve_emphasis(content):
    """ê°•ì¡° í‘œì‹œ ì¼ê´€ì„± ê°œì„ """
    # ë³¼ë“œ ê°•ì¡° ì •ë¦¬
    content = re.sub(r'\*\*([^*]+)\*\*', r'**\1**', content)
    content = re.sub(r'__([^_]+)__', r'**\1**', content)  # __ë¥¼ **ë¡œ í†µì¼
    
    # ì´íƒ¤ë¦­ ê°•ì¡° ì •ë¦¬
    content = re.sub(r'\b_([^_\s][^_]*[^_\s])_\b', r'*\1*', content)  # _ë¥¼ *ë¡œ í†µì¼
    
    # ì¤‘ì²©ëœ ê°•ì¡° ì •ë¦¬
    content = re.sub(r'\*\*\*([^*]+)\*\*\*', r'***\1***', content)
    
    return content

def improve_links(content):
    """ë§í¬ ì •ë¦¬"""
    # ë§í¬ í…ìŠ¤íŠ¸ì™€ URL ì •ë¦¬
    content = re.sub(r'\[([^\]]+)\]\(\s*([^)]+)\s*\)', r'[\1](\2)', content)
    
    # ìë™ ë§í¬ ì •ë¦¬
    content = re.sub(r'<(https?://[^>]+)>', r'\1', content)
    
    return content

def fix_spacing(content):
    """ê³µë°± ë° ì¤„ë°”ê¿ˆ ì •ë¦¬"""
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    content = re.sub(r'[ \t]+', ' ', content)
    
    # ì¤„ ë ê³µë°± ì œê±°
    content = re.sub(r'[ \t]+$', '', content, flags=re.MULTILINE)
    
    # ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬ (3ê°œ ì´ìƒì„ 2ê°œë¡œ)
    content = re.sub(r'\n{3,}', '\n\n', content)
    
    # ì œëª© ì „í›„ ê³µë°± ì •ë¦¬
    content = re.sub(r'\n+(#{1,6}\s[^\n]+)\n*', r'\n\n\1\n\n', content)
    
    # ì„¹ì…˜ êµ¬ë¶„ì„  ì „í›„ ê³µë°± ì •ë¦¬
    content = re.sub(r'\n*(-{3,}|={3,}|\*{3,})\n*', r'\n\n\1\n\n', content)
    
    return content

def improve_quotes(content):
    """ì¸ìš©êµ¬ ê°œì„ """
    lines = content.split('\n')
    result = []
    
    for line in lines:
        # ì¸ìš©êµ¬ ë§ˆì»¤ ì •ë¦¬
        if line.strip().startswith('>'):
            # > ë’¤ì— ê³µë°± í™•ë³´
            line = re.sub(r'^(\s*>+)([^>\s])', r'\1 \2', line)
        
        result.append(line)
    
    return '\n'.join(result)

def enhance_special_sections(content):
    """íŠ¹ìˆ˜ ì„¹ì…˜ ê°•ì¡°"""
    # ì£¼ìš” í‚¤ì›Œë“œë¥¼ í—¤ë”ë¡œ ë³€í™˜
    special_keywords = [
        r'(Key Insights?|Main Findings?|Conclusion|ê²°ë¡ |í•µì‹¬ ë°œê²¬|ì£¼ìš” ì¸ì‚¬ì´íŠ¸)',
        r'(Abstract|ìš”ì•½|ì´ˆë¡)',
        r'(Introduction|ì„œë¡ |ë„ì…)',
        r'(Methodology|ë°©ë²•ë¡ |ë°©ë²•)',
        r'(Results?|ê²°ê³¼)',
        r'(Discussion|í† ë¡ |ë…¼ì˜)',
        r'(Limitation|í•œê³„ì ?)',
        r'(Future Work|í–¥í›„ ì—°êµ¬|ë¯¸ë˜ ì—°êµ¬)'
    ]
    
    for pattern in special_keywords:
        # ë‹¨ë…ìœ¼ë¡œ ìˆëŠ” í‚¤ì›Œë“œë¥¼ í—¤ë”ë¡œ ë³€í™˜
        content = re.sub(f'^{pattern}:\s*$', r'### \1', content, flags=re.MULTILINE | re.IGNORECASE)
        content = re.sub(f'^{pattern}\s*$', r'### \1', content, flags=re.MULTILINE | re.IGNORECASE)
    
    # Insight ë²ˆí˜¸ ë§¤ê¸°ê¸°
    content = re.sub(r'^(\s*[-\*]\s*)(Insight\s+\d+)', r'\1**\2**', content, flags=re.MULTILINE | re.IGNORECASE)
    
    return content

def improve_korean_text(content):
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°œì„ """
    # í•œêµ­ì–´ì™€ ì˜ì–´/ìˆ«ì ì‚¬ì´ ê³µë°± ì¶”ê°€ (ì„ íƒì )
    # content = re.sub(r'([ê°€-í£])([A-Za-z0-9])', r'\1 \2', content)
    # content = re.sub(r'([A-Za-z0-9])([ê°€-í£])', r'\1 \2', content)
    
    # í•œêµ­ì–´ ë¬¸ì¥ë¶€í˜¸ ì •ë¦¬
    content = re.sub(r'([ê°€-í£])\s*,\s*', r'\1, ', content)
    content = re.sub(r'([ê°€-í£])\s*\.\s*', r'\1. ', content)
    
    # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    content = re.sub(r'([ê°€-í£])\s+([ê°€-í£])', lambda m: f'{m.group(1)}{m.group(2)}' if len(m.group(0)) > 3 else m.group(0), content)
    
    return content

def add_table_of_contents(content):
    """ëª©ì°¨ ìë™ ìƒì„± (ì„ íƒì )"""
    lines = content.split('\n')
    headers = []
    
    for line in lines:
        if line.strip().startswith('#'):
            level = len(re.match(r'^#+', line.strip()).group(0))
            title = re.sub(r'^#+\s*', '', line.strip())
            headers.append((level, title))
    
    if len(headers) > 3:  # í—¤ë”ê°€ 3ê°œ ì´ìƒì¼ ë•Œë§Œ ëª©ì°¨ ìƒì„±
        toc = ["## ëª©ì°¨\n"]
        for level, title in headers[1:]:  # ì²« ë²ˆì§¸ í—¤ë”(ì œëª©)ëŠ” ì œì™¸
            indent = "  " * (level - 2)
            toc.append(f"{indent}- [{title}](#{title.lower().replace(' ', '-')})")
        
        toc_text = '\n'.join(toc) + '\n\n'
        
        # ì²« ë²ˆì§¸ í—¤ë” ë‹¤ìŒì— ëª©ì°¨ ì‚½ì…
        if headers:
            first_header_line = None
            for i, line in enumerate(lines):
                if line.strip().startswith('#'):
                    first_header_line = i
                    break
            
            if first_header_line is not None and first_header_line < len(lines) - 1:
                lines.insert(first_header_line + 1, toc_text)
    
    return '\n'.join(lines)

def process_file(input_file, output_file=None, add_toc=False):
    """
    ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì²˜ë¦¬
    
    Args:
        input_file (str): ì…ë ¥ íŒŒì¼ ê²½ë¡œ
        output_file (str, optional): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì…ë ¥ íŒŒì¼ì— ë®ì–´ì“°ê¸°)
        add_toc (bool): ëª©ì°¨ ì¶”ê°€ ì—¬ë¶€
    """
    input_path = Path(input_file)
    if not input_path.exists():
        raise FileNotFoundError(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
    
    # íŒŒì¼ ì½ê¸°
    with open(input_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ê°€ë…ì„± ê°œì„ 
    improved_content = improve_markdown_readability(content)
    
    # ëª©ì°¨ ì¶”ê°€ (ì„ íƒì )
    if add_toc:
        improved_content = add_table_of_contents(improved_content)
    
    # ì¶œë ¥ íŒŒì¼ ê²°ì •
    if output_file is None:
        output_path = input_path
    else:
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # íŒŒì¼ ì“°ê¸°
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(improved_content)
    
    print(f"âœ… ë§ˆí¬ë‹¤ìš´ ê°œì„  ì™„ë£Œ!")
    print(f"ğŸ“„ ì…ë ¥: {input_path}")
    print(f"ğŸ“„ ì¶œë ¥: {output_path}")
    
    # ê°œì„ ì‚¬í•­ í†µê³„
    original_lines = content.count('\n')
    improved_lines = improved_content.count('\n')
    
    print(f"ğŸ“Š í†µê³„:")
    print(f"   - ì›ë³¸ ì¤„ ìˆ˜: {original_lines}")
    print(f"   - ê°œì„  í›„ ì¤„ ìˆ˜: {improved_lines}")
    print(f"   - íŒŒì¼ í¬ê¸°: {len(improved_content):,} ë°”ì´íŠ¸")

def main():
    parser = argparse.ArgumentParser(description='ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ê°€ë…ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤')
    parser.add_argument('--input', '-i', required=True, help='ì…ë ¥ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', '-o', help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ìƒëµì‹œ ì…ë ¥ íŒŒì¼ì— ë®ì–´ì“°ê¸°)')
    parser.add_argument('--add-toc', action='store_true', help='ëª©ì°¨ ìë™ ìƒì„±')
    
    args = parser.parse_args()
    
    try:
        process_file(
            input_file=args.input,
            output_file=args.output,
            add_toc=args.add_toc
        )
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main()) 