#!/usr/bin/env python3
"""
ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ URL â†’ ai-folio ë¸”ë¡œê·¸ ì™„ì „ ìë™í™”

ì‚¬ìš©ë²•:
    1. ë…¸ì…˜ API í† í° ì„¤ì •: export NOTION_TOKEN="your_token"
    2. python scripts/notion_db_auto.py --database-url "https://notion.so/..."
    
íŠ¹ì§•:
    - ë…¸ì…˜ DB URLë§Œ ìˆìœ¼ë©´ ì™„ì „ ìë™í™”
    - API ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì‹œê°„ ë™ê¸°í™” ê°€ëŠ¥
    - ì´ë¯¸ì§€ ìë™ ë‹¤ìš´ë¡œë“œ
    - ai-folio ì™„ì „ í˜¸í™˜
"""

import os
import re
import requests
import argparse
from pathlib import Path
from datetime import datetime
import time
import yaml

try:
    from notion_client import Client
    NOTION_CLIENT_AVAILABLE = True
except ImportError:
    print("âŒ notion-clientê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    print("   ì„¤ì¹˜ ëª…ë ¹: pip install notion-client")
    NOTION_CLIENT_AVAILABLE = False

# ë¡œì»¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ import
from markdown_utils import (
    extract_metadata_from_content,
    generate_tags_from_content,
    create_front_matter,
    create_metadata_section,
    generate_slug_from_title
)

class NotionDatabaseProcessor:
    def __init__(self, token):
        """
        ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        
        Args:
            token (str): ë…¸ì…˜ API í† í°
        """
        if not NOTION_CLIENT_AVAILABLE:
            raise ImportError("notion-client íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        self.notion = Client(auth=token)
        self.token = token
        self.downloaded_images = {}  # URL -> ë¡œì»¬ íŒŒì¼ëª… ë§¤í•‘
    
    def extract_database_id_from_url(self, url):
        """
        ë…¸ì…˜ URLì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ ID ì¶”ì¶œ
        
        Args:
            url (str): ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ URL
            
        Returns:
            str: ë°ì´í„°ë² ì´ìŠ¤ ID
        """
        # ë‹¤ì–‘í•œ ë…¸ì…˜ URL íŒ¨í„´ ì²˜ë¦¬
        patterns = [
            r'/([a-f0-9]{32})\?',  # ?v= ì•ì˜ ID
            r'/([a-f0-9]{32})$',   # URL ëì˜ ID
            r'/([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})',  # UUID í˜•ì‹
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                db_id = match.group(1).replace('-', '')
                return db_id
        
        raise ValueError(f"URLì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {url}")
    
    def get_database_pages(self, database_id):
        """
        ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            database_id (str): ë°ì´í„°ë² ì´ìŠ¤ ID
            
        Returns:
            list: í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ“– ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í˜ì´ì§€ë“¤ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        
        pages = []
        start_cursor = None
        
        while True:
            try:
                response = self.notion.databases.query(
                    database_id=database_id,
                    start_cursor=start_cursor,
                    page_size=100
                )
                
                pages.extend(response["results"])
                
                if not response["has_more"]:
                    break
                    
                start_cursor = response["next_cursor"]
                time.sleep(0.1)  # API ì œí•œ ë°©ì§€
                
            except Exception as e:
                print(f"âŒ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                break
        
        print(f"âœ… ì´ {len(pages)}ê°œì˜ í˜ì´ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        return pages
    
    def extract_page_metadata(self, page):
        """
        í˜ì´ì§€ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        
        Args:
            page (dict): ë…¸ì…˜ í˜ì´ì§€ ê°ì²´
            
        Returns:
            dict: ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°
        """
        properties = page.get("properties", {})
        metadata = {
            "id": page["id"],
            "title": "Unknown Paper",
            "venue": "",
            "date": "",
            "person": "",
            "property": "",
            "created_time": page.get("created_time", ""),
            "last_edited_time": page.get("last_edited_time", "")
        }
        
        # ì œëª© ì¶”ì¶œ
        title_props = ["ì´ë¦„", "Name", "Title", "name", "title"]
        for prop_name in title_props:
            title_prop = properties.get(prop_name)
            if title_prop and title_prop.get("title"):
                title_text = ""
                for text_obj in title_prop["title"]:
                    title_text += text_obj.get("plain_text", "")
                metadata["title"] = title_text.strip()
                break
        
        # Venue ì¶”ì¶œ
        venue_prop = properties.get("Venue")
        if venue_prop:
            if venue_prop["type"] == "select" and venue_prop.get("select"):
                metadata["venue"] = venue_prop["select"]["name"]
            elif venue_prop["type"] == "rich_text" and venue_prop.get("rich_text"):
                venue_text = ""
                for text_obj in venue_prop["rich_text"]:
                    venue_text += text_obj.get("plain_text", "")
                metadata["venue"] = venue_text.strip()
        
        # Date ì¶”ì¶œ
        date_prop = properties.get("Date")
        if date_prop and date_prop.get("date"):
            metadata["date"] = date_prop["date"]["start"]
        
        # Person ì¶”ì¶œ
        person_prop = properties.get("Person")
        if person_prop:
            if person_prop["type"] == "people" and person_prop.get("people"):
                names = []
                for person in person_prop["people"]:
                    names.append(person.get("name", ""))
                metadata["person"] = ", ".join(names)
            elif person_prop["type"] == "rich_text" and person_prop.get("rich_text"):
                person_text = ""
                for text_obj in person_prop["rich_text"]:
                    person_text += text_obj.get("plain_text", "")
                metadata["person"] = person_text.strip()
        
        # Property ì¶”ì¶œ
        property_prop = properties.get("Property")
        if property_prop:
            if property_prop["type"] == "multi_select" and property_prop.get("multi_select"):
                properties_list = []
                for prop in property_prop["multi_select"]:
                    properties_list.append(prop["name"])
                metadata["property"] = ", ".join(properties_list)
            elif property_prop["type"] == "select" and property_prop.get("select"):
                metadata["property"] = property_prop["select"]["name"]
        
        return metadata
    
    def get_page_content(self, page_id, slug=None):
        """
        í˜ì´ì§€ ë‚´ìš©ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
        
        Args:
            page_id (str): í˜ì´ì§€ ID
            slug (str): í¬ìŠ¤íŠ¸ ìŠ¬ëŸ¬ê·¸ (ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œìš©)
            
        Returns:
            str: ë§ˆí¬ë‹¤ìš´ ë‚´ìš©
        """
        try:
            blocks = self.notion.blocks.children.list(block_id=page_id)
            return self.blocks_to_markdown(blocks["results"], slug)
        except Exception as e:
            print(f"   âŒ í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return ""
    
    def blocks_to_markdown(self, blocks, slug=None):
        """
        ë…¸ì…˜ ë¸”ë¡ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (ê¸°ë³¸ì ì¸ ë³€í™˜)
        
        Args:
            blocks (list): ë…¸ì…˜ ë¸”ë¡ ë¦¬ìŠ¤íŠ¸
            slug (str): í¬ìŠ¤íŠ¸ ìŠ¬ëŸ¬ê·¸ (ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œìš©)
            
        Returns:
            str: ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸
        """
        markdown_content = []
        image_counter = 0
        
        for block in blocks:
            block_type = block["type"]
            
            if block_type == "paragraph":
                text = self.extract_text_from_rich_text(block["paragraph"]["rich_text"])
                if text.strip():
                    markdown_content.append(text + "\n")
            
            elif block_type == "heading_1":
                text = self.extract_text_from_rich_text(block["heading_1"]["rich_text"])
                markdown_content.append(f"# {text}\n")
            
            elif block_type == "heading_2":
                text = self.extract_text_from_rich_text(block["heading_2"]["rich_text"])
                markdown_content.append(f"## {text}\n")
            
            elif block_type == "heading_3":
                text = self.extract_text_from_rich_text(block["heading_3"]["rich_text"])
                markdown_content.append(f"### {text}\n")
            
            elif block_type == "bulleted_list_item":
                text = self.extract_text_from_rich_text(block["bulleted_list_item"]["rich_text"])
                markdown_content.append(f"- {text}\n")
            
            elif block_type == "numbered_list_item":
                text = self.extract_text_from_rich_text(block["numbered_list_item"]["rich_text"])
                markdown_content.append(f"1. {text}\n")
            
            elif block_type == "code":
                text = self.extract_text_from_rich_text(block["code"]["rich_text"])
                language = block["code"].get("language", "")
                markdown_content.append(f"```{language}\n{text}\n```\n")
            
            elif block_type == "quote":
                text = self.extract_text_from_rich_text(block["quote"]["rich_text"])
                markdown_content.append(f"> {text}\n")
            
            elif block_type == "image":
                image_url = block["image"].get("file", {}).get("url", "")
                if image_url and slug:
                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ê²½ë¡œ ë³€í™˜
                    filename = self.download_image(image_url, slug, image_counter)
                    if filename:
                        if filename.startswith("external:"):
                            # ì™¸ë¶€ URLì¸ ê²½ìš° ì›ë³¸ URL ì‚¬ìš©
                            actual_url = filename[9:]  # "external:" ì œê±°
                            print(f"   âš ï¸  ì™¸ë¶€ URL ì‚¬ìš©: {actual_url[:50]}...")
                            markdown_content.append(f"![Image]({actual_url})\n")
                        else:
                            # ë¡œì»¬ íŒŒì¼ì¸ ê²½ìš° al-folio í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                            al_folio_tag = f'{{% include figure.liquid loading="eager" path="assets/img/posts/{slug}/{filename}" class="img-fluid rounded z-depth-1" %}}'
                            markdown_content.append(f"{al_folio_tag}\n")
                        image_counter += 1
                    else:
                        # ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ì‹œ ì›ë³¸ URL ìœ ì§€
                        print(f"   âš ï¸  ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, ì›ë³¸ URL ì‚¬ìš©")
                        markdown_content.append(f"![Image]({image_url})\n")
                elif image_url:
                    # slugê°€ ì—†ëŠ” ê²½ìš° ì›ë³¸ URL ì‚¬ìš©
                    markdown_content.append(f"![Image]({image_url})\n")
            
            # ë‹¤ë¥¸ ë¸”ë¡ íƒ€ì…ë“¤ì€ í•„ìš”ì— ë”°ë¼ ì¶”ê°€
        
        return "\n".join(markdown_content)
    
    def extract_text_from_rich_text(self, rich_text_array):
        """
        ë…¸ì…˜ rich textì—ì„œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            rich_text_array (list): ë…¸ì…˜ rich text ë°°ì—´
            
        Returns:
            str: ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        text_parts = []
        for text_obj in rich_text_array:
            plain_text = text_obj.get("plain_text", "")
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            if text_obj.get("annotations", {}).get("bold"):
                plain_text = f"**{plain_text}**"
            if text_obj.get("annotations", {}).get("italic"):
                plain_text = f"*{plain_text}*"
            if text_obj.get("annotations", {}).get("code"):
                plain_text = f"`{plain_text}`"
            
            text_parts.append(plain_text)
        
        return "".join(text_parts)
    
    def get_image_from_notion_block(self, block):
        """
        ë…¸ì…˜ ë¸”ë¡ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì¶”ì¶œ
        
        Args:
            block (dict): ë…¸ì…˜ ì´ë¯¸ì§€ ë¸”ë¡
            
        Returns:
            dict: ì´ë¯¸ì§€ ì •ë³´ (url, caption ë“±)
        """
        image_info = {}
        
        if block["type"] == "image":
            image_data = block["image"]
            
            # íŒŒì¼ URL ì¶”ì¶œ
            if image_data.get("file"):
                image_info["url"] = image_data["file"]["url"]
                image_info["type"] = "file"
            elif image_data.get("external"):
                image_info["url"] = image_data["external"]["url"]
                image_info["type"] = "external"
            
            # ìº¡ì…˜ ì¶”ì¶œ
            caption_parts = []
            for caption in image_data.get("caption", []):
                caption_parts.append(caption.get("plain_text", ""))
            image_info["caption"] = " ".join(caption_parts)
            
        return image_info
    
    def download_image(self, image_url, slug, image_index=0):
        """
        ë…¸ì…˜ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ì— ì €ì¥
        
        Args:
            image_url (str): ë…¸ì…˜ ì´ë¯¸ì§€ URL
            slug (str): í¬ìŠ¤íŠ¸ ìŠ¬ëŸ¬ê·¸
            image_index (int): ì´ë¯¸ì§€ ì¸ë±ìŠ¤ (ê°™ì€ í¬ìŠ¤íŠ¸ ë‚´ ìˆœì„œ)
            
        Returns:
            str: ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ëª… (ì‹¤íŒ¨ì‹œ None)
        """
        try:
            # ì´ë¯¸ì§€ í´ë” ìƒì„±
            image_dir = Path(f"assets/img/posts/{slug}")
            image_dir.mkdir(parents=True, exist_ok=True)
            
            # ë…¸ì…˜ ì´ë¯¸ì§€ URLì€ íŠ¹ë³„í•œ ì²˜ë¦¬ê°€ í•„ìš”í•¨
            # ë…¸ì…˜ S3 URLì˜ ê²½ìš° Authorization í—¤ë” ì—†ì´ ìš”ì²­
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            # ë…¸ì…˜ íŒŒì¼ URLì¸ì§€ í™•ì¸
            if 'prod-files-secure.s3' in image_url or 'notion.so' in image_url:
                # ë…¸ì…˜ íŒŒì¼ì˜ ê²½ìš° Authorization í—¤ë” ì œê±°
                print(f"   ğŸ”— ë…¸ì…˜ íŒŒì¼ URL ê°ì§€: {image_url[:50]}...")
                response = requests.get(image_url, headers=headers, stream=True, timeout=30)
            else:
                # ì¼ë°˜ ì´ë¯¸ì§€ URLì˜ ê²½ìš° ë…¸ì…˜ API í—¤ë” ì‚¬ìš©
                headers['Authorization'] = f'Bearer {self.token}'
                headers['Notion-Version'] = '2022-06-28'
                response = requests.get(image_url, headers=headers, stream=True, timeout=30)
            
            response.raise_for_status()
            
            # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
            content_type = response.headers.get('content-type', '')
            url_ext = ''
            
            # URLì—ì„œ í™•ì¥ì ì¶”ì¶œ ì‹œë„
            import urllib.parse
            parsed_url = urllib.parse.urlparse(image_url)
            url_path = parsed_url.path.lower()
            
            if url_path.endswith('.jpg') or url_path.endswith('.jpeg'):
                url_ext = '.jpg'
            elif url_path.endswith('.png'):
                url_ext = '.png'
            elif url_path.endswith('.gif'):
                url_ext = '.gif'
            elif url_path.endswith('.webp'):
                url_ext = '.webp'
            elif url_path.endswith('.svg'):
                url_ext = '.svg'
            
            # Content-Typeì—ì„œ í™•ì¥ì ì¶”ì¶œ
            if not url_ext:
                if 'jpeg' in content_type or 'jpg' in content_type:
                    url_ext = '.jpg'
                elif 'png' in content_type:
                    url_ext = '.png'
                elif 'gif' in content_type:
                    url_ext = '.gif'
                elif 'webp' in content_type:
                    url_ext = '.webp'
                elif 'svg' in content_type:
                    url_ext = '.svg'
                else:
                    url_ext = '.jpg'  # ê¸°ë³¸ê°’ì„ jpgë¡œ ë³€ê²½
            
            # íŒŒì¼ëª… ìƒì„±
            filename = f"image_{image_index:03d}{url_ext}"
            file_path = image_dir / filename
            
            # íŒŒì¼ ì €ì¥
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:  # ë¹ˆ ì²­í¬ í•„í„°ë§
                        f.write(chunk)
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = file_path.stat().st_size
            if file_size == 0:
                print(f"   âš ï¸  ë¹ˆ íŒŒì¼ì´ ë‹¤ìš´ë¡œë“œë¨: {filename}")
                file_path.unlink()  # ë¹ˆ íŒŒì¼ ì‚­ì œ
                return None
            
            print(f"   ğŸ“· ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename} ({file_size:,} bytes)")
            return filename
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 400:
                print(f"   âš ï¸  ì´ë¯¸ì§€ URL ì ‘ê·¼ ë¶ˆê°€ (400 Bad Request)")
                print(f"      ë…¸ì…˜ ì´ë¯¸ì§€ëŠ” ì„ì‹œ URLì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤: {image_url[:80]}...")
                # 400 ì—ëŸ¬ì˜ ê²½ìš° ì›ë³¸ URLì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë„ë¡ ë°˜í™˜
                return f"external:{image_url}"
            else:
                print(f"   âŒ HTTP ì—ëŸ¬: {e}")
                return None
        except Exception as e:
            print(f"   âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def convert_page_to_blog(self, page, output_date):
        """
        ë…¸ì…˜ í˜ì´ì§€ë¥¼ ai-folio ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            page (dict): ë…¸ì…˜ í˜ì´ì§€
            output_date (str): ì¶œë ¥ ë‚ ì§œ - ë©”íƒ€ë°ì´í„°ì— ë‚ ì§œê°€ ì—†ì„ ë•Œ ì‚¬ìš©
            
        Returns:
            tuple: (ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ, ì„±ê³µ ì—¬ë¶€)
        """
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = self.extract_page_metadata(page)
        title = metadata["title"]
        
        print(f"   ğŸ“ ì œëª©: {title}")
        
        # ë‚ ì§œ ê²°ì • (ë©”íƒ€ë°ì´í„° ìš°ì„ , ì—†ìœ¼ë©´ ì œê³µëœ ë‚ ì§œ ì‚¬ìš©)
        final_date = output_date
        if metadata.get("date") and metadata["date"].strip():
            meta_date = metadata["date"].strip()
            try:
                # ê°„ë‹¨í•œ ë‚ ì§œ íŒŒì‹± (YYYY-MM-DD í˜•ì‹ ìœ„ì£¼)
                if re.match(r'\d{4}-\d{2}-\d{2}', meta_date):
                    final_date = meta_date[:10]  # YYYY-MM-DD ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    print(f"   ğŸ“… ë©”íƒ€ë°ì´í„° ë‚ ì§œ ì‚¬ìš©: {final_date}")
                else:
                    print(f"   âš ï¸  ë©”íƒ€ë°ì´í„° ë‚ ì§œ í˜•ì‹ ì¸ì‹ ë¶ˆê°€ ({meta_date}), ì œê³µëœ ë‚ ì§œ ì‚¬ìš©: {output_date}")
            except Exception:
                print(f"   âš ï¸  ë©”íƒ€ë°ì´í„° ë‚ ì§œ ì²˜ë¦¬ ì‹¤íŒ¨, ì œê³µëœ ë‚ ì§œ ì‚¬ìš©: {output_date}")
        else:
            print(f"   ğŸ“… ì œê³µëœ ë‚ ì§œ ì‚¬ìš©: {final_date}")
        
        # ìŠ¬ëŸ¬ê·¸ ìƒì„±
        slug = generate_slug_from_title(title, final_date)
        print(f"   ğŸ”— ìŠ¬ëŸ¬ê·¸: {slug}")
        
        # í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ìŠ¬ëŸ¬ê·¸ ì „ë‹¬)
        content = self.get_page_content(page["id"], slug)
        if not content.strip():
            print(f"   âš ï¸  ë‚´ìš©ì´ ì—†ëŠ” í˜ì´ì§€ì…ë‹ˆë‹¤.")
            return None, False
        
        # íƒœê·¸ ìƒì„±
        tags = generate_tags_from_content(title, content, metadata)
        print(f"   ğŸ·ï¸  íƒœê·¸: {', '.join(tags)}")
        
        # Front matter ìƒì„±
        front_matter = create_front_matter(title, final_date, tags, metadata, slug)
        
        # ë©”íƒ€ë°ì´í„° ì„¹ì…˜ ìƒì„±
        metadata_section = create_metadata_section(metadata)
        
        # ìµœì¢… ë‚´ìš© êµ¬ì„±
        yaml_front_matter = "---\n" + yaml.dump(front_matter, default_flow_style=False, allow_unicode=True) + "---\n"
        final_content = yaml_front_matter + metadata_section + "\n" + content
        
        # ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        output_file = Path(f"_posts/{slug}.md")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(final_content)
        
        print(f"   âœ… ë³€í™˜ ì™„ë£Œ: {output_file}")
        
        return str(output_file), True

def process_notion_database(database_url, token, start_date=None):
    """
    ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì²˜ë¦¬í•´ì„œ ai-folio ë¸”ë¡œê·¸ë¡œ ë³€í™˜
    
    Args:
        database_url (str): ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ URL
        token (str): ë…¸ì…˜ API í† í°
        start_date (str, optional): ì‹œì‘ ë‚ ì§œ
    """
    print("ğŸš€ ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ ìë™ ë³€í™˜ ì‹œì‘!")
    
    processor = NotionDatabaseProcessor(token)
    
    # URLì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ ID ì¶”ì¶œ
    try:
        database_id = processor.extract_database_id_from_url(database_url)
        print(f"ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ ID: {database_id}")
    except ValueError as e:
        print(f"âŒ {e}")
        return
    
    # ë°ì´í„°ë² ì´ìŠ¤ í˜ì´ì§€ë“¤ ê°€ì ¸ì˜¤ê¸°
    pages = processor.get_database_pages(database_id)
    
    if not pages:
        print("âŒ ê°€ì ¸ì˜¬ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    if not start_date:
        start_date = datetime.now().strftime("%Y-%m-%d")
    
    success_count = 0
    failed_count = 0
    
    for i, page in enumerate(pages):
        try:
            # ë‚ ì§œë¥¼ í•˜ë£¨ì”© ì¦ê°€ì‹œì¼œì„œ ìˆœì„œ ìœ ì§€ (ì•ˆì „í•œ ë°©ë²•)
            from datetime import timedelta
            start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            current_dt = start_dt + timedelta(days=i)
            date_str = current_dt.strftime("%Y-%m-%d")
            
            print(f"\nğŸ“– [{i+1}/{len(pages)}] í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...")
            
            output_file, success = processor.convert_page_to_blog(page, date_str)
            if success:
                success_count += 1
            else:
                failed_count += 1
            
            # API ì œí•œ ë°©ì§€
            time.sleep(0.3)
            
        except Exception as e:
            print(f"   âŒ í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1
            continue
    
    print(f"\nğŸ‰ ë³€í™˜ ì™„ë£Œ!")
    print(f"   âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"   ğŸ“ ì´ ì²˜ë¦¬: {len(pages)}ê°œ")

def main():
    if not NOTION_CLIENT_AVAILABLE:
        return 1
    
    parser = argparse.ArgumentParser(description='ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ â†’ ai-folio ë¸”ë¡œê·¸ ìë™ ë³€í™˜ê¸°')
    parser.add_argument('--database-url', required=True, help='ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ URL')
    parser.add_argument('--token', help='ë…¸ì…˜ API í† í°')
    parser.add_argument('--start-date', help='ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)')
    
    args = parser.parse_args()
    
    token = args.token or os.getenv('NOTION_TOKEN')
    if not token:
        print("âŒ ë…¸ì…˜ API í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤!")
        print("   ë°©ë²• 1: --token íŒŒë¼ë¯¸í„°")
        print("   ë°©ë²• 2: export NOTION_TOKEN='your_token'")
        print("   ë°©ë²• 3: https://developers.notion.com/ì—ì„œ Integration ìƒì„±")
        return 1
    
    try:
        process_notion_database(
            database_url=args.database_url,
            token=token,
            start_date=args.start_date
        )
    except Exception as e:
        print(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main()) 